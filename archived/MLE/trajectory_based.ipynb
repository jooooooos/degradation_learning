{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_complexity_traj_utils import evaluate_one_estimator_torch\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_sample_complexity_study_torch_parallel(\n",
    "        true_theta_np,\n",
    "        d=5,\n",
    "        num_init_trajs=10,\n",
    "        jump_size=2,\n",
    "        num_increments=10,\n",
    "        num_repeat=20,\n",
    "        learning_rate=0.001,\n",
    "        num_epochs=1000,\n",
    "        batch_size=32,\n",
    "        max_workers=4  # you control # of parallel jobs here\n",
    "    ):\n",
    "    traj_sizes = [num_init_trajs * (jump_size ** i) for i in range(num_increments)]\n",
    "    l2_errors, max_errors, log_likelihoods, estimators = [], [], [], []\n",
    "\n",
    "    for k in tqdm(traj_sizes, desc=\"Trajectory sizes\"):\n",
    "        kwargs_list = [\n",
    "            {\n",
    "                \"k\": k,\n",
    "                \"d\": d,\n",
    "                \"true_theta_np\": true_theta_np,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"seed\": np.random.randint(0, 1e6)\n",
    "            }\n",
    "            for _ in range(num_repeat)\n",
    "        ]\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "            results = list(executor.map(evaluate_one_estimator_torch, kwargs_list))\n",
    "\n",
    "        l2s, maxs, lls, theta_hats = zip(*results)\n",
    "        l2_errors.append((np.mean(l2s), np.std(l2s)))\n",
    "        max_errors.append((np.mean(maxs), np.std(maxs)))\n",
    "        log_likelihoods.append((np.mean(lls), np.std(lls)))\n",
    "        estimators.append(theta_hats)\n",
    "\n",
    "    return traj_sizes, l2_errors, max_errors, log_likelihoods, estimators\n",
    "\n",
    "def plot_with_ci(x, means_and_stds, ylabel, title, save=False):\n",
    "    means = np.array([mean for mean, std in means_and_stds])\n",
    "    stds = np.array([std for mean, std in means_and_stds])\n",
    "\n",
    "    lower = means - 1.96 * stds\n",
    "    upper = means + 1.96 * stds\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x, means, label=\"Mean\", color=\"blue\")\n",
    "    plt.fill_between(x, lower, upper, color=\"blue\", alpha=0.2, label=\"95% CI\")\n",
    "    plt.xlabel(\"Number of Trajectories\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figs/{ylabel}_TB.png\", dpi=300) if save else None\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c0bbe8d5af4297ace5552cadac2b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Trajectory sizes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = 3\n",
    "true_theta_np = np.random.uniform(0.2, 0.8, size=(1,d))\n",
    "\n",
    "traj_sizes, l2s, maxs, lls, estimators = run_sample_complexity_study_torch_parallel(\n",
    "    true_theta_np=true_theta_np,\n",
    "    d=d,\n",
    "    num_init_trajs=100,\n",
    "    jump_size=2,\n",
    "    num_increments=1,\n",
    "    num_repeat=20,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=1000,\n",
    "    batch_size=8,\n",
    "    max_workers=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5617205 , 0.62166464, 0.4842712 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(estimators).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.35825943, 0.31447919, 0.73706058]]),\n",
       " [(array([0.9885555 , 0.35790345, 0.5317727 ], dtype=float32),\n",
       "   array([0.5617071 , 0.50835997, 0.8113076 ], dtype=float32),\n",
       "   array([0.85460883, 0.32857186, 0.3119584 ], dtype=float32),\n",
       "   array([1.0460751 , 0.26730463, 0.2355254 ], dtype=float32),\n",
       "   array([0.61465585, 0.3912766 , 0.50851035], dtype=float32),\n",
       "   array([0.48299775, 0.95463413, 0.05600949], dtype=float32),\n",
       "   array([0.3960647 , 0.9533036 , 0.23909846], dtype=float32),\n",
       "   array([0.5215588 , 0.8190409 , 0.59503984], dtype=float32),\n",
       "   array([0.5523347 , 0.53843904, 0.35275748], dtype=float32),\n",
       "   array([0.6148491 , 0.57228684, 0.29582858], dtype=float32),\n",
       "   array([0.34707072, 0.71496296, 0.59568214], dtype=float32),\n",
       "   array([0.23477848, 0.71755755, 0.8187558 ], dtype=float32),\n",
       "   array([0.5253758 , 1.0030268 , 0.13051999], dtype=float32),\n",
       "   array([0.5581951 , 0.74052614, 0.7254748 ], dtype=float32),\n",
       "   array([0.803447  , 0.46652877, 0.6129582 ], dtype=float32),\n",
       "   array([0.35794213, 0.47736612, 0.6497037 ], dtype=float32),\n",
       "   array([0.28697318, 0.96368253, 0.3702538 ], dtype=float32),\n",
       "   array([0.1232242 , 0.6856789 , 0.75255173], dtype=float32),\n",
       "   array([0.45642558, 0.8726772 , 0.25197262], dtype=float32),\n",
       "   array([0.907569  , 0.10016587, 0.8397425 ], dtype=float32))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_theta_np, estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sample_complexity_results_TB.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((traj_sizes, l2s, maxs, lls), f)\n",
    "    \n",
    "# # load results\n",
    "# with open(\"sample_complexity_results_TB.pkl\", \"rb\") as f:\n",
    "#     traj_sizes, l2s, maxs, lls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_ci(traj_sizes, l2s, \"L2 Norm Error\", \"Sample Complexity: L2 Distance\", save=True)\n",
    "plot_with_ci(traj_sizes, maxs, \"Max Norm Error\", \"Sample Complexity: Max Norm\", save=True)\n",
    "plot_with_ci(traj_sizes, lls, \"Avg Log-Likelihood\", \"Sample Complexity: Log-Likelihood\", save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
