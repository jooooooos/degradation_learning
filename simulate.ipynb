{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bf8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from simulation import Simulator, CustomerGenerator\n",
    "from hazard_models import ExponentialHazard\n",
    "from utility_learner import ProjectedVolumeLearner, diam\n",
    "from degradation_learner import DegradationLearner\n",
    "\n",
    "from utils import unit_ball_rejection_sample, correct_signs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e08dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Sampling Functions ---\n",
    "# def context_sampler() -> np.ndarray:\n",
    "#     \"\"\"Samples a customer's context vector from a uniform distribution.\"\"\"\n",
    "#     return np.random.uniform(low=0.0, high=1.0, size=D)\n",
    "\n",
    "def context_sampler() -> np.ndarray:\n",
    "    \"\"\"Samples a customer's context vector uniformly from the unit ball.\"\"\"\n",
    "    return np.abs(unit_ball_rejection_sample(D))\n",
    "\n",
    "def rental_sampler() -> float:\n",
    "    \"\"\"Samples a customer's desired rental duration from an exponential distribution.\"\"\"\n",
    "    return np.random.exponential(scale=20.0)\n",
    "\n",
    "def interarrival_sampler() -> float:\n",
    "    \"\"\"Samples the time until the next customer arrives.\"\"\"\n",
    "    return np.random.exponential(scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc2c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulation Configuration ---\n",
    "D = 5                                  # Dimension of context vectors\n",
    "LAMBDA_VAL = 0.001                     # Baseline hazard constant\n",
    "NUM_CUSTOMERS = 2000                   # Total number of customers to simulate, i.e. T\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(41)\n",
    "\n",
    "# Ground truth vectors\n",
    "THETA_TRUE = np.array([0.5, 0.2, 0.1, 0.3, 0.4])    # For degradation\n",
    "UTILITY_TRUE = context_sampler()  # For customer's willingness to pay\n",
    "\n",
    "# --- Machine's Pricing Vector 'r' ---\n",
    "# You can change this to test different pricing strategies.\n",
    "# Case 1: A non-zero pricing strategy\n",
    "# PRICING_R = np.array([2.0, 2.0, 2.0, 2.0, 2.0])\n",
    "# Case 2: Zero price (free rentals), guaranteeing 100% acceptance\n",
    "PRICING_R = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e600551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_exp_hazard_model = ExponentialHazard(lambda_val=LAMBDA_VAL)\n",
    "# spontaneous_exp_hazard_model = None # ExponentialHazard(lambda_val=0.01)\n",
    "\n",
    "customer_gen = CustomerGenerator(\n",
    "    d=D,\n",
    "    context_sampler=context_sampler,\n",
    "    rental_sampler=rental_sampler,\n",
    "    interarrival_sampler=interarrival_sampler\n",
    ")\n",
    "\n",
    "centroid_params = {\n",
    "    # 'num_samples': 2000,\n",
    "    # 'thin': None,\n",
    "    # 'burn_in': 500 * D ** 2,\n",
    "    # 'tol': 1e-4,\n",
    "    # 'rho_target': 0.01\n",
    "}\n",
    "\n",
    "termination_rule = lambda diameter: diameter < 0.01  # Example custom termination rule\n",
    "\n",
    "projected_volume_learner = ProjectedVolumeLearner(\n",
    "    T=NUM_CUSTOMERS, \n",
    "    d=D, \n",
    "    centroid_params=centroid_params,\n",
    "    incentive_constant=1.1,\n",
    "    termination_rule=termination_rule,\n",
    ")\n",
    "\n",
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.999,             # Discount factor\n",
    "    'learning_rate': 1e-4,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "training_hyperparams = {\n",
    "    'num_iterations': 100, # Number of training iterations per policy update\n",
    "    'dataset_size': 50000,      # Number of transitions to generate for the offline dataset\n",
    "    'batch_size': 256           # Batch size for training\n",
    "}\n",
    "\n",
    "# Instantiate the Simulator with the new parameters\n",
    "simulator = Simulator(\n",
    "    d=D,\n",
    "    T=NUM_CUSTOMERS,\n",
    "    \n",
    "    theta_true=THETA_TRUE,\n",
    "    utility_true=UTILITY_TRUE,\n",
    "    pricing_r=PRICING_R,\n",
    "    \n",
    "    usage_hazard_model=usage_exp_hazard_model,\n",
    "    customer_generator=customer_gen,\n",
    "    projected_volume_learner=projected_volume_learner,  # Use default ProjectedVolumeLearner\n",
    "    \n",
    "    mdp_params=mdp_params,\n",
    "    training_hyperparams=training_hyperparams,\n",
    "    policy_update_threshold=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting simulation for 2000 customers...\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Restricted license - for non-production use only - expires 2026-11-23\n",
      "INFO:root:Customer 1: Diameter: 1.0038\n",
      "  0%|          | 1/2000 [00:05<2:56:35,  5.30s/it]INFO:root:Customer 2: Diameter: 0.7896\n",
      "  0%|          | 2/2000 [00:10<2:59:28,  5.39s/it]INFO:root:Customer 3: Diameter: 0.6292\n",
      "  0%|          | 3/2000 [00:16<3:08:00,  5.65s/it]INFO:root:Customer 4: Diameter: 0.5915\n",
      "  0%|          | 4/2000 [00:22<3:15:12,  5.87s/it]INFO:root:Customer 5: Diameter: 0.6412\n",
      "  0%|          | 5/2000 [00:29<3:22:11,  6.08s/it]INFO:root:Customer 6: Diameter: 0.2740\n",
      "  0%|          | 6/2000 [00:36<3:32:50,  6.40s/it]INFO:root:Customer 7: Diameter: 0.4080\n",
      "  0%|          | 7/2000 [00:43<3:40:58,  6.65s/it]INFO:root:Customer 8: Diameter: 0.2810\n",
      "  0%|          | 8/2000 [00:50<3:48:21,  6.88s/it]INFO:root:Customer 9: Diameter: 0.3840\n",
      "  0%|          | 9/2000 [00:58<3:54:43,  7.07s/it]INFO:root:Customer 10: Diameter: 0.4161\n",
      "  0%|          | 10/2000 [01:06<4:03:31,  7.34s/it]INFO:root:Customer 11: Diameter: 0.2253\n",
      "  1%|          | 11/2000 [01:14<4:12:23,  7.61s/it]INFO:root:Customer 12: Diameter: 0.2270\n",
      "  1%|          | 12/2000 [01:23<4:24:28,  7.98s/it]INFO:root:Customer 13: Diameter: 0.1966\n",
      "  1%|          | 13/2000 [01:32<4:37:57,  8.39s/it]INFO:root:Customer 14: Diameter: 0.1062\n",
      "  1%|          | 14/2000 [01:42<4:48:23,  8.71s/it]INFO:root:Customer 15: Diameter: 0.2531\n",
      "  1%|          | 15/2000 [01:52<4:59:30,  9.05s/it]INFO:root:Customer 16: Diameter: 0.2217\n",
      "  1%|          | 16/2000 [02:02<5:15:43,  9.55s/it]INFO:root:Customer 17: Diameter: 0.1827\n",
      "  1%|          | 17/2000 [02:13<5:28:10,  9.93s/it]INFO:root:Customer 18: Diameter: 0.0877\n",
      "  1%|          | 18/2000 [02:24<5:36:24, 10.18s/it]INFO:root:Customer 19: Diameter: 0.0985\n",
      "  1%|          | 19/2000 [02:35<5:44:20, 10.43s/it]INFO:root:Customer 20: Diameter: 0.1796\n",
      "  1%|          | 20/2000 [02:46<5:48:37, 10.56s/it]INFO:root:Customer 21: Diameter: 0.0653\n",
      "  1%|          | 21/2000 [02:57<5:59:16, 10.89s/it]INFO:root:Customer 22: Diameter: 0.0419\n",
      "  1%|          | 22/2000 [03:10<6:16:05, 11.41s/it]INFO:root:Customer 23: Diameter: 0.1280\n",
      "  1%|          | 23/2000 [03:23<6:30:16, 11.84s/it]INFO:root:Customer 24: Diameter: 0.0373\n",
      "  1%|          | 24/2000 [03:36<6:42:28, 12.22s/it]INFO:root:Customer 25: Diameter: 0.0600\n",
      "  1%|▏         | 25/2000 [03:49<6:53:12, 12.55s/it]INFO:root:Customer 26: Diameter: 0.0331\n",
      "  1%|▏         | 26/2000 [04:04<7:10:05, 13.07s/it]INFO:root:Customer 27: Diameter: 0.0380\n",
      "  1%|▏         | 27/2000 [04:18<7:23:30, 13.49s/it]INFO:root:Customer 28: Diameter: 0.0283\n",
      "  1%|▏         | 28/2000 [04:33<7:35:23, 13.86s/it]INFO:root:Customer 29: Diameter: 0.0354\n",
      "  1%|▏         | 29/2000 [04:50<8:12:45, 15.00s/it]INFO:root:Customer 30: Diameter: 0.0191\n",
      "  2%|▏         | 30/2000 [05:09<8:44:09, 15.96s/it]INFO:root:Customer 31: Diameter: 0.0052\n",
      "INFO:root:Exploration phase completed at customer 31.\n",
      "  2%|▏         | 31/2000 [05:28<9:18:10, 17.01s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         5 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.48491D+00    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5      0      1      0     0     0   0.000D+00   2.485D+00\n",
      "  F =   2.4849066497880004     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:07<00:00, 6654.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# simulator.projected_volume_learner.is_terminated = True\n",
    "simulation_data = simulator.run(num_customers=NUM_CUSTOMERS)\n",
    "df = pd.DataFrame(simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a53c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_history = pd.DataFrame(simulator.degradation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "\n",
    "degradation_learner.fit(degradation_history)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.event_type == 'rental'].profit.mean(), df[df.event_type == 'rental'].profit.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126debf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.feedback.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086d1ae",
   "metadata": {},
   "source": [
    "## Estimating $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "\n",
    "degradation_learner.fit(df)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0da177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.999,             # Discount factor\n",
    "    'learning_rate': 1e-4,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "# Training Hyperparameters\n",
    "TRAINING_ITERATIONS = 100\n",
    "DATASET_SIZE = 50000          # Number of transitions to generate for the offline dataset\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "u_hat = simulator.centroids[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22317754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_agent = DPAgent(\n",
    "    d=D,\n",
    "    u_hat=u_hat,\n",
    "    degradation_learner=degradation_learner,\n",
    "    customer_generator=customer_gen,\n",
    "    params=mdp_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "dp_agent.train(\n",
    "    num_iterations=TRAINING_ITERATIONS,\n",
    "    dataset_size=DATASET_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = dp_agent.get_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "X_i = df.loc[i, 'sum_of_contexts_after']\n",
    "I_i = 3 # df.loc[i, '']\n",
    "x_i = df.loc[i+1, 'customer_context']\n",
    "T_i = df.loc[i+1, 'rental_duration']\n",
    "\n",
    "arrival_state = np.concatenate([\n",
    "    X_i,\n",
    "    x_i,\n",
    "    [T_i, I_i, 0.0]\n",
    "])\n",
    "action_arrival = optimal_policy(arrival_state)\n",
    "action_map = {0: 'Give Max Acceptable Price', 1: 'Shutdown'}\n",
    "print(f\"Sample Arrival State. Optimal Action: {action_map[action_arrival]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Departure State\n",
    "departure_state = np.concatenate([\n",
    "    X_i+x_i*10, \n",
    "    np.zeros(D), \n",
    "    [0.0, I_i, 1.0]\n",
    "])\n",
    "action_departure = optimal_policy(departure_state)\n",
    "action_map = {2: 'Replace Machine', 3: 'Do Not Replace'}\n",
    "print(f\"Sample Departure State. Optimal Action: {action_map[action_departure]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
