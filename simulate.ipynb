{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bf8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from simulation import Simulator, CustomerGenerator\n",
    "from hazard_models import ExponentialHazard\n",
    "from utility_learner import ProjectedVolumeLearner, diam\n",
    "from degradation_learner import DegradationLearner\n",
    "\n",
    "from utils import unit_ball_rejection_sample, correct_signs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e08dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Sampling Functions ---\n",
    "# def context_sampler() -> np.ndarray:\n",
    "#     \"\"\"Samples a customer's context vector from a uniform distribution.\"\"\"\n",
    "#     return np.random.uniform(low=0.0, high=1.0, size=D)\n",
    "\n",
    "def context_sampler() -> np.ndarray:\n",
    "    \"\"\"Samples a customer's context vector uniformly from the unit ball.\"\"\"\n",
    "    return np.abs(unit_ball_rejection_sample(D))\n",
    "\n",
    "def rental_sampler() -> float:\n",
    "    \"\"\"Samples a customer's desired rental duration from an exponential distribution.\"\"\"\n",
    "    return np.random.exponential(scale=10.0)\n",
    "\n",
    "def interarrival_sampler() -> float:\n",
    "    \"\"\"Samples the time until the next customer arrives.\"\"\"\n",
    "    return np.random.exponential(scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc2c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulation Configuration ---\n",
    "D = 4                                  # Dimension of context vectors\n",
    "LAMBDA_VAL = 0.001                     # Baseline hazard constant\n",
    "NUM_CUSTOMERS = 100000                   # Total number of customers to simulate, i.e. T\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(41)\n",
    "\n",
    "# Ground truth vectors\n",
    "THETA_TRUE = np.array([0.5, 0.2, 0.1, 0.3])#$, 0.4])    # For degradation\n",
    "UTILITY_TRUE = context_sampler()  # For customer's willingness to pay\n",
    "\n",
    "# --- Machine's Pricing Vector 'r' ---\n",
    "# This is a fallback pricing vector, when we don't feed u_hat to calculate_price\n",
    "PRICING_R = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e600551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_exp_hazard_model = ExponentialHazard(lambda_val=LAMBDA_VAL)\n",
    "# spontaneous_exp_hazard_model = None # ExponentialHazard(lambda_val=0.01)\n",
    "\n",
    "customer_gen = CustomerGenerator(\n",
    "    d=D,\n",
    "    context_sampler=context_sampler,\n",
    "    rental_sampler=rental_sampler,\n",
    "    interarrival_sampler=interarrival_sampler\n",
    ")\n",
    "\n",
    "centroid_params = {\n",
    "    # 'num_samples': 2000,\n",
    "    # 'thin': None,\n",
    "    # 'burn_in': 500 * D ** 2,\n",
    "    # 'tol': 1e-4,\n",
    "    # 'rho_target': 0.01\n",
    "}\n",
    "\n",
    "termination_rule = lambda diameter: diameter < 0.0005  # Example custom termination rule\n",
    "\n",
    "projected_volume_learner = ProjectedVolumeLearner(\n",
    "    T=NUM_CUSTOMERS, \n",
    "    d=D, \n",
    "    centroid_params=centroid_params,\n",
    "    incentive_constant=1.1,\n",
    "    termination_rule=termination_rule,\n",
    ")\n",
    "\n",
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.99,             # Discount factor\n",
    "    'learning_rate': 1e-3,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "training_hyperparams = {\n",
    "    'num_iterations': 50, # Number of training iterations per policy update\n",
    "    'dataset_size': 500000,      # Number of transitions to generate for the offline dataset\n",
    "    'batch_size': 2048           # Batch size for training\n",
    "}\n",
    "\n",
    "policy_params = {\n",
    "    'type': 'softmax',\n",
    "    'tau': 1.0,\n",
    "    'epsilon': 0.1,\n",
    "}\n",
    "\n",
    "# Instantiate the Simulator with the new parameters\n",
    "simulator = Simulator(\n",
    "    d=D,\n",
    "    T=NUM_CUSTOMERS,\n",
    "    \n",
    "    theta_true=THETA_TRUE,\n",
    "    utility_true=UTILITY_TRUE,\n",
    "    pricing_r=PRICING_R,\n",
    "    \n",
    "    usage_hazard_model=usage_exp_hazard_model,\n",
    "    customer_generator=customer_gen,\n",
    "    projected_volume_learner=projected_volume_learner,  # Use default ProjectedVolumeLearner\n",
    "    \n",
    "    mdp_params=mdp_params,\n",
    "    training_hyperparams=training_hyperparams,\n",
    "    policy_params=policy_params,\n",
    "    policy_update_threshold=5,\n",
    "    time_normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6288559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting simulation for 100000 customers...\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Set parameter Username\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LicenseID to value 2651514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Set parameter LicenseID to value 2651514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2026-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Academic license - for non-commercial use only - expires 2026-04-14\n",
      "INFO:root:Customer 1: Diameter: 1.0041\n",
      "  0%|          | 1/100000 [00:02<82:20:35,  2.96s/it]INFO:root:Customer 2: Diameter: 0.7731\n",
      "  0%|          | 2/100000 [00:06<88:01:30,  3.17s/it]INFO:root:Customer 3: Diameter: 0.6616\n",
      "  0%|          | 3/100000 [00:09<94:00:59,  3.38s/it]INFO:root:Customer 4: Diameter: 0.4420\n",
      "  0%|          | 4/100000 [00:13<100:14:34,  3.61s/it]INFO:root:Customer 5: Diameter: 0.3997\n",
      "  0%|          | 5/100000 [00:18<106:17:59,  3.83s/it]INFO:root:Customer 6: Diameter: 0.6467\n",
      "  0%|          | 6/100000 [00:22<112:59:09,  4.07s/it]INFO:root:Customer 7: Diameter: 0.4222\n",
      "  0%|          | 7/100000 [00:27<120:52:14,  4.35s/it]INFO:root:Customer 8: Diameter: 0.3064\n",
      "  0%|          | 8/100000 [00:32<130:04:44,  4.68s/it]INFO:root:Customer 9: Diameter: 0.2615\n",
      "  0%|          | 9/100000 [00:38<139:45:03,  5.03s/it]INFO:root:Customer 10: Diameter: 0.4127\n",
      "  0%|          | 10/100000 [00:44<149:52:13,  5.40s/it]INFO:root:Customer 11: Diameter: 0.2853\n",
      "  0%|          | 11/100000 [00:51<159:19:57,  5.74s/it]INFO:root:Customer 12: Diameter: 0.0759\n",
      "  0%|          | 12/100000 [00:58<168:14:39,  6.06s/it]INFO:root:Customer 13: Diameter: 0.1593\n",
      "  0%|          | 13/100000 [01:05<177:01:57,  6.37s/it]INFO:root:Customer 14: Diameter: 0.0694\n",
      "  0%|          | 14/100000 [01:12<186:14:52,  6.71s/it]INFO:root:Customer 15: Diameter: 0.0962\n",
      "  0%|          | 15/100000 [01:20<194:38:55,  7.01s/it]INFO:root:Customer 16: Diameter: 0.0467\n",
      "  0%|          | 16/100000 [01:28<203:33:23,  7.33s/it]INFO:root:Customer 17: Diameter: 0.0888\n",
      "  0%|          | 17/100000 [01:37<212:22:41,  7.65s/it]INFO:root:Customer 18: Diameter: 0.1337\n",
      "  0%|          | 18/100000 [01:45<220:00:08,  7.92s/it]INFO:root:Customer 19: Diameter: 0.0659\n",
      "  0%|          | 19/100000 [01:54<226:52:31,  8.17s/it]INFO:root:Customer 20: Diameter: 0.0585\n",
      "  0%|          | 20/100000 [02:03<234:14:59,  8.43s/it]INFO:root:Customer 21: Diameter: 0.0471\n",
      "  0%|          | 21/100000 [02:12<242:33:04,  8.73s/it]INFO:root:Customer 22: Diameter: 0.0599\n",
      "  0%|          | 22/100000 [02:22<250:52:15,  9.03s/it]INFO:root:Customer 23: Diameter: 0.0177\n",
      "  0%|          | 23/100000 [02:32<259:40:42,  9.35s/it]INFO:root:Customer 24: Diameter: 0.0186\n",
      "  0%|          | 24/100000 [02:43<269:02:46,  9.69s/it]INFO:root:Customer 25: Diameter: 0.0255\n",
      "  0%|          | 25/100000 [02:53<278:17:05, 10.02s/it]INFO:root:Customer 26: Diameter: 0.0119\n",
      "  0%|          | 26/100000 [03:05<289:12:14, 10.41s/it]INFO:root:Customer 27: Diameter: 0.0088\n",
      "  0%|          | 27/100000 [03:17<300:50:33, 10.83s/it]INFO:root:Customer 28: Diameter: 0.0152\n",
      "  0%|          | 28/100000 [03:29<311:33:14, 11.22s/it]INFO:root:Customer 29: Diameter: 0.0154\n",
      "  0%|          | 29/100000 [03:41<319:33:29, 11.51s/it]INFO:root:Customer 30: Diameter: 0.0099\n",
      "  0%|          | 30/100000 [03:53<326:54:04, 11.77s/it]INFO:root:Customer 31: Diameter: 0.0104\n",
      "  0%|          | 31/100000 [04:06<334:04:25, 12.03s/it]INFO:root:Customer 32: Diameter: 0.0057\n",
      "  0%|          | 32/100000 [04:19<342:34:39, 12.34s/it]INFO:root:Customer 33: Diameter: 0.0056\n",
      "  0%|          | 33/100000 [04:32<351:57:28, 12.67s/it]INFO:root:Customer 34: Diameter: 0.0066\n",
      "  0%|          | 34/100000 [04:46<358:52:10, 12.92s/it]INFO:root:Customer 35: Diameter: 0.0049\n",
      "  0%|          | 35/100000 [05:00<365:41:51, 13.17s/it]INFO:root:Customer 36: Diameter: 0.0024\n",
      "  0%|          | 36/100000 [05:14<374:19:39, 13.48s/it]INFO:root:Customer 37: Diameter: 0.0035\n",
      "  0%|          | 37/100000 [05:28<383:38:38, 13.82s/it]INFO:root:Customer 38: Diameter: 0.0012\n",
      "  0%|          | 38/100000 [05:44<394:38:33, 14.21s/it]INFO:root:Customer 39: Diameter: 0.0026\n",
      "  0%|          | 39/100000 [05:59<402:43:07, 14.50s/it]INFO:root:Customer 40: Diameter: 0.0020\n",
      "  0%|          | 40/100000 [06:14<407:20:27, 14.67s/it]INFO:root:Customer 41: Diameter: 0.0010\n",
      "  0%|          | 41/100000 [06:29<415:01:30, 14.95s/it]INFO:root:Customer 42: Diameter: 0.0008\n",
      "  0%|          | 42/100000 [06:45<421:22:01, 15.18s/it]INFO:root:Customer 43: Diameter: 0.0004\n",
      "  0%|          | 43/100000 [07:01<427:59:53, 15.41s/it]INFO:root:Exploration phase completed at customer 44.\n",
      "INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [1. 1. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.79176D+00    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.46413D-01    |proj g|=  3.89924D-01\n",
      "\n",
      "At iterate    2    f=  3.52838D-01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      2      4      5     0     2   0.000D+00   3.528D-01\n",
      "  F =  0.35283828155771779     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: mps\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [01:00<00:00, 8241.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.2684 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 2/50 | Loss: 1.2527 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 3/50 | Loss: 1.2499 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 4/50 | Loss: 1.2465 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 5/50 | Loss: 1.2425 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 6/50 | Loss: 1.2553 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 7/50 | Loss: 1.2400 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 8/50 | Loss: 1.2377 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 9/50 | Loss: 1.2357 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 10/50 | Loss: 1.2405 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 11/50 | Loss: 1.3282 | Avg Q-Value: 1.06\n",
      "INFO:root:Iter 12/50 | Loss: 1.3261 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 13/50 | Loss: 1.3249 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 14/50 | Loss: 1.3236 | Avg Q-Value: 1.13\n",
      "INFO:root:Iter 15/50 | Loss: 1.3237 | Avg Q-Value: 1.14\n",
      "INFO:root:Iter 16/50 | Loss: 1.3248 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 17/50 | Loss: 1.3230 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 18/50 | Loss: 1.3262 | Avg Q-Value: 1.12\n",
      "INFO:root:Iter 19/50 | Loss: 1.3220 | Avg Q-Value: 1.16\n",
      "INFO:root:Iter 20/50 | Loss: 1.3215 | Avg Q-Value: 1.16\n",
      "INFO:root:Iter 21/50 | Loss: 1.3305 | Avg Q-Value: 1.38\n",
      "INFO:root:Iter 22/50 | Loss: 1.3285 | Avg Q-Value: 1.45\n",
      "INFO:root:Iter 23/50 | Loss: 1.3287 | Avg Q-Value: 1.40\n",
      "INFO:root:Iter 24/50 | Loss: 1.3265 | Avg Q-Value: 1.42\n",
      "INFO:root:Iter 25/50 | Loss: 1.3258 | Avg Q-Value: 1.45\n",
      "INFO:root:Iter 26/50 | Loss: 1.3310 | Avg Q-Value: 1.45\n",
      "INFO:root:Iter 27/50 | Loss: 1.3311 | Avg Q-Value: 1.48\n",
      "INFO:root:Iter 28/50 | Loss: 1.3254 | Avg Q-Value: 1.43\n",
      "INFO:root:Iter 29/50 | Loss: 1.3234 | Avg Q-Value: 1.47\n",
      "INFO:root:Iter 30/50 | Loss: 1.3243 | Avg Q-Value: 1.47\n",
      "INFO:root:Iter 31/50 | Loss: 1.3436 | Avg Q-Value: 1.74\n",
      "INFO:root:Iter 32/50 | Loss: 1.3408 | Avg Q-Value: 1.76\n",
      "INFO:root:Iter 33/50 | Loss: 1.3384 | Avg Q-Value: 1.80\n",
      "INFO:root:Iter 34/50 | Loss: 1.3369 | Avg Q-Value: 1.74\n",
      "INFO:root:Iter 35/50 | Loss: 1.3372 | Avg Q-Value: 1.77\n",
      "INFO:root:Iter 36/50 | Loss: 1.3390 | Avg Q-Value: 1.74\n",
      "INFO:root:Iter 37/50 | Loss: 1.3365 | Avg Q-Value: 1.80\n",
      "INFO:root:Iter 38/50 | Loss: 1.3390 | Avg Q-Value: 1.78\n",
      "INFO:root:Iter 39/50 | Loss: 1.3364 | Avg Q-Value: 1.79\n",
      "INFO:root:Iter 40/50 | Loss: 1.3364 | Avg Q-Value: 1.73\n",
      "INFO:root:Iter 41/50 | Loss: 1.3220 | Avg Q-Value: 2.04\n",
      "INFO:root:Iter 42/50 | Loss: 1.3174 | Avg Q-Value: 2.07\n",
      "INFO:root:Iter 43/50 | Loss: 1.3180 | Avg Q-Value: 2.07\n",
      "INFO:root:Iter 44/50 | Loss: 1.3168 | Avg Q-Value: 2.05\n",
      "INFO:root:Iter 45/50 | Loss: 1.3170 | Avg Q-Value: 2.06\n",
      "INFO:root:Iter 46/50 | Loss: 1.3166 | Avg Q-Value: 2.10\n",
      "INFO:root:Iter 47/50 | Loss: 1.3188 | Avg Q-Value: 2.06\n",
      "INFO:root:Iter 48/50 | Loss: 1.3161 | Avg Q-Value: 2.07\n",
      "INFO:root:Iter 49/50 | Loss: 1.3157 | Avg Q-Value: 2.05\n",
      "INFO:root:Iter 50/50 | Loss: 1.3164 | Avg Q-Value: 2.09\n",
      "100%|██████████| 50/50 [1:11:44<00:00, 86.08s/it]\n",
      "INFO:root:Policy updated.\n",
      "  0%|          | 44/100000 [1:19:47<36663:23:53, 1320.46s/it]INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [1.    0.    0.515 1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.13130D+00    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  7.08112D+00    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  5.87814D+00    |proj g|=  6.40112D-01\n",
      "\n",
      "At iterate    3    f=  5.08174D+00    |proj g|=  6.93673D-02\n",
      "\n",
      "At iterate    4    f=  5.08010D+00    |proj g|=  3.02227D-02\n",
      "\n",
      "At iterate    5    f=  5.07971D+00    |proj g|=  6.92841D-04\n",
      "\n",
      "At iterate    6    f=  5.07971D+00    |proj g|=  7.14806D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      7     11     0     3   7.148D-06   5.080D+00\n",
      "  F =   5.0797125062345136     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: mps\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [02:38<00:00, 3149.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 8.9280 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 2/50 | Loss: 8.9126 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 3/50 | Loss: 8.9084 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 4/50 | Loss: 8.9035 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 5/50 | Loss: 8.9026 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 6/50 | Loss: 8.9035 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 7/50 | Loss: 8.8980 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 8/50 | Loss: 8.8968 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 9/50 | Loss: 9.5348 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 10/50 | Loss: 8.8939 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 11/50 | Loss: 8.9481 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 12/50 | Loss: 8.9458 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 13/50 | Loss: 8.9438 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 14/50 | Loss: 8.9435 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 15/50 | Loss: 8.9420 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 16/50 | Loss: 8.9408 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 17/50 | Loss: 8.9398 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 18/50 | Loss: 8.9404 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 19/50 | Loss: 8.9396 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 20/50 | Loss: 8.9383 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 21/50 | Loss: 8.9533 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 22/50 | Loss: 8.9489 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 23/50 | Loss: 8.9592 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 24/50 | Loss: 8.9478 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 25/50 | Loss: 8.9509 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 26/50 | Loss: 8.9475 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 27/50 | Loss: 8.9487 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 28/50 | Loss: 8.9486 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 29/50 | Loss: 8.9519 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 30/50 | Loss: 8.9457 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 31/50 | Loss: 8.9621 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 32/50 | Loss: 8.9583 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 33/50 | Loss: 8.9598 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 34/50 | Loss: 8.9582 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 35/50 | Loss: 8.9585 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 36/50 | Loss: 8.9583 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 37/50 | Loss: 8.9573 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 38/50 | Loss: 8.9635 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 39/50 | Loss: 8.9555 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 40/50 | Loss: 8.9569 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 41/50 | Loss: 8.9729 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 42/50 | Loss: 8.9695 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 43/50 | Loss: 8.9693 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 44/50 | Loss: 8.9690 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 45/50 | Loss: 8.9684 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 46/50 | Loss: 8.9701 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 47/50 | Loss: 8.9677 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 48/50 | Loss: 8.9687 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 49/50 | Loss: 8.9678 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 50/50 | Loss: 8.9673 | Avg Q-Value: 0.54\n",
      "100%|██████████| 50/50 [1:11:51<00:00, 86.23s/it]\n",
      "INFO:root:Policy updated.\n",
      "  0%|          | 327/100000 [2:34:18<467:10:50, 16.87s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 674/100000 [2:34:18<106:03:16,  3.84s/it]INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [0.356 0.    0.44  0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.82477D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.51120D+01    |proj g|=  4.79646D-01\n",
      "\n",
      "At iterate    2    f=  2.49098D+01    |proj g|=  6.12250D-01\n",
      "\n",
      "At iterate    3    f=  2.45175D+01    |proj g|=  4.99813D-01\n",
      "\n",
      "At iterate    4    f=  2.44816D+01    |proj g|=  2.08562D-01\n",
      "\n",
      "At iterate    5    f=  2.44763D+01    |proj g|=  9.41274D-02\n",
      "\n",
      "At iterate    6    f=  2.44753D+01    |proj g|=  4.46977D-02\n",
      "\n",
      "At iterate    7    f=  2.44744D+01    |proj g|=  2.61079D-02\n",
      "\n",
      "At iterate    8    f=  2.44743D+01    |proj g|=  7.52670D-03\n",
      "\n",
      "At iterate    9    f=  2.44743D+01    |proj g|=  8.63931D-04\n",
      "\n",
      "At iterate   10    f=  2.44743D+01    |proj g|=  3.20102D-04\n",
      "\n",
      "At iterate   11    f=  2.44743D+01    |proj g|=  7.56513D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     11     13     15     0     1   7.565D-05   2.447D+01\n",
      "  F =   24.474317600971563     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: mps\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [03:20<00:00, 2488.46it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8726 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 2/50 | Loss: 0.8507 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 3/50 | Loss: 0.8443 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 4/50 | Loss: 0.8409 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 5/50 | Loss: 0.8435 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 6/50 | Loss: 0.8368 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 7/50 | Loss: 0.8362 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 8/50 | Loss: 0.8340 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 9/50 | Loss: 0.8332 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 10/50 | Loss: 0.8309 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 11/50 | Loss: 0.9138 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 12/50 | Loss: 0.9135 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 13/50 | Loss: 0.9113 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 14/50 | Loss: 0.9102 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 15/50 | Loss: 0.9099 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 16/50 | Loss: 0.9090 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 17/50 | Loss: 0.9079 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 18/50 | Loss: 0.9087 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 19/50 | Loss: 0.9078 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 20/50 | Loss: 0.9062 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 21/50 | Loss: 0.9137 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 22/50 | Loss: 0.9103 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 23/50 | Loss: 0.9105 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 24/50 | Loss: 0.9106 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 25/50 | Loss: 0.9097 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 26/50 | Loss: 0.9103 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 27/50 | Loss: 0.9086 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 28/50 | Loss: 0.9144 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 29/50 | Loss: 0.9209 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 30/50 | Loss: 0.9075 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 31/50 | Loss: 0.9204 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 32/50 | Loss: 0.9194 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 33/50 | Loss: 0.9184 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 34/50 | Loss: 0.9173 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 35/50 | Loss: 0.9178 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 36/50 | Loss: 0.9165 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 37/50 | Loss: 0.9186 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 38/50 | Loss: 0.9177 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 39/50 | Loss: 0.9174 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 40/50 | Loss: 0.9160 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 41/50 | Loss: 0.9179 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 42/50 | Loss: 0.9269 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 43/50 | Loss: 0.9177 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 44/50 | Loss: 0.9159 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 45/50 | Loss: 0.9158 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 46/50 | Loss: 0.9159 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 47/50 | Loss: 0.9158 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 48/50 | Loss: 0.9156 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 49/50 | Loss: 0.9162 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 50/50 | Loss: 0.9168 | Avg Q-Value: 0.64\n",
      "100%|██████████| 50/50 [1:11:42<00:00, 86.05s/it]\n",
      "INFO:root:Policy updated.\n",
      "  1%|          | 876/100000 [3:49:22<312:29:09, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 972/100000 [3:49:22<221:03:22,  8.04s/it]INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [0.369 0.    0.479 0.661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.64943D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.06775D+01    |proj g|=  4.21109D-01\n",
      "\n",
      "At iterate    2    f=  4.05697D+01    |proj g|=  5.57755D-01\n",
      "\n",
      "At iterate    3    f=  4.02489D+01    |proj g|=  5.80325D-01\n",
      "\n",
      "At iterate    4    f=  4.02064D+01    |proj g|=  3.17210D-01\n",
      "\n",
      "At iterate    5    f=  4.01946D+01    |proj g|=  7.09349D-02\n",
      "\n",
      "At iterate    6    f=  4.01941D+01    |proj g|=  6.74101D-02\n",
      "\n",
      "At iterate    7    f=  4.01934D+01    |proj g|=  1.73089D-02\n",
      "\n",
      "At iterate    8    f=  4.01934D+01    |proj g|=  9.18220D-04\n",
      "\n",
      "At iterate    9    f=  4.01934D+01    |proj g|=  6.88940D-05\n",
      "\n",
      "At iterate   10    f=  4.01934D+01    |proj g|=  2.11172D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     10     12     14     0     1   2.112D-05   4.019D+01\n",
      "  F =   40.193354176780545     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: mps\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [08:16<00:00, 1006.58it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.2947 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 2/50 | Loss: 1.2884 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 3/50 | Loss: 1.4918 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 4/50 | Loss: 1.2702 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 5/50 | Loss: 1.2675 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 6/50 | Loss: 1.2671 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 7/50 | Loss: 1.2634 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 8/50 | Loss: 1.2618 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 9/50 | Loss: 1.2615 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 10/50 | Loss: 1.2612 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 11/50 | Loss: 1.3317 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 12/50 | Loss: 1.3293 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 13/50 | Loss: 1.3281 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 14/50 | Loss: 1.3275 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 15/50 | Loss: 1.3260 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 16/50 | Loss: 1.3285 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 17/50 | Loss: 1.3255 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 18/50 | Loss: 1.3245 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 19/50 | Loss: 1.3241 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 20/50 | Loss: 1.3228 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 21/50 | Loss: 1.3468 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 22/50 | Loss: 1.3495 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 23/50 | Loss: 1.3419 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 24/50 | Loss: 1.3417 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 25/50 | Loss: 1.3412 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 26/50 | Loss: 1.3406 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 27/50 | Loss: 1.3414 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 28/50 | Loss: 1.3439 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 29/50 | Loss: 1.3386 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 30/50 | Loss: 1.3390 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 31/50 | Loss: 1.3575 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 32/50 | Loss: 1.3499 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 33/50 | Loss: 1.3526 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 34/50 | Loss: 1.3525 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 35/50 | Loss: 1.3496 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 36/50 | Loss: 1.3492 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 37/50 | Loss: 1.3521 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 38/50 | Loss: 1.3614 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 39/50 | Loss: 1.3508 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 40/50 | Loss: 1.3501 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 41/50 | Loss: 1.3480 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 42/50 | Loss: 1.3438 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 43/50 | Loss: 1.3446 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 44/50 | Loss: 1.3443 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 45/50 | Loss: 1.3456 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 46/50 | Loss: 1.3430 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 47/50 | Loss: 1.3424 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 48/50 | Loss: 1.3467 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 49/50 | Loss: 1.3429 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 50/50 | Loss: 1.3437 | Avg Q-Value: 0.39\n",
      "100%|██████████| 50/50 [1:11:14<00:00, 85.50s/it]\n",
      "INFO:root:Policy updated.\n",
      "  1%|          | 1165/100000 [5:08:55<389:44:40, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1267/100000 [5:08:55<269:13:02,  9.82s/it]INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [0.225 0.    0.613 0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.72788D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.03604D+01    |proj g|=  4.55986D-01\n",
      "\n",
      "At iterate    2    f=  6.02604D+01    |proj g|=  5.96495D-01\n",
      "\n",
      "At iterate    3    f=  5.99737D+01    |proj g|=  4.87697D-01\n",
      "\n",
      "At iterate    4    f=  5.99280D+01    |proj g|=  3.13049D-01\n",
      "\n",
      "At iterate    5    f=  5.99212D+01    |proj g|=  3.32861D-02\n",
      "\n",
      "At iterate    6    f=  5.99211D+01    |proj g|=  2.53782D-02\n",
      "\n",
      "At iterate    7    f=  5.99210D+01    |proj g|=  1.60910D-03\n",
      "\n",
      "At iterate    8    f=  5.99210D+01    |proj g|=  1.43592D-04\n",
      "\n",
      "At iterate    9    f=  5.99210D+01    |proj g|=  2.78381D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     11     12     0     0   2.784D-06   5.992D+01\n",
      "  F =   59.921014570126886     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: mps\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [06:11<00:00, 1346.29it/s]t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8905 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 2/50 | Loss: 0.8850 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 3/50 | Loss: 0.8719 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 4/50 | Loss: 0.8690 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 5/50 | Loss: 0.8672 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 6/50 | Loss: 0.8654 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 7/50 | Loss: 0.8650 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 8/50 | Loss: 0.8668 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 9/50 | Loss: 0.8689 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 10/50 | Loss: 0.8599 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 11/50 | Loss: 0.9444 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 12/50 | Loss: 0.9430 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 13/50 | Loss: 0.9435 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 14/50 | Loss: 0.9426 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 15/50 | Loss: 0.9404 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 16/50 | Loss: 0.9390 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 17/50 | Loss: 0.9379 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 18/50 | Loss: 0.9374 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 19/50 | Loss: 0.9375 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 20/50 | Loss: 0.9357 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 21/50 | Loss: 0.9515 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 22/50 | Loss: 0.9450 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 23/50 | Loss: 0.9479 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 24/50 | Loss: 0.9438 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 25/50 | Loss: 0.9816 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 26/50 | Loss: 0.9448 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 27/50 | Loss: 0.9401 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 28/50 | Loss: 0.9410 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 29/50 | Loss: 0.9405 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 30/50 | Loss: 0.9391 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 31/50 | Loss: 0.9472 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 32/50 | Loss: 0.9464 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 33/50 | Loss: 0.9439 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 34/50 | Loss: 0.9442 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 35/50 | Loss: 0.9457 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 36/50 | Loss: 0.9437 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 37/50 | Loss: 0.9441 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 38/50 | Loss: 0.9430 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 39/50 | Loss: 0.9481 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 40/50 | Loss: 0.9463 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 41/50 | Loss: 0.9588 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 42/50 | Loss: 0.9664 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 43/50 | Loss: 0.9571 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 44/50 | Loss: 0.9570 | Avg Q-Value: 0.59\n",
      " 88%|████████▊ | 44/50 [1:03:46<08:41, 86.97s/it]\n",
      "  1%|▏         | 1350/100000 [6:18:53<461:27:25, 16.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# simulator.projected_volume_learner.is_terminated = True\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simulation_data \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_customers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CUSTOMERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m degradation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mdegradation_history)\n\u001b[1;32m      4\u001b[0m simulation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[0;32m~/Desktop/degradable/simulation.py:297\u001b[0m, in \u001b[0;36mSimulator.run\u001b[0;34m(self, num_customers)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# --- Check if policy update is needed ---\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_exploration_done \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreakdowns_since_last_update \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_update_threshold:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[0;32m~/Desktop/degradable/simulation.py:148\u001b[0m, in \u001b[0;36mSimulator._update_policy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m u_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojected_volume_learner\u001b[38;5;241m.\u001b[39mget_estimate()\n\u001b[1;32m    140\u001b[0m dp_agent \u001b[38;5;241m=\u001b[39m DPAgent(\n\u001b[1;32m    141\u001b[0m     d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md,\n\u001b[1;32m    142\u001b[0m     u_hat\u001b[38;5;241m=\u001b[39mu_hat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp_params\n\u001b[1;32m    147\u001b[0m )\n\u001b[0;32m--> 148\u001b[0m \u001b[43mdp_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_hyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_policy \u001b[38;5;241m=\u001b[39m dp_agent\u001b[38;5;241m.\u001b[39mget_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_params)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreakdowns_since_last_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Reset the counter\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/degradable/policy.py:267\u001b[0m, in \u001b[0;36mDPAgent.train\u001b[0;34m(self, num_iterations, dataset_size, batch_size)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    266\u001b[0m     q_next_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network(ns_batch)\n\u001b[0;32m--> 267\u001b[0m     max_q_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_max_q_for_valid_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_next_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     target_q \u001b[38;5;241m=\u001b[39m r_batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m max_q_next\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# --- Update the Q-Network ---\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/degradable/policy.py:222\u001b[0m, in \u001b[0;36mDPAgent._get_max_q_for_valid_actions\u001b[0;34m(self, states_tensor, q_values_tensor)\u001b[0m\n\u001b[1;32m    219\u001b[0m max_q_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(states_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(states_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 222\u001b[0m     phase \u001b[38;5;241m=\u001b[39m \u001b[43mstates_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:  \u001b[38;5;66;03m# Arrival\u001b[39;00m\n\u001b[1;32m    224\u001b[0m         valid_actions_q \u001b[38;5;241m=\u001b[39m q_values_tensor[i, :\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# simulator.projected_volume_learner.is_terminated = True\n",
    "simulation_data = simulator.run(num_customers=NUM_CUSTOMERS)\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "simulation_df = pd.DataFrame(simulator.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0fff9",
   "metadata": {},
   "source": [
    "## Training policy under perfect information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8793230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Generating 5000000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000000/5000000 [00:42<00:00, 117220.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from policy import DPAgent\n",
    "\n",
    "class PerfectDegradationLearner:\n",
    "    def __init__(self, d, theta_true, hazard_model):\n",
    "        self.d = d\n",
    "        self.theta_true = theta_true\n",
    "        self.hazard_model = hazard_model  # Placeholder, not used\n",
    "        \n",
    "    def get_theta(self):\n",
    "        return self.theta_true\n",
    "    \n",
    "    def cum_baseline(self, t):\n",
    "        return self.hazard_model.Lambda_0(t)\n",
    "    \n",
    "    def inverse_cum_baseline(self, u):\n",
    "        return self.hazard_model.Lambda_0_inverse(u)\n",
    "    \n",
    "perfect_degradation_learner = PerfectDegradationLearner(\n",
    "    d=D, \n",
    "    theta_true=THETA_TRUE,\n",
    "    hazard_model=usage_exp_hazard_model,\n",
    ")\n",
    "perfect_dpagent = DPAgent(\n",
    "    d=D,\n",
    "    u_hat=UTILITY_TRUE,\n",
    "    time_normalize=True,\n",
    "    degradation_learner=perfect_degradation_learner,\n",
    "    customer_generator=customer_gen,\n",
    "    params=mdp_params,\n",
    ")\n",
    "\n",
    "perfect_dpagent.train(\n",
    "    num_iterations=50,\n",
    "    dataset_size=5000000,\n",
    "    batch_size=1024\n",
    ")\n",
    "\n",
    "perfect_policy = perfect_dpagent.get_policy(\n",
    "    {'type': 'greedy'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e64b25",
   "metadata": {},
   "source": [
    "### Debugging: Look at experience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent\n",
    "\n",
    "print(simulator.projected_volume_learner.get_estimate())\n",
    "print(UTILITY_TRUE)\n",
    "\n",
    "dp_agent = DPAgent(\n",
    "    d=simulator.d,\n",
    "    u_hat=simulator.projected_volume_learner.get_estimate(),\n",
    "    time_normalize=simulator.time_normalize,\n",
    "    degradation_learner=simulator.degradation_learner,\n",
    "    customer_generator=simulator.customer_generator,\n",
    "    params=simulator.mdp_params\n",
    ")\n",
    "\n",
    "dataset = dp_agent.experience_generator.generate(500)\n",
    "\n",
    "for data in dataset:\n",
    "    state, action, reward, next_state = data\n",
    "    print(\"State:\", state.round(3))\n",
    "    print(\"Action:\", dp_agent.experience_generator.ACTION_MAP[action])\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Next State:\", next_state.round(3))\n",
    "    print(\"-----\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a07cf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.72788D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.03604D+01    |proj g|=  4.55986D-01\n",
      "\n",
      "At iterate    2    f=  6.02604D+01    |proj g|=  5.96495D-01\n",
      "\n",
      "At iterate    3    f=  5.99737D+01    |proj g|=  4.87697D-01\n",
      "\n",
      "At iterate    4    f=  5.99280D+01    |proj g|=  3.13049D-01\n",
      "\n",
      "At iterate    5    f=  5.99212D+01    |proj g|=  3.32861D-02\n",
      "\n",
      "At iterate    6    f=  5.99211D+01    |proj g|=  2.53782D-02\n",
      "\n",
      "At iterate    7    f=  5.99210D+01    |proj g|=  1.60910D-03\n",
      "\n",
      "At iterate    8    f=  5.99210D+01    |proj g|=  1.43592D-04\n",
      "\n",
      "At iterate    9    f=  5.99210D+01    |proj g|=  2.78381D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     11     12     0     0   2.784D-06   5.992D+01\n",
      "  F =   59.921014570126886     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22545111, 0.00038501, 0.61250084, 0.59371561])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "degradation_learner.fit(degradation_df)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f90ec4",
   "metadata": {},
   "source": [
    "Testing Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "X_i = df.loc[i, 'sum_of_contexts_after']\n",
    "I_i = 3 # df.loc[i, '']\n",
    "x_i = df.loc[i+1, 'customer_context']\n",
    "T_i = df.loc[i+1, 'rental_duration']\n",
    "\n",
    "arrival_state = np.concatenate([\n",
    "    X_i,\n",
    "    x_i,\n",
    "    [T_i, I_i, 0.0]\n",
    "])\n",
    "action_arrival = optimal_policy(arrival_state)\n",
    "action_map = {0: 'Give Max Acceptable Price', 1: 'Shutdown'}\n",
    "print(f\"Sample Arrival State. Optimal Action: {action_map[action_arrival]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Departure State\n",
    "departure_state = np.concatenate([\n",
    "    X_i+x_i*10, \n",
    "    np.zeros(D), \n",
    "    [0.0, I_i, 1.0]\n",
    "])\n",
    "action_departure = optimal_policy(departure_state)\n",
    "action_map = {2: 'Replace Machine', 3: 'Do Not Replace'}\n",
    "print(f\"Sample Departure State. Optimal Action: {action_map[action_departure]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
