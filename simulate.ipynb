{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1bf8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import torch\n",
    "\n",
    "from policy import DPAgent\n",
    "from simulation import Simulator, CustomerGenerator\n",
    "from hazard_models import ExponentialHazard\n",
    "from utility_learner import ProjectedVolumeLearner, diam\n",
    "from degradation_learner import DegradationLearner\n",
    "\n",
    "from utils import unit_ball_rejection_sample, correct_signs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e08dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Sampling Functions ---\n",
    "# def context_sampler() -> np.ndarray:\n",
    "#     \"\"\"Samples a customer's context vector from a uniform distribution.\"\"\"\n",
    "#     return np.random.uniform(low=0.0, high=1.0, size=D)\n",
    "\n",
    "def context_sampler() -> np.ndarray:\n",
    "    \"\"\"Samples a customer's context vector uniformly from the unit ball.\"\"\"\n",
    "    return np.abs(unit_ball_rejection_sample(D))\n",
    "\n",
    "def rental_sampler() -> float:\n",
    "    \"\"\"Samples a customer's desired rental duration from an exponential distribution.\"\"\"\n",
    "    return np.random.exponential(scale=10.0)\n",
    "\n",
    "def interarrival_sampler() -> float:\n",
    "    \"\"\"Samples the time until the next customer arrives.\"\"\"\n",
    "    return np.random.exponential(scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cc2c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulation Configuration ---\n",
    "D = 4                                  # Dimension of context vectors\n",
    "LAMBDA_VAL = 0.001                     # Baseline hazard constant\n",
    "NUM_CUSTOMERS = 20000                   # Total number of customers to simulate, i.e. T\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(41)\n",
    "\n",
    "# Ground truth vectors\n",
    "THETA_TRUE = np.array([0.5, 0.2, 0.4, 0.3])#$, 0.4])    # For degradation\n",
    "UTILITY_TRUE = np.array([0.12450167, 0.40850869, 0.43930126, 0.71356037])\n",
    "\n",
    "# context_sampler()  # For customer's willingness to pay\n",
    "\n",
    "# --- Machine's Pricing Vector 'r' ---\n",
    "# This is a fallback pricing vector, when we don't feed u_hat to calculate_price\n",
    "PRICING_R = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e600551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_exp_hazard_model = ExponentialHazard(lambda_val=LAMBDA_VAL)\n",
    "# spontaneous_exp_hazard_model = None # ExponentialHazard(lambda_val=0.01)\n",
    "\n",
    "customer_gen = CustomerGenerator(\n",
    "    d=D,\n",
    "    context_sampler=context_sampler,\n",
    "    rental_sampler=rental_sampler,\n",
    "    interarrival_sampler=interarrival_sampler\n",
    ")\n",
    "\n",
    "centroid_params = {\n",
    "    # 'num_samples': 2000,\n",
    "    # 'thin': None,\n",
    "    # 'burn_in': 500 * D ** 2,\n",
    "    # 'tol': 1e-4,\n",
    "    # 'rho_target': 0.01\n",
    "}\n",
    "\n",
    "termination_rule = lambda diameter: diameter < 0.0001  # Example custom termination rule\n",
    "\n",
    "projected_volume_learner = ProjectedVolumeLearner(\n",
    "    T=NUM_CUSTOMERS, \n",
    "    d=D, \n",
    "    centroid_params=centroid_params,\n",
    "    incentive_constant=1.1,\n",
    "    termination_rule=termination_rule,\n",
    ")\n",
    "\n",
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.99,             # Discount factor\n",
    "    'learning_rate': 1e-3,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "training_hyperparams = {\n",
    "    'num_iterations': 50, # Number of training iterations per policy update\n",
    "    'dataset_size': 50000,      # Number of transitions to generate for the offline dataset\n",
    "    'batch_size': 2048           # Batch size for training\n",
    "}\n",
    "\n",
    "policy_params = {\n",
    "    'type': 'softmax',\n",
    "    'tau': 1.0,\n",
    "    'epsilon': 0.1,\n",
    "}\n",
    "\n",
    "# Instantiate the Simulator with the new parameters\n",
    "simulator = Simulator(\n",
    "    d=D,\n",
    "    T=NUM_CUSTOMERS,\n",
    "    \n",
    "    theta_true=THETA_TRUE,\n",
    "    utility_true=UTILITY_TRUE,\n",
    "    pricing_r=PRICING_R,\n",
    "    \n",
    "    usage_hazard_model=usage_exp_hazard_model,\n",
    "    customer_generator=customer_gen,\n",
    "    projected_volume_learner=projected_volume_learner,  # Use default ProjectedVolumeLearner\n",
    "    \n",
    "    mdp_params=mdp_params,\n",
    "    training_hyperparams=training_hyperparams,\n",
    "    policy_params=policy_params,\n",
    "    policy_update_threshold=5,\n",
    "    time_normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c192729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting simulation for 20000 customers...\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]INFO:root:Customer 1: Diameter: 1.0024\n",
      "  0%|          | 1/20000 [00:06<35:51:23,  6.45s/it]INFO:root:Customer 2: Diameter: 0.7409\n",
      "  0%|          | 2/20000 [00:13<38:25:48,  6.92s/it]INFO:root:Customer 3: Diameter: 0.5836\n",
      "  0%|          | 3/20000 [00:21<40:57:03,  7.37s/it]INFO:root:Customer 4: Diameter: 0.5709\n",
      "  0%|          | 4/20000 [00:30<44:07:58,  7.95s/it]INFO:root:Customer 5: Diameter: 0.3622\n",
      "  0%|          | 5/20000 [00:39<47:11:10,  8.50s/it]INFO:root:Customer 6: Diameter: 0.2571\n",
      "  0%|          | 6/20000 [00:50<50:46:06,  9.14s/it]INFO:root:Customer 7: Diameter: 0.4223\n",
      "  0%|          | 7/20000 [01:01<54:25:53,  9.80s/it]INFO:root:Customer 8: Diameter: 0.5478\n",
      "  0%|          | 8/20000 [01:13<58:54:43, 10.61s/it]INFO:root:Customer 9: Diameter: 0.5527\n",
      "  0%|          | 9/20000 [01:25<61:28:30, 11.07s/it]INFO:root:Customer 10: Diameter: 0.1374\n",
      "  0%|          | 10/20000 [01:39<66:36:11, 11.99s/it]INFO:root:Customer 11: Diameter: 0.1915\n",
      "  0%|          | 11/20000 [01:52<67:38:42, 12.18s/it]INFO:root:Customer 12: Diameter: 0.1684\n",
      "  0%|          | 12/20000 [02:05<69:40:58, 12.55s/it]INFO:root:Customer 13: Diameter: 0.1545\n",
      "  0%|          | 13/20000 [02:20<72:48:30, 13.11s/it]INFO:root:Customer 14: Diameter: 0.1614\n",
      "  0%|          | 14/20000 [02:35<76:01:49, 13.70s/it]INFO:root:Customer 15: Diameter: 0.0995\n",
      "  0%|          | 15/20000 [02:50<78:43:47, 14.18s/it]INFO:root:Customer 16: Diameter: 0.0652\n",
      "  0%|          | 16/20000 [03:05<80:26:26, 14.49s/it]INFO:root:Customer 17: Diameter: 0.1168\n",
      "  0%|          | 17/20000 [03:22<83:11:25, 14.99s/it]INFO:root:Customer 18: Diameter: 0.0420\n",
      "  0%|          | 18/20000 [03:39<87:19:54, 15.73s/it]INFO:root:Customer 19: Diameter: 0.0390\n",
      "  0%|          | 19/20000 [03:57<91:35:15, 16.50s/it]INFO:root:Customer 20: Diameter: 0.0256\n",
      "  0%|          | 20/20000 [04:16<94:56:34, 17.11s/it]INFO:root:Customer 21: Diameter: 0.0461\n",
      "  0%|          | 21/20000 [04:34<97:29:26, 17.57s/it]INFO:root:Customer 22: Diameter: 0.0293\n",
      "  0%|          | 22/20000 [04:53<99:47:53, 17.98s/it]INFO:root:Customer 23: Diameter: 0.0376\n",
      "  0%|          | 23/20000 [05:14<104:33:29, 18.84s/it]INFO:root:Customer 24: Diameter: 0.0294\n",
      "  0%|          | 24/20000 [05:36<109:47:17, 19.79s/it]INFO:root:Customer 25: Diameter: 0.0228\n",
      "  0%|          | 25/20000 [05:58<112:32:42, 20.28s/it]INFO:root:Customer 26: Diameter: 0.0259\n",
      "  0%|          | 26/20000 [06:19<114:34:32, 20.65s/it]INFO:root:Customer 27: Diameter: 0.0090\n",
      "  0%|          | 27/20000 [06:41<116:53:32, 21.07s/it]INFO:root:Customer 28: Diameter: 0.0173\n",
      "  0%|          | 28/20000 [07:04<119:58:29, 21.63s/it]INFO:root:Customer 29: Diameter: 0.0097\n",
      "  0%|          | 29/20000 [07:29<124:41:31, 22.48s/it]INFO:root:Customer 30: Diameter: 0.0067\n",
      "  0%|          | 30/20000 [07:55<130:32:24, 23.53s/it]INFO:root:Customer 31: Diameter: 0.0095\n",
      "  0%|          | 31/20000 [08:21<135:15:31, 24.38s/it]INFO:root:Customer 32: Diameter: 0.0052\n",
      "  0%|          | 32/20000 [08:48<140:07:09, 25.26s/it]INFO:root:Customer 33: Diameter: 0.0056\n",
      "  0%|          | 33/20000 [09:15<142:25:46, 25.68s/it]INFO:root:Customer 34: Diameter: 0.0025\n",
      "  0%|          | 34/20000 [09:43<146:06:44, 26.35s/it]INFO:root:Customer 35: Diameter: 0.0031\n",
      "  0%|          | 35/20000 [10:11<149:29:52, 26.96s/it]INFO:root:Customer 36: Diameter: 0.0021\n",
      "  0%|          | 36/20000 [10:40<151:54:46, 27.39s/it]INFO:root:Customer 37: Diameter: 0.0025\n",
      "  0%|          | 37/20000 [11:09<154:46:01, 27.91s/it]INFO:root:Customer 38: Diameter: 0.0036\n",
      "  0%|          | 38/20000 [11:38<156:19:48, 28.19s/it]INFO:root:Customer 39: Diameter: 0.0026\n",
      "  0%|          | 39/20000 [12:09<161:10:21, 29.07s/it]INFO:root:Customer 40: Diameter: 0.0020\n",
      "  0%|          | 40/20000 [12:42<167:29:27, 30.21s/it]INFO:root:Customer 41: Diameter: 0.0011\n",
      "  0%|          | 41/20000 [13:14<170:27:27, 30.75s/it]INFO:root:Customer 42: Diameter: 0.0018\n",
      "  0%|          | 42/20000 [13:47<174:15:57, 31.43s/it]INFO:root:Customer 43: Diameter: 0.0004\n",
      "  0%|          | 43/20000 [14:24<183:26:37, 33.09s/it]INFO:root:Customer 44: Diameter: 0.0005\n",
      "  0%|          | 44/20000 [14:57<184:03:27, 33.20s/it]INFO:root:Customer 45: Diameter: 0.0004\n",
      "  0%|          | 45/20000 [15:34<189:25:54, 34.17s/it]INFO:root:Customer 46: Diameter: 0.0010\n",
      "  0%|          | 46/20000 [16:07<188:20:27, 33.98s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 47: Diameter: 0.0006\n",
      "  0%|          | 47/20000 [16:42<190:27:24, 34.36s/it]INFO:root:Customer 48: Diameter: 0.0004\n",
      "  0%|          | 48/20000 [17:18<192:59:27, 34.82s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 49: Diameter: 0.0002\n",
      "  0%|          | 49/20000 [17:53<193:43:37, 34.96s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 50: Diameter: 0.0004\n",
      "  0%|          | 50/20000 [18:29<195:24:54, 35.26s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 51: Diameter: 0.0002\n",
      "  0%|          | 51/20000 [19:09<202:25:38, 36.53s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 52: Diameter: 0.0002\n",
      "  0%|          | 52/20000 [19:49<208:55:42, 37.71s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 53: Diameter: 0.0001\n",
      "  0%|          | 53/20000 [20:28<211:09:55, 38.11s/it]INFO:root:Exploration phase completed at customer 54.\n",
      "INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.79176D+00    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.89305D-02    |proj g|=  4.29010D-02\n",
      "\n",
      "At iterate    2    f=  4.10146D-02    |proj g|=  2.48911D-02\n",
      "\n",
      "At iterate    3    f=  3.68035D-02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      3      5      6     0     4   0.000D+00   3.680D-02\n",
      "  F =   3.6803478648273824E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:21<00:00, 2345.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 2.5282 | Avg Q-Value: 0.05\n",
      "INFO:root:Iter 2/50 | Loss: 2.4871 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 3/50 | Loss: 2.4116 | Avg Q-Value: -0.08\n",
      "INFO:root:Iter 4/50 | Loss: 2.3560 | Avg Q-Value: -0.09\n",
      "INFO:root:Iter 5/50 | Loss: 2.3425 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 6/50 | Loss: 2.3478 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 7/50 | Loss: 2.3484 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 8/50 | Loss: 2.3326 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 9/50 | Loss: 2.3276 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 10/50 | Loss: 2.3236 | Avg Q-Value: -0.00\n",
      "INFO:root:Iter 11/50 | Loss: 2.3659 | Avg Q-Value: 0.05\n",
      "INFO:root:Iter 12/50 | Loss: 2.2990 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 13/50 | Loss: 2.2918 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 14/50 | Loss: 2.2909 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 15/50 | Loss: 2.2843 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 16/50 | Loss: 2.2879 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 17/50 | Loss: 2.2789 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 18/50 | Loss: 2.2780 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 19/50 | Loss: 2.2935 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 20/50 | Loss: 2.2763 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 21/50 | Loss: 2.4059 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 22/50 | Loss: 2.4452 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 23/50 | Loss: 3.5415 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 24/50 | Loss: 2.3166 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 25/50 | Loss: 2.3080 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 26/50 | Loss: 2.3053 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 27/50 | Loss: 2.3057 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 28/50 | Loss: 2.3121 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 29/50 | Loss: 2.3085 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 30/50 | Loss: 2.3235 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 31/50 | Loss: 2.4371 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 32/50 | Loss: 2.3678 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 33/50 | Loss: 2.3054 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 34/50 | Loss: 2.4378 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 35/50 | Loss: 2.3159 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 36/50 | Loss: 3.5492 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 37/50 | Loss: 2.3080 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 38/50 | Loss: 2.3292 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 39/50 | Loss: 2.2959 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 40/50 | Loss: 2.3009 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 41/50 | Loss: 2.5020 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 42/50 | Loss: 2.3396 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 43/50 | Loss: 2.3382 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 44/50 | Loss: 2.3151 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 45/50 | Loss: 2.3175 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 46/50 | Loss: 2.3169 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 47/50 | Loss: 2.3101 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 48/50 | Loss: 2.3037 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 49/50 | Loss: 2.3043 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 50/50 | Loss: 2.3040 | Avg Q-Value: 0.25\n",
      "100%|██████████| 50/50 [04:23<00:00,  5.27s/it]\n",
      "INFO:root:Policy updated.\n",
      "  1%|          | 226/20000 [25:14<8:15:13,  1.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 506/20000 [25:14<2:10:49,  2.48it/s]INFO:root:Updating optimal policy...\n",
      "\n",
      " Nonpositive definiteness in Cholesky factorization in formk;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "INFO:root:Theta updated. New theta_hat: [0.135 0.092 1.    1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.80731D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.27804D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  1.21919D+01    |proj g|=  7.36337D-01\n",
      "\n",
      "At iterate    3    f=  1.15689D+01    |proj g|=  3.05766D-01\n",
      "\n",
      "At iterate    4    f=  1.15382D+01    |proj g|=  7.35209D-03\n",
      "\n",
      "At iterate    5    f=  1.15382D+01    |proj g|=  5.18057D-03\n",
      "\n",
      "At iterate    6    f=  1.15381D+01    |proj g|=  7.58997D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8     12     0     2   7.590D-06   1.154D+01\n",
      "  F =   11.538142027495908     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:15<00:00, 3153.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 506/20000 [25:33<2:10:49,  2.48it/s]INFO:root:Iter 1/50 | Loss: 1.5778 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 2/50 | Loss: 1.4873 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 3/50 | Loss: 1.4772 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 4/50 | Loss: 1.4667 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 5/50 | Loss: 1.4580 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 6/50 | Loss: 1.4583 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 7/50 | Loss: 1.4578 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 8/50 | Loss: 1.4653 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 9/50 | Loss: 1.4483 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 10/50 | Loss: 1.4550 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 11/50 | Loss: 1.5109 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 12/50 | Loss: 1.4283 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 13/50 | Loss: 1.4221 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 14/50 | Loss: 1.4147 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 15/50 | Loss: 1.4114 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 16/50 | Loss: 1.4216 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 17/50 | Loss: 1.4099 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 18/50 | Loss: 1.4120 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 19/50 | Loss: 1.4119 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 20/50 | Loss: 1.4155 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 21/50 | Loss: 1.5024 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 22/50 | Loss: 1.4300 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 23/50 | Loss: 1.4195 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 24/50 | Loss: 1.4160 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 25/50 | Loss: 1.4161 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 26/50 | Loss: 1.4196 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 27/50 | Loss: 1.4166 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 28/50 | Loss: 1.4216 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 29/50 | Loss: 1.4126 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 30/50 | Loss: 1.4132 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 31/50 | Loss: 1.5018 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 32/50 | Loss: 1.4336 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 33/50 | Loss: 1.4308 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 34/50 | Loss: 1.4224 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 35/50 | Loss: 1.4244 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 36/50 | Loss: 2.5643 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 37/50 | Loss: 1.4215 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 38/50 | Loss: 1.4246 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 39/50 | Loss: 1.4223 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 40/50 | Loss: 1.4243 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 41/50 | Loss: 1.5096 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 42/50 | Loss: 1.4343 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 43/50 | Loss: 1.4272 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 44/50 | Loss: 1.4286 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 45/50 | Loss: 1.4317 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 46/50 | Loss: 1.4211 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 47/50 | Loss: 1.4237 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 48/50 | Loss: 1.4223 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 49/50 | Loss: 1.4290 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 50/50 | Loss: 1.4204 | Avg Q-Value: 0.64\n",
      "100%|██████████| 50/50 [04:18<00:00,  5.16s/it]\n",
      "INFO:root:Policy updated.\n",
      "  3%|▎         | 596/20000 [29:48<6:15:46,  1.16s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.59650D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.36901D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  2.30034D+01    |proj g|=  7.83661D-01\n",
      "\n",
      "At iterate    3    f=  2.26476D+01    |proj g|=  5.81307D-01\n",
      "\n",
      "At iterate    4    f=  2.25912D+01    |proj g|=  1.68389D-01\n",
      "\n",
      "At iterate    5    f=  2.25883D+01    |proj g|=  5.90243D-02\n",
      "\n",
      "At iterate    6    f=  2.25871D+01    |proj g|=  3.71692D-02\n",
      "\n",
      "At iterate    7    f=  2.25868D+01    |proj g|=  9.69864D-03\n",
      "\n",
      "At iterate    8    f=  2.25868D+01    |proj g|=  2.62560D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.403 0.773 0.805 1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  2.25868D+01    |proj g|=  5.03904D-04\n",
      "\n",
      "At iterate   10    f=  2.25868D+01    |proj g|=  1.65401D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     10     11     13     0     1   1.654D-05   2.259D+01\n",
      "  F =   22.586794637940265     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:33<00:00, 1502.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.2160 | Avg Q-Value: -0.06\n",
      "INFO:root:Iter 2/50 | Loss: 1.1500 | Avg Q-Value: -0.11\n",
      "INFO:root:Iter 3/50 | Loss: 1.1239 | Avg Q-Value: -0.10\n",
      "INFO:root:Iter 4/50 | Loss: 1.1193 | Avg Q-Value: -0.06\n",
      "INFO:root:Iter 5/50 | Loss: 1.1103 | Avg Q-Value: -0.06\n",
      "INFO:root:Iter 6/50 | Loss: 1.1316 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 7/50 | Loss: 1.1713 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 8/50 | Loss: 1.1197 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 9/50 | Loss: 1.0917 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 10/50 | Loss: 1.0950 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 11/50 | Loss: 1.1481 | Avg Q-Value: 0.05\n",
      "INFO:root:Iter 12/50 | Loss: 1.1411 | Avg Q-Value: 0.03\n",
      "INFO:root:Iter 13/50 | Loss: 1.1291 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 14/50 | Loss: 1.1263 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 15/50 | Loss: 1.1304 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 16/50 | Loss: 1.1263 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 17/50 | Loss: 1.3221 | Avg Q-Value: 0.03\n",
      "INFO:root:Iter 18/50 | Loss: 1.1249 | Avg Q-Value: 0.04\n",
      "INFO:root:Iter 19/50 | Loss: 1.1278 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 20/50 | Loss: 1.1403 | Avg Q-Value: 0.03\n",
      "INFO:root:Iter 21/50 | Loss: 1.1678 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 22/50 | Loss: 1.1191 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 23/50 | Loss: 1.1262 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 24/50 | Loss: 1.1349 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 25/50 | Loss: 1.1337 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 26/50 | Loss: 1.1165 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 27/50 | Loss: 1.1147 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 28/50 | Loss: 1.1777 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 29/50 | Loss: 1.1482 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 30/50 | Loss: 1.1233 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 31/50 | Loss: 1.1664 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 32/50 | Loss: 1.1461 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 33/50 | Loss: 1.1437 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 34/50 | Loss: 1.1376 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 35/50 | Loss: 1.1419 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 36/50 | Loss: 1.1349 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 37/50 | Loss: 1.1356 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 38/50 | Loss: 1.1476 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 39/50 | Loss: 1.1385 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 40/50 | Loss: 1.2247 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 41/50 | Loss: 1.1396 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 42/50 | Loss: 1.1251 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 43/50 | Loss: 1.1459 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 44/50 | Loss: 1.1390 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 45/50 | Loss: 1.1233 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 46/50 | Loss: 1.2123 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 47/50 | Loss: 1.1273 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 48/50 | Loss: 1.1331 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 49/50 | Loss: 1.1342 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 50/50 | Loss: 1.1311 | Avg Q-Value: 0.17\n",
      "100%|██████████| 50/50 [04:47<00:00,  5.75s/it]\n",
      "INFO:root:Policy updated.\n",
      "  4%|▍         | 874/20000 [35:09<5:29:38,  1.03s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.425 0.979 0.837 1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.93487D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  3.17927D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  3.12764D+01    |proj g|=  8.31180D-01\n",
      "\n",
      "At iterate    3    f=  3.08592D+01    |proj g|=  5.29983D-01\n",
      "\n",
      "At iterate    4    f=  3.08103D+01    |proj g|=  1.54311D-01\n",
      "\n",
      "At iterate    5    f=  3.08062D+01    |proj g|=  7.66556D-02\n",
      "\n",
      "At iterate    6    f=  3.08039D+01    |proj g|=  8.71945D-03\n",
      "\n",
      "At iterate    7    f=  3.08039D+01    |proj g|=  1.92709D-03\n",
      "\n",
      "At iterate    8    f=  3.08039D+01    |proj g|=  4.72676D-05\n",
      "\n",
      "At iterate    9    f=  3.08039D+01    |proj g|=  1.88240D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     10     12     0     1   1.882D-06   3.080D+01\n",
      "  F =   30.803922582655527     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:40<00:00, 1246.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 2.1831 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 2/50 | Loss: 2.1539 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 3/50 | Loss: 2.1421 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 4/50 | Loss: 2.1309 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 5/50 | Loss: 2.1266 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 6/50 | Loss: 2.1332 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 7/50 | Loss: 2.1240 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 8/50 | Loss: 2.1198 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 9/50 | Loss: 2.1283 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 10/50 | Loss: 2.1154 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 11/50 | Loss: 2.1375 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 12/50 | Loss: 2.1151 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 13/50 | Loss: 2.1240 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 14/50 | Loss: 2.0913 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 15/50 | Loss: 2.1032 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 16/50 | Loss: 2.0927 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 17/50 | Loss: 2.0949 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 18/50 | Loss: 2.1234 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 19/50 | Loss: 2.0910 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 20/50 | Loss: 2.1057 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 21/50 | Loss: 2.1322 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 22/50 | Loss: 2.1230 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 23/50 | Loss: 2.5570 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 24/50 | Loss: 2.1000 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 25/50 | Loss: 2.1072 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 26/50 | Loss: 2.1201 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 27/50 | Loss: 2.1019 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 28/50 | Loss: 2.1155 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 29/50 | Loss: 2.1155 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 30/50 | Loss: 2.1287 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 31/50 | Loss: 2.1270 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 32/50 | Loss: 2.1235 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 33/50 | Loss: 2.1069 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 34/50 | Loss: 2.1155 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 35/50 | Loss: 2.1036 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 36/50 | Loss: 2.1081 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 37/50 | Loss: 2.1045 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 38/50 | Loss: 2.1107 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 39/50 | Loss: 2.1150 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 40/50 | Loss: 2.1031 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 41/50 | Loss: 2.1512 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 42/50 | Loss: 2.1148 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 43/50 | Loss: 2.1126 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 44/50 | Loss: 2.1108 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 45/50 | Loss: 2.1291 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 46/50 | Loss: 2.1065 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 47/50 | Loss: 2.1052 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 48/50 | Loss: 2.1081 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 49/50 | Loss: 2.1093 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 50/50 | Loss: 2.1007 | Avg Q-Value: 0.43\n",
      "100%|██████████| 50/50 [04:40<00:00,  5.61s/it]\n",
      "INFO:root:Policy updated.\n",
      "  6%|▌         | 1153/20000 [40:30<5:07:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1591/20000 [40:31<1:34:40,  3.24it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.04360D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  5.04221D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  4.86291D+01    |proj g|=  8.71501D-01\n",
      "\n",
      "At iterate    3    f=  4.79215D+01    |proj g|=  6.51846D-01\n",
      "\n",
      "At iterate    4    f=  4.77541D+01    |proj g|=  4.20098D-01\n",
      "\n",
      "At iterate    5    f=  4.77150D+01    |proj g|=  3.70591D-01\n",
      "\n",
      "At iterate    6    f=  4.76569D+01    |proj g|=  3.75944D-02\n",
      "\n",
      "At iterate    7    f=  4.76567D+01    |proj g|=  1.35549D-02\n",
      "\n",
      "At iterate    8    f=  4.76567D+01    |proj g|=  3.39833D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.851 0.952 0.206 0.866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  4.76567D+01    |proj g|=  4.31605D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     10     12     0     0   4.316D-05   4.766D+01\n",
      "  F =   47.656686070693453     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:27<00:00, 1804.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.9600 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 2/50 | Loss: 0.9347 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 3/50 | Loss: 0.9052 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 4/50 | Loss: 0.8973 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 5/50 | Loss: 0.8959 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 6/50 | Loss: 0.9006 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 7/50 | Loss: 0.8862 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 8/50 | Loss: 0.8982 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 9/50 | Loss: 0.8829 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 10/50 | Loss: 0.8804 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 11/50 | Loss: 0.8910 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 12/50 | Loss: 0.9013 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 13/50 | Loss: 0.9119 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 14/50 | Loss: 0.8892 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 15/50 | Loss: 0.9022 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 16/50 | Loss: 0.8843 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 17/50 | Loss: 0.8857 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 18/50 | Loss: 0.8852 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 19/50 | Loss: 1.0874 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 20/50 | Loss: 0.8996 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 21/50 | Loss: 0.9298 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 22/50 | Loss: 0.9246 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 23/50 | Loss: 0.9032 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 24/50 | Loss: 0.9053 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 25/50 | Loss: 0.9106 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 26/50 | Loss: 0.9066 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 27/50 | Loss: 0.9084 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 28/50 | Loss: 0.9103 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 29/50 | Loss: 0.9008 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 30/50 | Loss: 0.9051 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 31/50 | Loss: 0.9372 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 32/50 | Loss: 0.9356 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 33/50 | Loss: 0.9005 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 34/50 | Loss: 0.9407 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 35/50 | Loss: 0.9059 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 36/50 | Loss: 0.9220 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 37/50 | Loss: 0.9194 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 38/50 | Loss: 0.9078 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 39/50 | Loss: 0.8985 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 40/50 | Loss: 0.9059 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 41/50 | Loss: 0.9222 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 42/50 | Loss: 0.9052 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 43/50 | Loss: 0.9115 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 44/50 | Loss: 0.9133 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 45/50 | Loss: 0.9054 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 46/50 | Loss: 0.9137 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 47/50 | Loss: 0.9001 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 48/50 | Loss: 0.9127 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 49/50 | Loss: 0.9077 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 50/50 | Loss: 1.0883 | Avg Q-Value: 0.56\n",
      "100%|██████████| 50/50 [04:51<00:00,  5.83s/it]\n",
      "INFO:root:Policy updated.\n",
      "  9%|▉         | 1781/20000 [45:51<3:39:10,  1.39it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.38800D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  7.58766D+01    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  7.16330D+01    |proj g|=  8.31812D-01\n",
      "\n",
      "At iterate    3    f=  7.05239D+01    |proj g|=  7.50260D-01\n",
      "\n",
      "At iterate    4    f=  7.02370D+01    |proj g|=  2.95703D-01\n",
      "\n",
      "At iterate    5    f=  7.01252D+01    |proj g|=  2.29817D-01\n",
      "\n",
      "At iterate    6    f=  7.00489D+01    |proj g|=  1.14776D-01\n",
      "\n",
      "At iterate    7    f=  7.00470D+01    |proj g|=  1.97105D-02\n",
      "\n",
      "At iterate    8    f=  7.00470D+01    |proj g|=  4.37032D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.793 0.592 0.098 1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  7.00470D+01    |proj g|=  1.85353D-04\n",
      "\n",
      "At iterate   10    f=  7.00470D+01    |proj g|=  2.55865D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     10     11     14     0     1   2.559D-05   7.005D+01\n",
      "  F =   70.046996880103165     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:29<00:00, 1669.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8404 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 2/50 | Loss: 0.8560 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 3/50 | Loss: 0.8232 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 4/50 | Loss: 0.8327 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 5/50 | Loss: 0.8181 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 6/50 | Loss: 0.8138 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 7/50 | Loss: 0.8145 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 8/50 | Loss: 0.8060 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 9/50 | Loss: 0.8199 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 10/50 | Loss: 0.8036 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 11/50 | Loss: 0.8401 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 12/50 | Loss: 0.8512 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 13/50 | Loss: 0.8433 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 14/50 | Loss: 0.8377 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 15/50 | Loss: 0.8438 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 16/50 | Loss: 0.8309 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 17/50 | Loss: 0.8328 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 18/50 | Loss: 0.8712 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 19/50 | Loss: 0.8276 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 20/50 | Loss: 0.8331 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 21/50 | Loss: 0.8472 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 22/50 | Loss: 0.8691 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 23/50 | Loss: 0.8503 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 24/50 | Loss: 0.8478 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 25/50 | Loss: 0.8426 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 26/50 | Loss: 0.8523 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 27/50 | Loss: 0.8478 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 28/50 | Loss: 0.8510 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 29/50 | Loss: 0.8426 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 30/50 | Loss: 0.8637 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 31/50 | Loss: 0.8480 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 32/50 | Loss: 0.8528 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 33/50 | Loss: 0.8515 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 34/50 | Loss: 0.8493 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 35/50 | Loss: 0.8516 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 36/50 | Loss: 0.8691 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 37/50 | Loss: 0.8529 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 38/50 | Loss: 0.8552 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 39/50 | Loss: 0.8475 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 40/50 | Loss: 0.8482 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 41/50 | Loss: 0.8872 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 42/50 | Loss: 0.8561 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 43/50 | Loss: 0.9052 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 44/50 | Loss: 0.8565 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 45/50 | Loss: 0.8567 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 46/50 | Loss: 0.8506 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 47/50 | Loss: 0.8577 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 48/50 | Loss: 0.8638 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 49/50 | Loss: 0.9030 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 50/50 | Loss: 0.8585 | Avg Q-Value: 0.50\n",
      "100%|██████████| 50/50 [04:49<00:00,  5.80s/it]\n",
      "INFO:root:Policy updated.\n",
      " 10%|▉         | 1998/20000 [51:11<4:49:06,  1.04it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14897D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.01714D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.31704D+01    |proj g|=  7.89285D-01\n",
      "\n",
      "At iterate    3    f=  9.15765D+01    |proj g|=  9.09745D-01\n",
      "\n",
      "At iterate    4    f=  9.10815D+01    |proj g|=  3.67510D-01\n",
      "\n",
      "At iterate    5    f=  9.08653D+01    |proj g|=  8.46670D-02\n",
      "\n",
      "At iterate    6    f=  9.08089D+01    |proj g|=  5.79893D-02\n",
      "\n",
      "At iterate    7    f=  9.08087D+01    |proj g|=  6.99680D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.672 0.592 0.    1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  9.08087D+01    |proj g|=  3.38731D-03\n",
      "\n",
      "At iterate    9    f=  9.08087D+01    |proj g|=  7.83705D-04\n",
      "\n",
      "At iterate   10    f=  9.08087D+01    |proj g|=  3.73221D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     10     11     15     0     2   3.732D-05   9.081D+01\n",
      "  F =   90.808704268923961     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:14<00:00, 3385.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.9169 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 2/50 | Loss: 0.8179 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 3/50 | Loss: 0.8048 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 4/50 | Loss: 0.8013 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 5/50 | Loss: 0.7836 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 6/50 | Loss: 0.7862 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 7/50 | Loss: 0.7732 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 8/50 | Loss: 0.7781 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 9/50 | Loss: 0.7726 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 10/50 | Loss: 0.7719 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 11/50 | Loss: 0.9081 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 12/50 | Loss: 0.8257 | Avg Q-Value: 0.80\n",
      "INFO:root:Iter 13/50 | Loss: 0.8112 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 14/50 | Loss: 0.8287 | Avg Q-Value: 0.80\n",
      "INFO:root:Iter 15/50 | Loss: 0.8108 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 16/50 | Loss: 0.8177 | Avg Q-Value: 0.78\n",
      "INFO:root:Iter 17/50 | Loss: 0.8278 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 18/50 | Loss: 0.8302 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 19/50 | Loss: 0.8077 | Avg Q-Value: 0.80\n",
      "INFO:root:Iter 20/50 | Loss: 0.8113 | Avg Q-Value: 0.79\n",
      "INFO:root:Iter 21/50 | Loss: 0.9077 | Avg Q-Value: 0.92\n",
      "INFO:root:Iter 22/50 | Loss: 0.7886 | Avg Q-Value: 0.92\n",
      "INFO:root:Iter 23/50 | Loss: 0.7969 | Avg Q-Value: 0.91\n",
      "INFO:root:Iter 24/50 | Loss: 0.7948 | Avg Q-Value: 0.92\n",
      "INFO:root:Iter 25/50 | Loss: 0.7860 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 26/50 | Loss: 0.7927 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 27/50 | Loss: 0.9150 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 28/50 | Loss: 0.7863 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 29/50 | Loss: 0.7857 | Avg Q-Value: 0.92\n",
      "INFO:root:Iter 30/50 | Loss: 0.7797 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 31/50 | Loss: 1.0178 | Avg Q-Value: 0.88\n",
      "INFO:root:Iter 32/50 | Loss: 0.8296 | Avg Q-Value: 0.97\n",
      "INFO:root:Iter 33/50 | Loss: 0.8306 | Avg Q-Value: 1.04\n",
      "INFO:root:Iter 34/50 | Loss: 0.8264 | Avg Q-Value: 1.00\n",
      "INFO:root:Iter 35/50 | Loss: 0.8158 | Avg Q-Value: 0.99\n",
      "INFO:root:Iter 36/50 | Loss: 0.8114 | Avg Q-Value: 1.01\n",
      "INFO:root:Iter 37/50 | Loss: 0.8200 | Avg Q-Value: 1.00\n",
      "INFO:root:Iter 38/50 | Loss: 0.8011 | Avg Q-Value: 1.01\n",
      "INFO:root:Iter 39/50 | Loss: 0.8025 | Avg Q-Value: 1.01\n",
      "INFO:root:Iter 40/50 | Loss: 0.8001 | Avg Q-Value: 1.01\n",
      "INFO:root:Iter 41/50 | Loss: 1.0552 | Avg Q-Value: 1.25\n",
      "INFO:root:Iter 42/50 | Loss: 0.8132 | Avg Q-Value: 1.13\n",
      "INFO:root:Iter 43/50 | Loss: 0.7936 | Avg Q-Value: 1.12\n",
      "INFO:root:Iter 44/50 | Loss: 0.7892 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 45/50 | Loss: 0.7900 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 46/50 | Loss: 0.9115 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 47/50 | Loss: 0.8002 | Avg Q-Value: 1.12\n",
      "INFO:root:Iter 48/50 | Loss: 0.7957 | Avg Q-Value: 1.12\n",
      "INFO:root:Iter 49/50 | Loss: 0.7941 | Avg Q-Value: 1.12\n",
      "INFO:root:Iter 50/50 | Loss: 0.8024 | Avg Q-Value: 1.12\n",
      "100%|██████████| 50/50 [04:58<00:00,  5.98s/it]\n",
      "INFO:root:Policy updated.\n",
      " 11%|█         | 2111/20000 [56:25<7:27:56,  1.50s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.36420D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.26580D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    2    f=  1.13357D+02    |proj g|=  7.15123D-01\n",
      "\n",
      "At iterate    3    f=  1.12084D+02    |proj g|=  7.77573D-01\n",
      "\n",
      "At iterate    4    f=  1.11694D+02    |proj g|=  4.57830D-01\n",
      "\n",
      "At iterate    5    f=  1.11489D+02    |proj g|=  2.73981D-01\n",
      "\n",
      "At iterate    6    f=  1.11372D+02    |proj g|=  3.10309D-01\n",
      "\n",
      "At iterate    7    f=  1.11367D+02    |proj g|=  1.58149D-02\n",
      "\n",
      "At iterate    8    f=  1.11367D+02    |proj g|=  6.43458D-03\n",
      "\n",
      "At iterate    9    f=  1.11367D+02    |proj g|=  1.60025D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.556 0.475 0.051 0.986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f=  1.11367D+02    |proj g|=  3.74777D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     10     11     13     0     0   3.748D-04   1.114D+02\n",
      "  F =   111.36711729515692     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:15<00:00, 3171.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8813 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 2/50 | Loss: 0.8334 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 3/50 | Loss: 0.8067 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 4/50 | Loss: 0.8209 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 5/50 | Loss: 0.7976 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 6/50 | Loss: 0.8417 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 7/50 | Loss: 0.7915 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 8/50 | Loss: 0.7964 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 9/50 | Loss: 0.7875 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 10/50 | Loss: 0.7871 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 11/50 | Loss: 0.8238 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 12/50 | Loss: 0.7824 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 13/50 | Loss: 0.7703 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 14/50 | Loss: 0.7664 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 15/50 | Loss: 0.7624 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 16/50 | Loss: 0.7618 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 17/50 | Loss: 0.7750 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 18/50 | Loss: 0.7891 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 19/50 | Loss: 0.7590 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 20/50 | Loss: 0.7652 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 21/50 | Loss: 0.8193 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 22/50 | Loss: 0.7555 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 23/50 | Loss: 0.7547 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 24/50 | Loss: 0.7538 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 25/50 | Loss: 0.7522 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 26/50 | Loss: 0.7579 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 27/50 | Loss: 0.7747 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 28/50 | Loss: 0.7552 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 29/50 | Loss: 0.7492 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 30/50 | Loss: 0.7554 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 31/50 | Loss: 0.8627 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 32/50 | Loss: 0.7807 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 33/50 | Loss: 0.7757 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 34/50 | Loss: 0.7833 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 35/50 | Loss: 0.7835 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 36/50 | Loss: 0.7716 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 37/50 | Loss: 0.7781 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 38/50 | Loss: 0.7843 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 39/50 | Loss: 0.7776 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 40/50 | Loss: 0.7777 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 41/50 | Loss: 0.8444 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 42/50 | Loss: 0.7702 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 43/50 | Loss: 0.7632 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 44/50 | Loss: 0.8307 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 45/50 | Loss: 0.7605 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 46/50 | Loss: 0.7598 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 47/50 | Loss: 0.8292 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 48/50 | Loss: 0.7790 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 49/50 | Loss: 0.7572 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 50/50 | Loss: 0.7567 | Avg Q-Value: 0.86\n",
      "100%|██████████| 50/50 [04:56<00:00,  5.92s/it]\n",
      "INFO:root:Policy updated.\n",
      " 11%|█         | 2192/20000 [1:01:37<10:08:40,  2.05s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.55617D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.34540D+02    |proj g|=  5.35921D-01\n",
      "\n",
      "At iterate    2    f=  1.33959D+02    |proj g|=  4.98667D-01\n",
      "\n",
      "At iterate    3    f=  1.32830D+02    |proj g|=  1.88880D-01\n",
      "\n",
      "At iterate    4    f=  1.32826D+02    |proj g|=  1.91569D-02\n",
      "\n",
      "At iterate    5    f=  1.32826D+02    |proj g|=  3.56002D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.64  0.187 0.094 0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    6    f=  1.32826D+02    |proj g|=  2.77292D-04\n",
      "\n",
      "At iterate    7    f=  1.32826D+02    |proj g|=  6.48545D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   6.485D-05   1.328D+02\n",
      "  F =   132.82610646007222     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:14<00:00, 3412.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.0343 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 2/50 | Loss: 1.0129 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 3/50 | Loss: 1.0041 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 4/50 | Loss: 0.9923 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 5/50 | Loss: 1.0401 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 6/50 | Loss: 0.9918 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 7/50 | Loss: 0.9909 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 8/50 | Loss: 0.9786 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 9/50 | Loss: 0.9788 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 10/50 | Loss: 0.9758 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 11/50 | Loss: 1.0188 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 12/50 | Loss: 1.0105 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 13/50 | Loss: 1.0160 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 14/50 | Loss: 1.0194 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 15/50 | Loss: 1.0081 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 16/50 | Loss: 1.0117 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 17/50 | Loss: 1.0094 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 18/50 | Loss: 1.0165 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 19/50 | Loss: 1.0108 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 20/50 | Loss: 1.1110 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 21/50 | Loss: 1.0166 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 22/50 | Loss: 1.2138 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 23/50 | Loss: 1.0081 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 24/50 | Loss: 1.1113 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 25/50 | Loss: 1.0075 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 26/50 | Loss: 1.0286 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 27/50 | Loss: 1.0093 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 28/50 | Loss: 1.0085 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 29/50 | Loss: 1.4078 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 30/50 | Loss: 1.0113 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 31/50 | Loss: 1.0359 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 32/50 | Loss: 1.2178 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 33/50 | Loss: 1.0209 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 34/50 | Loss: 1.0310 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 35/50 | Loss: 1.0161 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 36/50 | Loss: 1.0288 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 37/50 | Loss: 1.0186 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 38/50 | Loss: 1.0172 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 39/50 | Loss: 1.0153 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 40/50 | Loss: 1.1198 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 41/50 | Loss: 1.0148 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 42/50 | Loss: 1.0664 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 43/50 | Loss: 1.0244 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 44/50 | Loss: 1.0303 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 45/50 | Loss: 1.0292 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 46/50 | Loss: 1.0207 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 47/50 | Loss: 1.0148 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 48/50 | Loss: 1.0263 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 49/50 | Loss: 1.0144 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 50/50 | Loss: 1.0135 | Avg Q-Value: 0.71\n",
      "100%|██████████| 50/50 [04:55<00:00,  5.90s/it]\n",
      "INFO:root:Policy updated.\n",
      " 12%|█▏        | 2428/20000 [1:06:48<7:27:06,  1.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2554/20000 [1:06:48<4:59:02,  1.03s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.78083D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.56082D+02    |proj g|=  5.60078D-01\n",
      "\n",
      "At iterate    2    f=  1.55315D+02    |proj g|=  5.19180D-01\n",
      "\n",
      "At iterate    3    f=  1.53756D+02    |proj g|=  2.80000D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.65  0.118 0.042 0.858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    4    f=  1.53749D+02    |proj g|=  3.99788D-02\n",
      "\n",
      "At iterate    5    f=  1.53749D+02    |proj g|=  6.37014D-03\n",
      "\n",
      "At iterate    6    f=  1.53749D+02    |proj g|=  5.37685D-04\n",
      "\n",
      "At iterate    7    f=  1.53749D+02    |proj g|=  4.46722D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   4.467D-05   1.537D+02\n",
      "  F =   153.74906103974311     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:14<00:00, 3456.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2554/20000 [1:07:03<4:59:02,  1.03s/it]INFO:root:Iter 1/50 | Loss: 0.9359 | Avg Q-Value: -0.18\n",
      "INFO:root:Iter 2/50 | Loss: 0.8729 | Avg Q-Value: -0.22\n",
      "INFO:root:Iter 3/50 | Loss: 0.7793 | Avg Q-Value: -0.23\n",
      "INFO:root:Iter 4/50 | Loss: 0.7974 | Avg Q-Value: -0.23\n",
      "INFO:root:Iter 5/50 | Loss: 0.8133 | Avg Q-Value: -0.22\n",
      "INFO:root:Iter 6/50 | Loss: 0.7744 | Avg Q-Value: -0.20\n",
      "INFO:root:Iter 7/50 | Loss: 0.7989 | Avg Q-Value: -0.20\n",
      "INFO:root:Iter 8/50 | Loss: 0.7692 | Avg Q-Value: -0.21\n",
      "INFO:root:Iter 9/50 | Loss: 0.7663 | Avg Q-Value: -0.20\n",
      "INFO:root:Iter 10/50 | Loss: 0.7630 | Avg Q-Value: -0.19\n",
      "INFO:root:Iter 11/50 | Loss: 0.8195 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 12/50 | Loss: 0.8129 | Avg Q-Value: 0.00\n",
      "INFO:root:Iter 13/50 | Loss: 0.7789 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 14/50 | Loss: 0.8099 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 15/50 | Loss: 0.7768 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 16/50 | Loss: 0.7738 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 17/50 | Loss: 0.7761 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 18/50 | Loss: 0.7720 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 19/50 | Loss: 0.7849 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 20/50 | Loss: 0.7729 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 21/50 | Loss: 0.8392 | Avg Q-Value: -0.06\n",
      "INFO:root:Iter 22/50 | Loss: 0.7923 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 23/50 | Loss: 0.7918 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 24/50 | Loss: 0.7884 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 25/50 | Loss: 0.7838 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 26/50 | Loss: 0.7935 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 27/50 | Loss: 0.7930 | Avg Q-Value: -0.00\n",
      "INFO:root:Iter 28/50 | Loss: 0.9150 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 29/50 | Loss: 0.7850 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 30/50 | Loss: 0.8238 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 31/50 | Loss: 0.8323 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 32/50 | Loss: 0.7875 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 33/50 | Loss: 0.7983 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 34/50 | Loss: 0.7881 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 35/50 | Loss: 0.8084 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 36/50 | Loss: 0.7864 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 37/50 | Loss: 0.7922 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 38/50 | Loss: 0.7878 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 39/50 | Loss: 0.7923 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 40/50 | Loss: 0.9125 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 41/50 | Loss: 0.8443 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 42/50 | Loss: 0.8029 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 43/50 | Loss: 0.7891 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 44/50 | Loss: 0.7949 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 45/50 | Loss: 0.7906 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 46/50 | Loss: 0.7893 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 47/50 | Loss: 0.7874 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 48/50 | Loss: 0.7963 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 49/50 | Loss: 0.7948 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 50/50 | Loss: 0.7948 | Avg Q-Value: 0.12\n",
      "100%|██████████| 50/50 [04:56<00:00,  5.93s/it]\n",
      "INFO:root:Policy updated.\n",
      " 13%|█▎        | 2556/20000 [1:12:00<10:29:47,  2.17s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.02451D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.77751D+02    |proj g|=  5.66455D-01\n",
      "\n",
      "At iterate    2    f=  1.77127D+02    |proj g|=  5.27621D-01\n",
      "\n",
      "At iterate    3    f=  1.75840D+02    |proj g|=  2.26225D-01\n",
      "\n",
      "At iterate    4    f=  1.75836D+02    |proj g|=  5.28152D-02\n",
      "\n",
      "At iterate    5    f=  1.75835D+02    |proj g|=  8.96723D-03\n",
      "\n",
      "At iterate    6    f=  1.75835D+02    |proj g|=  1.22296D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.619 0.141 0.114 0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    7    f=  1.75835D+02    |proj g|=  1.52275D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   1.523D-04   1.758D+02\n",
      "  F =   175.83536728819161     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:12<00:00, 4118.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.9751 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 2/50 | Loss: 0.9198 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 3/50 | Loss: 0.8992 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 4/50 | Loss: 0.9110 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 5/50 | Loss: 0.9079 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 6/50 | Loss: 0.8892 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 7/50 | Loss: 0.9131 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 8/50 | Loss: 0.8830 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 9/50 | Loss: 0.8773 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 10/50 | Loss: 0.9488 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 11/50 | Loss: 0.8263 | Avg Q-Value: 0.78\n",
      "INFO:root:Iter 12/50 | Loss: 0.8019 | Avg Q-Value: 0.81\n",
      "INFO:root:Iter 13/50 | Loss: 0.7863 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 14/50 | Loss: 0.7875 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 15/50 | Loss: 0.7836 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 16/50 | Loss: 0.8257 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 17/50 | Loss: 0.7803 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 18/50 | Loss: 0.7845 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 19/50 | Loss: 0.7790 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 20/50 | Loss: 0.7852 | Avg Q-Value: 0.84\n",
      "INFO:root:Iter 21/50 | Loss: 0.8273 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 22/50 | Loss: 0.7964 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 23/50 | Loss: 0.8026 | Avg Q-Value: 0.95\n",
      "INFO:root:Iter 24/50 | Loss: 0.8696 | Avg Q-Value: 0.97\n",
      "INFO:root:Iter 25/50 | Loss: 0.7939 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 26/50 | Loss: 0.7938 | Avg Q-Value: 0.95\n",
      "INFO:root:Iter 27/50 | Loss: 0.7896 | Avg Q-Value: 0.98\n",
      "INFO:root:Iter 28/50 | Loss: 0.8032 | Avg Q-Value: 0.95\n",
      "INFO:root:Iter 29/50 | Loss: 0.7928 | Avg Q-Value: 0.98\n",
      "INFO:root:Iter 30/50 | Loss: 0.8075 | Avg Q-Value: 0.95\n",
      "INFO:root:Iter 31/50 | Loss: 0.8659 | Avg Q-Value: 1.13\n",
      "INFO:root:Iter 32/50 | Loss: 0.8047 | Avg Q-Value: 1.07\n",
      "INFO:root:Iter 33/50 | Loss: 0.8390 | Avg Q-Value: 1.09\n",
      "INFO:root:Iter 34/50 | Loss: 0.8117 | Avg Q-Value: 1.08\n",
      "INFO:root:Iter 35/50 | Loss: 0.8141 | Avg Q-Value: 1.07\n",
      "INFO:root:Iter 36/50 | Loss: 0.8020 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 37/50 | Loss: 0.8010 | Avg Q-Value: 1.07\n",
      "INFO:root:Iter 38/50 | Loss: 0.7970 | Avg Q-Value: 1.06\n",
      "INFO:root:Iter 39/50 | Loss: 0.7969 | Avg Q-Value: 1.07\n",
      "INFO:root:Iter 40/50 | Loss: 0.8014 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 41/50 | Loss: 0.8408 | Avg Q-Value: 1.21\n",
      "INFO:root:Iter 42/50 | Loss: 0.8113 | Avg Q-Value: 1.18\n",
      "INFO:root:Iter 43/50 | Loss: 0.7983 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 44/50 | Loss: 0.7993 | Avg Q-Value: 1.18\n",
      "INFO:root:Iter 45/50 | Loss: 0.8025 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 46/50 | Loss: 0.8019 | Avg Q-Value: 1.17\n",
      "INFO:root:Iter 47/50 | Loss: 0.8059 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 48/50 | Loss: 0.8022 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 49/50 | Loss: 0.7971 | Avg Q-Value: 1.18\n",
      "INFO:root:Iter 50/50 | Loss: 0.7989 | Avg Q-Value: 1.22\n",
      "100%|██████████| 50/50 [04:13<00:00,  5.06s/it]\n",
      "INFO:root:Policy updated.\n",
      " 13%|█▎        | 2684/20000 [1:16:25<10:14:40,  2.13s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.26413D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.02434D+02    |proj g|=  5.86276D-01\n",
      "\n",
      "At iterate    2    f=  2.02072D+02    |proj g|=  5.46227D-01\n",
      "\n",
      "At iterate    3    f=  2.01436D+02    |proj g|=  1.82261D-01\n",
      "\n",
      "At iterate    4    f=  2.01434D+02    |proj g|=  4.73496D-02\n",
      "\n",
      "At iterate    5    f=  2.01434D+02    |proj g|=  1.25625D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.563 0.148 0.283 0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    6    f=  2.01434D+02    |proj g|=  3.53179D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      9     0     0   3.532D-04   2.014D+02\n",
      "  F =   201.43403452087773     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:13<00:00, 3785.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8388 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 2/50 | Loss: 0.8191 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 3/50 | Loss: 0.8135 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 4/50 | Loss: 0.8137 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 5/50 | Loss: 0.8064 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 6/50 | Loss: 0.7997 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 7/50 | Loss: 0.8025 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 8/50 | Loss: 0.7959 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 9/50 | Loss: 0.7946 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 10/50 | Loss: 0.7992 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 11/50 | Loss: 0.8146 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 12/50 | Loss: 0.8120 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 13/50 | Loss: 0.8183 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 14/50 | Loss: 0.8022 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 15/50 | Loss: 0.8062 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 16/50 | Loss: 0.8100 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 17/50 | Loss: 0.8313 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 18/50 | Loss: 0.8025 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 19/50 | Loss: 0.7971 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 20/50 | Loss: 0.8233 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 21/50 | Loss: 0.8206 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 22/50 | Loss: 0.8255 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 23/50 | Loss: 0.8516 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 24/50 | Loss: 0.8171 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 25/50 | Loss: 0.8433 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 26/50 | Loss: 0.8215 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 27/50 | Loss: 0.8251 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 28/50 | Loss: 0.8177 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 29/50 | Loss: 0.8188 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 30/50 | Loss: 0.8213 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 31/50 | Loss: 0.8246 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 32/50 | Loss: 0.8325 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 33/50 | Loss: 0.8151 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 34/50 | Loss: 0.8142 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 35/50 | Loss: 0.8202 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 36/50 | Loss: 0.8166 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 37/50 | Loss: 0.8131 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 38/50 | Loss: 0.8182 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 39/50 | Loss: 0.8148 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 40/50 | Loss: 0.8155 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 41/50 | Loss: 0.8264 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 42/50 | Loss: 0.8228 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 43/50 | Loss: 0.8252 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 44/50 | Loss: 0.8311 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 45/50 | Loss: 0.8459 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 46/50 | Loss: 0.8262 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 47/50 | Loss: 0.8200 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 48/50 | Loss: 0.8207 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 49/50 | Loss: 0.8216 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 50/50 | Loss: 0.8291 | Avg Q-Value: 0.72\n",
      "100%|██████████| 50/50 [04:21<00:00,  5.23s/it]\n",
      "INFO:root:Policy updated.\n",
      " 14%|█▍        | 2900/20000 [1:21:01<7:15:54,  1.53s/it] INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.49591D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.26692D+02    |proj g|=  6.13122D-01\n",
      "\n",
      "At iterate    2    f=  2.26288D+02    |proj g|=  5.68546D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.54  0.224 0.176 0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    3    f=  2.25662D+02    |proj g|=  3.50944D-01\n",
      "\n",
      "At iterate    4    f=  2.25653D+02    |proj g|=  6.41858D-02\n",
      "\n",
      "At iterate    5    f=  2.25653D+02    |proj g|=  3.15247D-03\n",
      "\n",
      "At iterate    6    f=  2.25653D+02    |proj g|=  5.72635D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      9     0     0   5.726D-04   2.257D+02\n",
      "  F =   225.65254388805420     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:13<00:00, 3682.28it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8060 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 2/50 | Loss: 0.7344 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 3/50 | Loss: 0.7205 | Avg Q-Value: 0.80\n",
      "INFO:root:Iter 4/50 | Loss: 0.7176 | Avg Q-Value: 0.81\n",
      "INFO:root:Iter 5/50 | Loss: 0.7167 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 6/50 | Loss: 0.7137 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 7/50 | Loss: 0.7407 | Avg Q-Value: 0.84\n",
      "INFO:root:Iter 8/50 | Loss: 0.7283 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 9/50 | Loss: 0.7110 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 10/50 | Loss: 0.7077 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 11/50 | Loss: 0.7335 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 12/50 | Loss: 0.7188 | Avg Q-Value: 1.02\n",
      "INFO:root:Iter 13/50 | Loss: 0.7141 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 14/50 | Loss: 0.7120 | Avg Q-Value: 1.04\n",
      "INFO:root:Iter 15/50 | Loss: 0.7054 | Avg Q-Value: 1.05\n",
      "INFO:root:Iter 16/50 | Loss: 0.7097 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 17/50 | Loss: 0.7129 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 18/50 | Loss: 0.7085 | Avg Q-Value: 1.05\n",
      "INFO:root:Iter 19/50 | Loss: 0.7103 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 20/50 | Loss: 0.7153 | Avg Q-Value: 1.03\n",
      "INFO:root:Iter 21/50 | Loss: 0.7417 | Avg Q-Value: 1.26\n",
      "INFO:root:Iter 22/50 | Loss: 0.7391 | Avg Q-Value: 1.25\n",
      "INFO:root:Iter 23/50 | Loss: 0.7429 | Avg Q-Value: 1.24\n",
      "INFO:root:Iter 24/50 | Loss: 0.7252 | Avg Q-Value: 1.26\n",
      "INFO:root:Iter 25/50 | Loss: 0.7316 | Avg Q-Value: 1.27\n",
      "INFO:root:Iter 26/50 | Loss: 0.7267 | Avg Q-Value: 1.26\n",
      "INFO:root:Iter 27/50 | Loss: 0.7295 | Avg Q-Value: 1.24\n",
      "INFO:root:Iter 28/50 | Loss: 0.7221 | Avg Q-Value: 1.23\n",
      "INFO:root:Iter 29/50 | Loss: 0.7237 | Avg Q-Value: 1.27\n",
      "INFO:root:Iter 30/50 | Loss: 0.7377 | Avg Q-Value: 1.24\n",
      "INFO:root:Iter 31/50 | Loss: 0.7352 | Avg Q-Value: 1.40\n",
      "INFO:root:Iter 32/50 | Loss: 0.7273 | Avg Q-Value: 1.39\n",
      "INFO:root:Iter 33/50 | Loss: 0.7168 | Avg Q-Value: 1.40\n",
      "INFO:root:Iter 34/50 | Loss: 0.7164 | Avg Q-Value: 1.38\n",
      "INFO:root:Iter 35/50 | Loss: 0.7221 | Avg Q-Value: 1.42\n",
      "INFO:root:Iter 36/50 | Loss: 0.7159 | Avg Q-Value: 1.39\n",
      "INFO:root:Iter 37/50 | Loss: 0.7134 | Avg Q-Value: 1.39\n",
      "INFO:root:Iter 38/50 | Loss: 0.7155 | Avg Q-Value: 1.42\n",
      "INFO:root:Iter 39/50 | Loss: 0.7153 | Avg Q-Value: 1.41\n",
      "INFO:root:Iter 40/50 | Loss: 0.7191 | Avg Q-Value: 1.38\n",
      "INFO:root:Iter 41/50 | Loss: 0.7377 | Avg Q-Value: 1.56\n",
      "INFO:root:Iter 42/50 | Loss: 0.7692 | Avg Q-Value: 1.55\n",
      "INFO:root:Iter 43/50 | Loss: 0.7099 | Avg Q-Value: 1.51\n",
      "INFO:root:Iter 44/50 | Loss: 0.7112 | Avg Q-Value: 1.50\n",
      "INFO:root:Iter 45/50 | Loss: 0.7124 | Avg Q-Value: 1.52\n",
      "INFO:root:Iter 46/50 | Loss: 0.7101 | Avg Q-Value: 1.50\n",
      "INFO:root:Iter 47/50 | Loss: 0.7133 | Avg Q-Value: 1.50\n",
      "INFO:root:Iter 48/50 | Loss: 0.7090 | Avg Q-Value: 1.54\n",
      "INFO:root:Iter 49/50 | Loss: 0.7178 | Avg Q-Value: 1.53\n",
      "INFO:root:Iter 50/50 | Loss: 0.7137 | Avg Q-Value: 1.55\n",
      "100%|██████████| 50/50 [05:02<00:00,  6.04s/it]\n",
      "INFO:root:Policy updated.\n",
      " 15%|█▍        | 2992/20000 [1:26:17<9:43:17,  2.06s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.69537D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.42623D+02    |proj g|=  6.01197D-01\n",
      "\n",
      "At iterate    2    f=  2.42200D+02    |proj g|=  5.78016D-01\n",
      "\n",
      "At iterate    3    f=  2.41545D+02    |proj g|=  4.20649D-01\n",
      "\n",
      "At iterate    4    f=  2.41538D+02    |proj g|=  6.15650D-02\n",
      "\n",
      "At iterate    5    f=  2.41538D+02    |proj g|=  9.79524D-03\n",
      "\n",
      "At iterate    6    f=  2.41538D+02    |proj g|=  6.38616D-03\n",
      "\n",
      "At iterate    7    f=  2.41538D+02    |proj g|=  2.67813D-03\n",
      "\n",
      "At iterate    8    f=  2.41538D+02    |proj g|=  6.35217D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   6.352D-05   2.415D+02\n",
      "  F =   241.53805062534596     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.449 0.366 0.145 0.638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:15<00:00, 3231.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.8098 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 2/50 | Loss: 0.7032 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 3/50 | Loss: 0.6901 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 4/50 | Loss: 0.7208 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 5/50 | Loss: 0.6818 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 6/50 | Loss: 0.6687 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 7/50 | Loss: 0.6715 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 8/50 | Loss: 0.6753 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 9/50 | Loss: 0.6660 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 10/50 | Loss: 0.6702 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 11/50 | Loss: 0.7569 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 12/50 | Loss: 0.6949 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 13/50 | Loss: 0.6833 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 14/50 | Loss: 0.6782 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 15/50 | Loss: 0.6894 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 16/50 | Loss: 0.6830 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 17/50 | Loss: 0.6773 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 18/50 | Loss: 0.6751 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 19/50 | Loss: 0.6837 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 20/50 | Loss: 0.6761 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 21/50 | Loss: 0.8260 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 22/50 | Loss: 0.7276 | Avg Q-Value: 0.89\n",
      "INFO:root:Iter 23/50 | Loss: 0.7123 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 24/50 | Loss: 0.7106 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 25/50 | Loss: 0.7062 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 26/50 | Loss: 0.7033 | Avg Q-Value: 0.87\n",
      "INFO:root:Iter 27/50 | Loss: 0.7068 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 28/50 | Loss: 0.7141 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 29/50 | Loss: 0.7119 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 30/50 | Loss: 0.7013 | Avg Q-Value: 0.84\n",
      "INFO:root:Iter 31/50 | Loss: 0.8401 | Avg Q-Value: 0.91\n",
      "INFO:root:Iter 32/50 | Loss: 0.7031 | Avg Q-Value: 0.88\n",
      "INFO:root:Iter 33/50 | Loss: 0.6908 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 34/50 | Loss: 0.6806 | Avg Q-Value: 0.94\n",
      "INFO:root:Iter 35/50 | Loss: 0.6885 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 36/50 | Loss: 0.6795 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 37/50 | Loss: 0.6825 | Avg Q-Value: 0.91\n",
      "INFO:root:Iter 38/50 | Loss: 0.6959 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 39/50 | Loss: 0.6831 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 40/50 | Loss: 0.7198 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 41/50 | Loss: 1.0103 | Avg Q-Value: 1.28\n",
      "INFO:root:Iter 42/50 | Loss: 0.7356 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 43/50 | Loss: 0.7057 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 44/50 | Loss: 0.7069 | Avg Q-Value: 1.09\n",
      "INFO:root:Iter 45/50 | Loss: 0.7062 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 46/50 | Loss: 0.7117 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 47/50 | Loss: 0.7081 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 48/50 | Loss: 0.7075 | Avg Q-Value: 1.10\n",
      "INFO:root:Iter 49/50 | Loss: 0.6988 | Avg Q-Value: 1.11\n",
      "INFO:root:Iter 50/50 | Loss: 0.7058 | Avg Q-Value: 1.10\n",
      "100%|██████████| 50/50 [05:04<00:00,  6.09s/it]\n",
      "INFO:root:Policy updated.\n",
      " 16%|█▌        | 3221/20000 [1:31:38<7:19:36,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3345/20000 [1:31:38<4:51:28,  1.05s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.99854D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.72187D+02    |proj g|=  6.06403D-01\n",
      "\n",
      "At iterate    2    f=  2.71868D+02    |proj g|=  5.73270D-01\n",
      "\n",
      "At iterate    3    f=  2.71339D+02    |proj g|=  5.09100D-01\n",
      "\n",
      "At iterate    4    f=  2.71319D+02    |proj g|=  9.15685D-02\n",
      "\n",
      "At iterate    5    f=  2.71319D+02    |proj g|=  1.27011D-02\n",
      "\n",
      "At iterate    6    f=  2.71319D+02    |proj g|=  7.76441D-03\n",
      "\n",
      "At iterate    7    f=  2.71319D+02    |proj g|=  3.43340D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.501 0.262 0.215 0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  2.71319D+02    |proj g|=  4.22955D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   4.230D-04   2.713D+02\n",
      "  F =   271.31900430365982     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:13<00:00, 3610.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3345/20000 [1:31:54<4:51:28,  1.05s/it]INFO:root:Iter 1/50 | Loss: 0.9278 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 2/50 | Loss: 0.8943 | Avg Q-Value: 0.00\n",
      "INFO:root:Iter 3/50 | Loss: 0.8903 | Avg Q-Value: 0.03\n",
      "INFO:root:Iter 4/50 | Loss: 0.8867 | Avg Q-Value: 0.04\n",
      "INFO:root:Iter 5/50 | Loss: 0.8914 | Avg Q-Value: 0.05\n",
      "INFO:root:Iter 6/50 | Loss: 0.8861 | Avg Q-Value: 0.05\n",
      "INFO:root:Iter 7/50 | Loss: 0.8862 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 8/50 | Loss: 0.8779 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 9/50 | Loss: 0.8786 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 10/50 | Loss: 0.8889 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 11/50 | Loss: 0.9073 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 12/50 | Loss: 0.9045 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 13/50 | Loss: 0.9041 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 14/50 | Loss: 0.9032 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 15/50 | Loss: 0.9091 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 16/50 | Loss: 0.9182 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 17/50 | Loss: 0.9120 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 18/50 | Loss: 0.9068 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 19/50 | Loss: 0.9011 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 20/50 | Loss: 0.9161 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 21/50 | Loss: 0.9486 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 22/50 | Loss: 0.9205 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 23/50 | Loss: 0.9201 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 24/50 | Loss: 1.0115 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 25/50 | Loss: 0.9287 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 26/50 | Loss: 0.9167 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 27/50 | Loss: 0.9105 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 28/50 | Loss: 0.9156 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 29/50 | Loss: 0.9121 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 30/50 | Loss: 0.9216 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 31/50 | Loss: 0.9222 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 32/50 | Loss: 1.0741 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 33/50 | Loss: 0.9173 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 34/50 | Loss: 0.9172 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 35/50 | Loss: 0.9183 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 36/50 | Loss: 0.9265 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 37/50 | Loss: 0.9285 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 38/50 | Loss: 0.9199 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 39/50 | Loss: 0.9208 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 40/50 | Loss: 1.0144 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 41/50 | Loss: 0.9265 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 42/50 | Loss: 0.9206 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 43/50 | Loss: 0.9277 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 44/50 | Loss: 0.9159 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 45/50 | Loss: 0.9197 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 46/50 | Loss: 0.9257 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 47/50 | Loss: 0.9233 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 48/50 | Loss: 0.9137 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 49/50 | Loss: 0.9180 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 50/50 | Loss: 0.9347 | Avg Q-Value: 0.35\n",
      "100%|██████████| 50/50 [04:57<00:00,  5.94s/it]\n",
      "INFO:root:Policy updated.\n",
      " 18%|█▊        | 3515/20000 [1:36:50<5:33:08,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3639/20000 [1:36:50<3:37:07,  1.26it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.30078D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  2.98890D+02    |proj g|=  5.96675D-01\n",
      "\n",
      "At iterate    2    f=  2.98355D+02    |proj g|=  5.52425D-01\n",
      "\n",
      "At iterate    3    f=  2.97388D+02    |proj g|=  5.77749D-01\n",
      "\n",
      "At iterate    4    f=  2.97374D+02    |proj g|=  9.13262D-02\n",
      "\n",
      "At iterate    5    f=  2.97374D+02    |proj g|=  2.03867D-02\n",
      "\n",
      "At iterate    6    f=  2.97374D+02    |proj g|=  3.22356D-03\n",
      "\n",
      "At iterate    7    f=  2.97374D+02    |proj g|=  2.12275D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   2.123D-03   2.974D+02\n",
      "  F =   297.37363123029701     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.562 0.211 0.187 0.654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:17<00:00, 2914.04it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.6098 | Avg Q-Value: 0.03\n",
      "INFO:root:Iter 2/50 | Loss: 1.5806 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 3/50 | Loss: 1.5686 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 4/50 | Loss: 1.5725 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 5/50 | Loss: 1.5609 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 6/50 | Loss: 1.5614 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 7/50 | Loss: 1.5563 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 8/50 | Loss: 1.5653 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 9/50 | Loss: 1.5462 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 10/50 | Loss: 1.5427 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 11/50 | Loss: 1.6040 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 12/50 | Loss: 1.5945 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 13/50 | Loss: 1.5849 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 14/50 | Loss: 1.6097 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 15/50 | Loss: 1.5839 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 16/50 | Loss: 1.5791 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 17/50 | Loss: 1.5785 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 18/50 | Loss: 1.8498 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 19/50 | Loss: 1.5896 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 20/50 | Loss: 1.5826 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 21/50 | Loss: 1.5831 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 22/50 | Loss: 1.5849 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 23/50 | Loss: 1.5800 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 24/50 | Loss: 1.5827 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 25/50 | Loss: 1.5887 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 26/50 | Loss: 1.5756 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 27/50 | Loss: 1.5860 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 28/50 | Loss: 1.8496 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 29/50 | Loss: 1.5826 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 30/50 | Loss: 1.5764 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 31/50 | Loss: 1.6059 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 32/50 | Loss: 1.5980 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 33/50 | Loss: 1.5971 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 34/50 | Loss: 1.6040 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 35/50 | Loss: 1.6114 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 36/50 | Loss: 1.5986 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 37/50 | Loss: 1.5950 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 38/50 | Loss: 1.6002 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 39/50 | Loss: 1.6095 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 40/50 | Loss: 1.6015 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 41/50 | Loss: 1.5884 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 42/50 | Loss: 1.5933 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 43/50 | Loss: 1.5884 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 44/50 | Loss: 1.5862 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 45/50 | Loss: 1.5841 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 46/50 | Loss: 1.6171 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 47/50 | Loss: 1.5819 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 48/50 | Loss: 1.5799 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 49/50 | Loss: 1.5858 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 50/50 | Loss: 1.5855 | Avg Q-Value: 0.49\n",
      "100%|██████████| 50/50 [05:06<00:00,  6.13s/it]\n",
      "INFO:root:Policy updated.\n",
      " 19%|█▉        | 3832/20000 [1:42:15<4:43:50,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 3955/20000 [1:42:15<3:07:30,  1.43it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.60210D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  3.28060D+02    |proj g|=  6.01164D-01\n",
      "\n",
      "At iterate    2    f=  3.27551D+02    |proj g|=  5.56521D-01\n",
      "\n",
      "At iterate    3    f=  3.26834D+02    |proj g|=  5.43483D-01\n",
      "\n",
      "At iterate    4    f=  3.26815D+02    |proj g|=  8.78037D-02\n",
      "\n",
      "At iterate    5    f=  3.26815D+02    |proj g|=  1.79052D-02\n",
      "\n",
      "At iterate    6    f=  3.26815D+02    |proj g|=  9.03254D-03\n",
      "\n",
      "At iterate    7    f=  3.26815D+02    |proj g|=  5.86563D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.531 0.239 0.23  0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  3.26815D+02    |proj g|=  3.31842D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   3.318D-04   3.268D+02\n",
      "  F =   326.81478601991751     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:19<00:00, 2543.63it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.6204 | Avg Q-Value: 0.09\n",
      "INFO:root:Iter 2/50 | Loss: 1.5815 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 3/50 | Loss: 1.6111 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 4/50 | Loss: 1.5612 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 5/50 | Loss: 1.5584 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 6/50 | Loss: 1.5639 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 7/50 | Loss: 1.5595 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 8/50 | Loss: 1.5572 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 9/50 | Loss: 1.5688 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 10/50 | Loss: 1.6859 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 11/50 | Loss: 1.6102 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 12/50 | Loss: 1.5821 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 13/50 | Loss: 1.5824 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 14/50 | Loss: 1.5797 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 15/50 | Loss: 1.5811 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 16/50 | Loss: 1.5908 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 17/50 | Loss: 1.5829 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 18/50 | Loss: 1.5851 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 19/50 | Loss: 1.5902 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 20/50 | Loss: 1.6044 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 21/50 | Loss: 1.5902 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 22/50 | Loss: 1.5923 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 23/50 | Loss: 1.5877 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 24/50 | Loss: 1.5895 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 25/50 | Loss: 1.5876 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 26/50 | Loss: 1.6019 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 27/50 | Loss: 1.5897 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 28/50 | Loss: 1.5888 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 29/50 | Loss: 1.5897 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 30/50 | Loss: 1.5888 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 31/50 | Loss: 1.6226 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 32/50 | Loss: 1.5927 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 33/50 | Loss: 1.6041 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 34/50 | Loss: 1.5954 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 35/50 | Loss: 1.5957 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 36/50 | Loss: 1.6183 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 37/50 | Loss: 1.5974 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 38/50 | Loss: 1.6260 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 39/50 | Loss: 1.5938 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 40/50 | Loss: 1.5904 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 41/50 | Loss: 1.6032 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 42/50 | Loss: 1.6217 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 43/50 | Loss: 1.6024 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 44/50 | Loss: 1.6026 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 45/50 | Loss: 1.5991 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 46/50 | Loss: 1.6406 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 47/50 | Loss: 1.6118 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 48/50 | Loss: 1.6662 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 49/50 | Loss: 1.6168 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 50/50 | Loss: 1.5973 | Avg Q-Value: 0.40\n",
      "100%|██████████| 50/50 [04:44<00:00,  5.70s/it]\n",
      "INFO:root:Policy updated.\n",
      " 21%|██        | 4167/20000 [1:47:21<4:02:24,  1.09it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.86709D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  3.54486D+02    |proj g|=  6.18185D-01\n",
      "\n",
      "At iterate    2    f=  3.53725D+02    |proj g|=  5.63492D-01\n",
      "\n",
      "At iterate    3    f=  3.52634D+02    |proj g|=  5.72596D-01\n",
      "\n",
      "At iterate    4    f=  3.52618D+02    |proj g|=  1.22043D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.558 0.23  0.156 0.614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  3.52618D+02    |proj g|=  9.91716D-03\n",
      "\n",
      "At iterate    6    f=  3.52618D+02    |proj g|=  1.97721D-03\n",
      "\n",
      "At iterate    7    f=  3.52618D+02    |proj g|=  6.74361D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   6.744D-04   3.526D+02\n",
      "  F =   352.61802377337636     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:14<00:00, 3514.15it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.7291 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 2/50 | Loss: 0.6859 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 3/50 | Loss: 0.6593 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 4/50 | Loss: 0.6543 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 5/50 | Loss: 0.6435 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 6/50 | Loss: 0.6416 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 7/50 | Loss: 0.6377 | Avg Q-Value: 0.00\n",
      "INFO:root:Iter 8/50 | Loss: 0.6396 | Avg Q-Value: 0.00\n",
      "INFO:root:Iter 9/50 | Loss: 0.6317 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 10/50 | Loss: 0.6323 | Avg Q-Value: 0.00\n",
      "INFO:root:Iter 11/50 | Loss: 0.7004 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 12/50 | Loss: 0.6721 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 13/50 | Loss: 0.6779 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 14/50 | Loss: 0.6693 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 15/50 | Loss: 0.6694 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 16/50 | Loss: 0.6720 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 17/50 | Loss: 0.6777 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 18/50 | Loss: 0.6669 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 19/50 | Loss: 0.6675 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 20/50 | Loss: 0.6805 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 21/50 | Loss: 0.6874 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 22/50 | Loss: 0.6623 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 23/50 | Loss: 0.6605 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 24/50 | Loss: 0.6701 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 25/50 | Loss: 0.6575 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 26/50 | Loss: 0.6730 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 27/50 | Loss: 0.6696 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 28/50 | Loss: 0.6661 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 29/50 | Loss: 0.6585 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 30/50 | Loss: 0.6610 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 31/50 | Loss: 0.7543 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 32/50 | Loss: 0.6870 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 33/50 | Loss: 0.6883 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 34/50 | Loss: 0.6863 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 35/50 | Loss: 0.6805 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 36/50 | Loss: 0.6765 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 37/50 | Loss: 0.6750 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 38/50 | Loss: 0.6779 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 39/50 | Loss: 0.6765 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 40/50 | Loss: 0.6737 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 41/50 | Loss: 0.6808 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 42/50 | Loss: 0.6717 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 43/50 | Loss: 0.6704 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 44/50 | Loss: 0.6713 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 45/50 | Loss: 0.6704 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 46/50 | Loss: 0.6747 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 47/50 | Loss: 0.6683 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 48/50 | Loss: 0.6729 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 49/50 | Loss: 0.7140 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 50/50 | Loss: 0.7389 | Avg Q-Value: 0.38\n",
      "100%|██████████| 50/50 [04:31<00:00,  5.44s/it]\n",
      "INFO:root:Policy updated.\n",
      " 21%|██        | 4240/20000 [1:52:07<6:54:57,  1.58s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.14002D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  3.82289D+02    |proj g|=  6.34117D-01\n",
      "\n",
      "At iterate    2    f=  3.81730D+02    |proj g|=  5.83290D-01\n",
      "\n",
      "At iterate    3    f=  3.80961D+02    |proj g|=  5.33465D-01\n",
      "\n",
      "At iterate    4    f=  3.80929D+02    |proj g|=  1.55461D-01\n",
      "\n",
      "At iterate    5    f=  3.80929D+02    |proj g|=  5.45682D-02\n",
      "\n",
      "At iterate    6    f=  3.80929D+02    |proj g|=  2.56164D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.525 0.213 0.207 0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    7    f=  3.80929D+02    |proj g|=  4.52364D-04\n",
      "\n",
      "At iterate    8    f=  3.80929D+02    |proj g|=  5.97022D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   5.970D-05   3.809D+02\n",
      "  F =   380.92872583742684     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:16<00:00, 3024.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.7768 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 2/50 | Loss: 0.7570 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 3/50 | Loss: 0.7133 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 4/50 | Loss: 0.7019 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 5/50 | Loss: 0.7007 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 6/50 | Loss: 0.6966 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 7/50 | Loss: 0.7024 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 8/50 | Loss: 0.6890 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 9/50 | Loss: 0.6914 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 10/50 | Loss: 0.8278 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 11/50 | Loss: 0.7277 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 12/50 | Loss: 0.7072 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 13/50 | Loss: 0.6982 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 14/50 | Loss: 0.7188 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 15/50 | Loss: 0.6906 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 16/50 | Loss: 0.6960 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 17/50 | Loss: 0.6965 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 18/50 | Loss: 0.6927 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 19/50 | Loss: 0.6928 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 20/50 | Loss: 0.6987 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 21/50 | Loss: 0.7634 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 22/50 | Loss: 0.7222 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 23/50 | Loss: 0.7328 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 24/50 | Loss: 0.7285 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 25/50 | Loss: 0.7213 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 26/50 | Loss: 0.7198 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 27/50 | Loss: 0.7159 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 28/50 | Loss: 0.7195 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 29/50 | Loss: 0.7501 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 30/50 | Loss: 0.7284 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 31/50 | Loss: 0.7569 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 32/50 | Loss: 0.7127 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 33/50 | Loss: 0.7081 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 34/50 | Loss: 0.7103 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 35/50 | Loss: 0.7093 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 36/50 | Loss: 0.7023 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 37/50 | Loss: 0.7050 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 38/50 | Loss: 0.7337 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 39/50 | Loss: 0.7039 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 40/50 | Loss: 0.7029 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 41/50 | Loss: 0.7971 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 42/50 | Loss: 0.7419 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 43/50 | Loss: 0.7292 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 44/50 | Loss: 0.7276 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 45/50 | Loss: 0.7561 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 46/50 | Loss: 0.7391 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 47/50 | Loss: 0.7251 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 48/50 | Loss: 0.7263 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 49/50 | Loss: 0.7291 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 50/50 | Loss: 0.7284 | Avg Q-Value: 0.76\n",
      "100%|██████████| 50/50 [04:47<00:00,  5.75s/it]\n",
      "INFO:root:Policy updated.\n",
      " 23%|██▎       | 4507/20000 [1:57:12<5:12:26,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 4635/20000 [1:57:12<3:30:51,  1.21it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.49966D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.16566D+02    |proj g|=  6.33399D-01\n",
      "\n",
      "At iterate    2    f=  4.15878D+02    |proj g|=  5.85022D-01\n",
      "\n",
      "At iterate    3    f=  4.14932D+02    |proj g|=  5.70596D-01\n",
      "\n",
      "At iterate    4    f=  4.14905D+02    |proj g|=  1.71950D-01\n",
      "\n",
      "At iterate    5    f=  4.14904D+02    |proj g|=  5.86013D-02\n",
      "\n",
      "At iterate    6    f=  4.14904D+02    |proj g|=  1.95458D-02\n",
      "\n",
      "At iterate    7    f=  4.14904D+02    |proj g|=  5.79360D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.562 0.224 0.178 0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  4.14904D+02    |proj g|=  5.06229D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   5.062D-05   4.149D+02\n",
      "  F =   414.90417026058242     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:21<00:00, 2277.78it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.9844 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 2/50 | Loss: 0.8860 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 3/50 | Loss: 0.8605 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 4/50 | Loss: 0.8564 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 5/50 | Loss: 0.8492 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 6/50 | Loss: 0.8535 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 7/50 | Loss: 0.8458 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 8/50 | Loss: 0.8447 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 9/50 | Loss: 0.8453 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 10/50 | Loss: 0.8430 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 11/50 | Loss: 0.8998 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 12/50 | Loss: 0.8484 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 13/50 | Loss: 0.8453 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 14/50 | Loss: 0.8465 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 15/50 | Loss: 0.8427 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 16/50 | Loss: 0.8431 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 17/50 | Loss: 0.8537 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 18/50 | Loss: 0.8456 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 19/50 | Loss: 0.8437 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 20/50 | Loss: 0.8444 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 21/50 | Loss: 0.9515 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 22/50 | Loss: 0.8801 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 23/50 | Loss: 0.8743 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 24/50 | Loss: 0.8870 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 25/50 | Loss: 0.8779 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 26/50 | Loss: 0.8714 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 27/50 | Loss: 0.8675 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 28/50 | Loss: 0.8748 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 29/50 | Loss: 0.8789 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 30/50 | Loss: 0.8679 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 31/50 | Loss: 0.9438 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 32/50 | Loss: 0.8783 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 33/50 | Loss: 0.8673 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 34/50 | Loss: 0.8680 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 35/50 | Loss: 0.8666 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 36/50 | Loss: 1.1448 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 37/50 | Loss: 0.8707 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 38/50 | Loss: 0.8641 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 39/50 | Loss: 0.8650 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 40/50 | Loss: 0.8695 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 41/50 | Loss: 1.0229 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 42/50 | Loss: 0.9291 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 43/50 | Loss: 0.8882 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 44/50 | Loss: 0.9030 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 45/50 | Loss: 0.9023 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 46/50 | Loss: 0.8858 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 47/50 | Loss: 0.8976 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 48/50 | Loss: 0.9382 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 49/50 | Loss: 0.8845 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 50/50 | Loss: 0.9127 | Avg Q-Value: 0.62\n",
      "100%|██████████| 50/50 [05:01<00:00,  6.03s/it]\n",
      "INFO:root:Policy updated.\n",
      " 24%|██▍       | 4843/20000 [2:02:37<4:18:16,  1.02s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.76990D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.45381D+02    |proj g|=  6.86979D-01\n",
      "\n",
      "At iterate    2    f=  4.44898D+02    |proj g|=  6.31331D-01\n",
      "\n",
      "At iterate    3    f=  4.44686D+02    |proj g|=  4.88362D-01\n",
      "\n",
      "At iterate    4    f=  4.44431D+02    |proj g|=  2.55748D-01\n",
      "\n",
      "At iterate    5    f=  4.44430D+02    |proj g|=  4.40477D-02\n",
      "\n",
      "At iterate    6    f=  4.44430D+02    |proj g|=  1.81393D-02\n",
      "\n",
      "At iterate    7    f=  4.44430D+02    |proj g|=  3.26303D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.452 0.188 0.241 0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  4.44430D+02    |proj g|=  7.31896D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   7.319D-04   4.444D+02\n",
      "  F =   444.43027256103613     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:17<00:00, 2784.96it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.0521 | Avg Q-Value: -0.08\n",
      "INFO:root:Iter 2/50 | Loss: 1.0425 | Avg Q-Value: -0.03\n",
      "INFO:root:Iter 3/50 | Loss: 1.0227 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 4/50 | Loss: 1.0261 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 5/50 | Loss: 1.0170 | Avg Q-Value: -0.01\n",
      "INFO:root:Iter 6/50 | Loss: 1.0291 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 7/50 | Loss: 1.0181 | Avg Q-Value: 0.02\n",
      "INFO:root:Iter 8/50 | Loss: 1.0144 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 9/50 | Loss: 1.0081 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 10/50 | Loss: 1.0064 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 11/50 | Loss: 1.0430 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 12/50 | Loss: 1.0729 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 13/50 | Loss: 1.0387 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 14/50 | Loss: 1.0471 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 15/50 | Loss: 1.0349 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 16/50 | Loss: 1.1036 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 17/50 | Loss: 1.0342 | Avg Q-Value: 0.14\n",
      "INFO:root:Iter 18/50 | Loss: 1.3650 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 19/50 | Loss: 1.0957 | Avg Q-Value: 0.15\n",
      "INFO:root:Iter 20/50 | Loss: 1.0344 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 21/50 | Loss: 1.0529 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 22/50 | Loss: 1.0509 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 23/50 | Loss: 1.0560 | Avg Q-Value: 0.16\n",
      "INFO:root:Iter 24/50 | Loss: 1.0493 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 25/50 | Loss: 1.0459 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 26/50 | Loss: 1.0444 | Avg Q-Value: 0.17\n",
      "INFO:root:Iter 27/50 | Loss: 1.0480 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 28/50 | Loss: 1.0541 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 29/50 | Loss: 1.0390 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 30/50 | Loss: 1.1630 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 31/50 | Loss: 1.0549 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 32/50 | Loss: 1.0565 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 33/50 | Loss: 1.0696 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 34/50 | Loss: 1.0817 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 35/50 | Loss: 1.0488 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 36/50 | Loss: 1.0460 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 37/50 | Loss: 1.0435 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 38/50 | Loss: 1.0488 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 39/50 | Loss: 1.0584 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 40/50 | Loss: 1.0454 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 41/50 | Loss: 1.0587 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 42/50 | Loss: 1.0627 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 43/50 | Loss: 1.0674 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 44/50 | Loss: 1.0579 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 45/50 | Loss: 1.0563 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 46/50 | Loss: 1.0616 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 47/50 | Loss: 1.0606 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 48/50 | Loss: 1.0676 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 49/50 | Loss: 1.0522 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 50/50 | Loss: 1.0570 | Avg Q-Value: 0.35\n",
      "100%|██████████| 50/50 [05:04<00:00,  6.09s/it]\n",
      "INFO:root:Policy updated.\n",
      " 25%|██▍       | 4978/20000 [2:08:01<5:30:35,  1.32s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.10020D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.76334D+02    |proj g|=  6.82857D-01\n",
      "\n",
      "At iterate    2    f=  4.75933D+02    |proj g|=  6.34015D-01\n",
      "\n",
      "At iterate    3    f=  4.75805D+02    |proj g|=  3.79751D-01\n",
      "\n",
      "At iterate    4    f=  4.75603D+02    |proj g|=  6.16394D-02\n",
      "\n",
      "At iterate    5    f=  4.75603D+02    |proj g|=  8.06857D-03\n",
      "\n",
      "At iterate    6    f=  4.75603D+02    |proj g|=  1.38700D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.418 0.186 0.313 0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    7    f=  4.75603D+02    |proj g|=  3.87726D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   3.877D-05   4.756D+02\n",
      "  F =   475.60296167590639     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:18<00:00, 2648.65it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.2367 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 2/50 | Loss: 1.2094 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 3/50 | Loss: 1.1958 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 4/50 | Loss: 1.1894 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 5/50 | Loss: 1.1797 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 6/50 | Loss: 1.1788 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 7/50 | Loss: 1.1776 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 8/50 | Loss: 1.3265 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 9/50 | Loss: 1.1706 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 10/50 | Loss: 1.1809 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 11/50 | Loss: 1.2068 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 12/50 | Loss: 1.2033 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 13/50 | Loss: 1.2169 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 14/50 | Loss: 1.2210 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 15/50 | Loss: 1.1973 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 16/50 | Loss: 1.2139 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 17/50 | Loss: 1.1996 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 18/50 | Loss: 1.4087 | Avg Q-Value: 0.69\n",
      "INFO:root:Iter 19/50 | Loss: 1.2121 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 20/50 | Loss: 1.2002 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 21/50 | Loss: 1.1988 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 22/50 | Loss: 1.1983 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 23/50 | Loss: 1.2544 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 24/50 | Loss: 1.1932 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 25/50 | Loss: 1.2022 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 26/50 | Loss: 1.1910 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 27/50 | Loss: 1.1908 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 28/50 | Loss: 1.2052 | Avg Q-Value: 0.78\n",
      "INFO:root:Iter 29/50 | Loss: 1.1971 | Avg Q-Value: 0.78\n",
      "INFO:root:Iter 30/50 | Loss: 1.2018 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 31/50 | Loss: 1.2111 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 32/50 | Loss: 1.2273 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 33/50 | Loss: 1.2480 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 34/50 | Loss: 1.2110 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 35/50 | Loss: 1.2089 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 36/50 | Loss: 1.2601 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 37/50 | Loss: 1.2162 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 38/50 | Loss: 1.2460 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 39/50 | Loss: 1.2064 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 40/50 | Loss: 1.2506 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 41/50 | Loss: 1.2173 | Avg Q-Value: 0.91\n",
      "INFO:root:Iter 42/50 | Loss: 1.2114 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 43/50 | Loss: 1.2226 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 44/50 | Loss: 1.2103 | Avg Q-Value: 0.95\n",
      "INFO:root:Iter 45/50 | Loss: 1.2496 | Avg Q-Value: 0.91\n",
      "INFO:root:Iter 46/50 | Loss: 1.2083 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 47/50 | Loss: 1.3852 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 48/50 | Loss: 1.2194 | Avg Q-Value: 0.94\n",
      "INFO:root:Iter 49/50 | Loss: 1.2096 | Avg Q-Value: 0.93\n",
      "INFO:root:Iter 50/50 | Loss: 1.2078 | Avg Q-Value: 0.96\n",
      "100%|██████████| 50/50 [04:48<00:00,  5.78s/it]\n",
      "INFO:root:Policy updated.\n",
      " 26%|██▋       | 5256/20000 [2:13:10<4:21:00,  1.06s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.33648D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  4.94659D+02    |proj g|=  6.67109D-01\n",
      "\n",
      "At iterate    2    f=  4.94285D+02    |proj g|=  6.28983D-01\n",
      "\n",
      "At iterate    3    f=  4.94117D+02    |proj g|=  3.73770D-01\n",
      "\n",
      "At iterate    4    f=  4.93899D+02    |proj g|=  3.81836D-01\n",
      "\n",
      "At iterate    5    f=  4.93896D+02    |proj g|=  2.96800D-02\n",
      "\n",
      "At iterate    6    f=  4.93896D+02    |proj g|=  8.80654D-03\n",
      "\n",
      "At iterate    7    f=  4.93896D+02    |proj g|=  8.19209D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.413 0.174 0.375 0.444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    8    f=  4.93896D+02    |proj g|=  9.13440D-04\n",
      "\n",
      "At iterate    9    f=  4.93896D+02    |proj g|=  4.84483D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     11     12     0     0   4.845D-05   4.939D+02\n",
      "  F =   493.89627779672162     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:18<00:00, 2776.94it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.1470 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 2/50 | Loss: 1.1270 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 3/50 | Loss: 1.1345 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 4/50 | Loss: 1.1197 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 5/50 | Loss: 1.1147 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 6/50 | Loss: 1.1341 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 7/50 | Loss: 1.1239 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 8/50 | Loss: 1.1086 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 9/50 | Loss: 1.1052 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 10/50 | Loss: 1.1843 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 11/50 | Loss: 1.1175 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 12/50 | Loss: 1.1132 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 13/50 | Loss: 1.1218 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 14/50 | Loss: 1.1177 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 15/50 | Loss: 1.1069 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 16/50 | Loss: 1.1137 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 17/50 | Loss: 1.1028 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 18/50 | Loss: 1.1021 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 19/50 | Loss: 1.1035 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 20/50 | Loss: 1.1177 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 21/50 | Loss: 1.1278 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 22/50 | Loss: 1.1396 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 23/50 | Loss: 1.1230 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 24/50 | Loss: 1.1353 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 25/50 | Loss: 1.1272 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 26/50 | Loss: 1.2058 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 27/50 | Loss: 1.1359 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 28/50 | Loss: 1.1226 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 29/50 | Loss: 1.1224 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 30/50 | Loss: 1.1181 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 31/50 | Loss: 1.1290 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 32/50 | Loss: 1.1226 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 33/50 | Loss: 1.1228 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 34/50 | Loss: 1.1393 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 35/50 | Loss: 1.1259 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 36/50 | Loss: 1.1279 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 37/50 | Loss: 1.1229 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 38/50 | Loss: 1.1326 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 39/50 | Loss: 1.1214 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 40/50 | Loss: 1.1255 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 41/50 | Loss: 1.1325 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 42/50 | Loss: 1.1313 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 43/50 | Loss: 1.1341 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 44/50 | Loss: 1.1345 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 45/50 | Loss: 1.1422 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 46/50 | Loss: 1.1303 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 47/50 | Loss: 1.1399 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 48/50 | Loss: 1.1287 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 49/50 | Loss: 1.1373 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 50/50 | Loss: 1.1305 | Avg Q-Value: 0.62\n",
      "100%|██████████| 50/50 [04:45<00:00,  5.72s/it]\n",
      "INFO:root:Policy updated.\n",
      " 27%|██▋       | 5390/20000 [2:18:15<5:18:35,  1.31s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.62367D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  5.23473D+02    |proj g|=  6.75595D-01\n",
      "\n",
      "At iterate    2    f=  5.23035D+02    |proj g|=  6.34330D-01\n",
      "\n",
      "At iterate    3    f=  5.22822D+02    |proj g|=  3.69185D-01\n",
      "\n",
      "At iterate    4    f=  5.22565D+02    |proj g|=  3.79606D-01\n",
      "\n",
      "At iterate    5    f=  5.22561D+02    |proj g|=  3.60880D-02\n",
      "\n",
      "At iterate    6    f=  5.22561D+02    |proj g|=  1.44623D-02\n",
      "\n",
      "At iterate    7    f=  5.22561D+02    |proj g|=  1.25465D-02\n",
      "\n",
      "At iterate    8    f=  5.22561D+02    |proj g|=  8.08153D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.417 0.152 0.372 0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  5.22561D+02    |proj g|=  4.70442D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     11     12     0     0   4.704D-05   5.226D+02\n",
      "  F =   522.56076508195576     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:21<00:00, 2330.51it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.7844 | Avg Q-Value: 0.01\n",
      "INFO:root:Iter 2/50 | Loss: 0.7295 | Avg Q-Value: -0.06\n",
      "INFO:root:Iter 3/50 | Loss: 0.6934 | Avg Q-Value: -0.11\n",
      "INFO:root:Iter 4/50 | Loss: 0.6846 | Avg Q-Value: -0.08\n",
      "INFO:root:Iter 5/50 | Loss: 0.7724 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 6/50 | Loss: 0.6728 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 7/50 | Loss: 0.6690 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 8/50 | Loss: 0.6733 | Avg Q-Value: -0.05\n",
      "INFO:root:Iter 9/50 | Loss: 0.6643 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 10/50 | Loss: 0.6709 | Avg Q-Value: -0.04\n",
      "INFO:root:Iter 11/50 | Loss: 0.7268 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 12/50 | Loss: 0.6981 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 13/50 | Loss: 0.6884 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 14/50 | Loss: 0.6937 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 15/50 | Loss: 0.6834 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 16/50 | Loss: 0.6869 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 17/50 | Loss: 0.6825 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 18/50 | Loss: 0.6856 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 19/50 | Loss: 0.6830 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 20/50 | Loss: 0.6874 | Avg Q-Value: 0.06\n",
      "INFO:root:Iter 21/50 | Loss: 0.7396 | Avg Q-Value: 0.07\n",
      "INFO:root:Iter 22/50 | Loss: 0.7065 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 23/50 | Loss: 0.7062 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 24/50 | Loss: 0.6958 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 25/50 | Loss: 0.7113 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 26/50 | Loss: 0.7148 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 27/50 | Loss: 0.7224 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 28/50 | Loss: 0.6949 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 29/50 | Loss: 0.6959 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 30/50 | Loss: 0.7011 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 31/50 | Loss: 0.7482 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 32/50 | Loss: 0.7015 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 33/50 | Loss: 0.6991 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 34/50 | Loss: 0.7059 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 35/50 | Loss: 0.7031 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 36/50 | Loss: 0.7074 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 37/50 | Loss: 0.6955 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 38/50 | Loss: 0.7096 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 39/50 | Loss: 0.7201 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 40/50 | Loss: 0.7060 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 41/50 | Loss: 0.7757 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 42/50 | Loss: 0.7153 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 43/50 | Loss: 0.7057 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 44/50 | Loss: 0.7027 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 45/50 | Loss: 0.7116 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 46/50 | Loss: 0.7034 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 47/50 | Loss: 0.7165 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 48/50 | Loss: 0.7059 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 49/50 | Loss: 0.7084 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 50/50 | Loss: 0.7117 | Avg Q-Value: 0.26\n",
      "100%|██████████| 50/50 [05:00<00:00,  6.00s/it]\n",
      "INFO:root:Policy updated.\n",
      " 28%|██▊       | 5550/20000 [2:23:39<5:40:06,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5796/20000 [2:23:39<2:19:55,  1.69it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.01637D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  5.59304D+02    |proj g|=  6.62247D-01\n",
      "\n",
      "At iterate    2    f=  5.58793D+02    |proj g|=  6.13101D-01\n",
      "\n",
      "At iterate    3    f=  5.58486D+02    |proj g|=  3.96318D-01\n",
      "\n",
      "At iterate    4    f=  5.58178D+02    |proj g|=  4.19411D-01\n",
      "\n",
      "At iterate    5    f=  5.58172D+02    |proj g|=  7.48154D-02\n",
      "\n",
      "At iterate    6    f=  5.58172D+02    |proj g|=  3.36381D-02\n",
      "\n",
      "At iterate    7    f=  5.58172D+02    |proj g|=  2.50579D-02\n",
      "\n",
      "At iterate    8    f=  5.58172D+02    |proj g|=  8.01057D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.474 0.141 0.396 0.424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  5.58172D+02    |proj g|=  6.41886D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     11     12     0     0   6.419D-05   5.582D+02\n",
      "  F =   558.17188391284628     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:22<00:00, 2182.62it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.0852 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 2/50 | Loss: 0.8588 | Avg Q-Value: 0.18\n",
      "INFO:root:Iter 3/50 | Loss: 0.7711 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 4/50 | Loss: 0.7205 | Avg Q-Value: 0.04\n",
      "INFO:root:Iter 5/50 | Loss: 0.7098 | Avg Q-Value: 0.08\n",
      "INFO:root:Iter 6/50 | Loss: 0.6926 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 7/50 | Loss: 0.7078 | Avg Q-Value: 0.10\n",
      "INFO:root:Iter 8/50 | Loss: 0.6927 | Avg Q-Value: 0.11\n",
      "INFO:root:Iter 9/50 | Loss: 0.7078 | Avg Q-Value: 0.13\n",
      "INFO:root:Iter 10/50 | Loss: 0.6975 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 11/50 | Loss: 0.8601 | Avg Q-Value: 0.19\n",
      "INFO:root:Iter 12/50 | Loss: 0.6611 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 13/50 | Loss: 0.6626 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 14/50 | Loss: 0.6695 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 15/50 | Loss: 0.6538 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 16/50 | Loss: 0.6590 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 17/50 | Loss: 0.6526 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 18/50 | Loss: 0.6632 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 19/50 | Loss: 0.6449 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 20/50 | Loss: 0.6414 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 21/50 | Loss: 1.1047 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 22/50 | Loss: 0.8253 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 23/50 | Loss: 0.7011 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 24/50 | Loss: 0.7263 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 25/50 | Loss: 0.6877 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 26/50 | Loss: 0.6864 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 27/50 | Loss: 0.6902 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 28/50 | Loss: 0.6974 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 29/50 | Loss: 0.6772 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 30/50 | Loss: 0.6846 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 31/50 | Loss: 0.9651 | Avg Q-Value: -0.02\n",
      "INFO:root:Iter 32/50 | Loss: 0.7186 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 33/50 | Loss: 0.6835 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 34/50 | Loss: 0.6650 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 35/50 | Loss: 0.6669 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 36/50 | Loss: 0.6657 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 37/50 | Loss: 0.6583 | Avg Q-Value: 0.43\n",
      "INFO:root:Iter 38/50 | Loss: 0.6672 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 39/50 | Loss: 0.6600 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 40/50 | Loss: 0.6675 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 41/50 | Loss: 1.1970 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 42/50 | Loss: 0.8214 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 43/50 | Loss: 0.7286 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 44/50 | Loss: 0.7109 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 45/50 | Loss: 0.7171 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 46/50 | Loss: 0.7032 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 47/50 | Loss: 0.6972 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 48/50 | Loss: 0.7049 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 49/50 | Loss: 0.7101 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 50/50 | Loss: 0.7026 | Avg Q-Value: 0.58\n",
      "100%|██████████| 50/50 [04:55<00:00,  5.92s/it]\n",
      "INFO:root:Policy updated.\n",
      " 30%|██▉       | 5994/20000 [2:28:59<3:37:29,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 6119/20000 [2:28:59<2:23:06,  1.62it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.38855D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  5.96063D+02    |proj g|=  6.71659D-01\n",
      "\n",
      "At iterate    2    f=  5.95378D+02    |proj g|=  6.21709D-01\n",
      "\n",
      "At iterate    3    f=  5.95020D+02    |proj g|=  3.80327D-01\n",
      "\n",
      "At iterate    4    f=  5.94623D+02    |proj g|=  4.44555D-01\n",
      "\n",
      "At iterate    5    f=  5.94619D+02    |proj g|=  8.56392D-02\n",
      "\n",
      "At iterate    6    f=  5.94619D+02    |proj g|=  2.50726D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.485 0.126 0.436 0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    7    f=  5.94619D+02    |proj g|=  1.11938D-02\n",
      "\n",
      "At iterate    8    f=  5.94619D+02    |proj g|=  1.66561D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     10     11     0     0   1.666D-03   5.946D+02\n",
      "  F =   594.61892874180626     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:20<00:00, 2446.10it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.3055 | Avg Q-Value: 0.12\n",
      "INFO:root:Iter 2/50 | Loss: 1.2624 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 3/50 | Loss: 1.2532 | Avg Q-Value: 0.20\n",
      "INFO:root:Iter 4/50 | Loss: 1.2484 | Avg Q-Value: 0.21\n",
      "INFO:root:Iter 5/50 | Loss: 1.2476 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 6/50 | Loss: 1.2858 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 7/50 | Loss: 1.2485 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 8/50 | Loss: 1.2552 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 9/50 | Loss: 1.2399 | Avg Q-Value: 0.22\n",
      "INFO:root:Iter 10/50 | Loss: 1.2462 | Avg Q-Value: 0.23\n",
      "INFO:root:Iter 11/50 | Loss: 1.3140 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 12/50 | Loss: 1.2726 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 13/50 | Loss: 1.2617 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 14/50 | Loss: 1.2608 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 15/50 | Loss: 1.2600 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 16/50 | Loss: 1.2582 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 17/50 | Loss: 1.2550 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 18/50 | Loss: 1.2563 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 19/50 | Loss: 1.2549 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 20/50 | Loss: 1.2551 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 21/50 | Loss: 1.2876 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 22/50 | Loss: 1.2922 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 23/50 | Loss: 1.2824 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 24/50 | Loss: 1.2725 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 25/50 | Loss: 1.2732 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 26/50 | Loss: 1.3212 | Avg Q-Value: 0.41\n",
      "INFO:root:Iter 27/50 | Loss: 1.2801 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 28/50 | Loss: 1.2723 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 29/50 | Loss: 1.3006 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 30/50 | Loss: 1.2743 | Avg Q-Value: 0.42\n",
      "INFO:root:Iter 31/50 | Loss: 1.2812 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 32/50 | Loss: 1.2724 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 33/50 | Loss: 1.2769 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 34/50 | Loss: 1.2727 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 35/50 | Loss: 1.2749 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 36/50 | Loss: 1.2782 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 37/50 | Loss: 1.2809 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 38/50 | Loss: 1.3129 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 39/50 | Loss: 1.2956 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 40/50 | Loss: 1.2795 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 41/50 | Loss: 1.2904 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 42/50 | Loss: 1.2845 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 43/50 | Loss: 1.2844 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 44/50 | Loss: 1.2825 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 45/50 | Loss: 1.2939 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 46/50 | Loss: 1.2951 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 47/50 | Loss: 1.2827 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 48/50 | Loss: 1.2818 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 49/50 | Loss: 1.2801 | Avg Q-Value: 0.54\n",
      "INFO:root:Iter 50/50 | Loss: 1.2828 | Avg Q-Value: 0.55\n",
      "100%|██████████| 50/50 [05:02<00:00,  6.05s/it]\n",
      "INFO:root:Policy updated.\n",
      " 32%|███▏      | 6391/20000 [2:34:24<2:34:46,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.75012D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.33388D+02    |proj g|=  6.81789D-01\n",
      "\n",
      "At iterate    2    f=  6.32750D+02    |proj g|=  6.31978D-01\n",
      "\n",
      "At iterate    3    f=  6.32497D+02    |proj g|=  6.00725D-01\n",
      "\n",
      "At iterate    4    f=  6.32152D+02    |proj g|=  2.40465D-01\n",
      "\n",
      "At iterate    5    f=  6.32151D+02    |proj g|=  3.52878D-02\n",
      "\n",
      "At iterate    6    f=  6.32151D+02    |proj g|=  6.68677D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.464 0.148 0.421 0.366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    7    f=  6.32151D+02    |proj g|=  1.53259D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      7      9     10     0     0   1.533D-03   6.322D+02\n",
      "  F =   632.15101457669141     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:42<00:00, 1168.74it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.9431 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 2/50 | Loss: 0.9699 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 3/50 | Loss: 0.8758 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 4/50 | Loss: 0.8743 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 5/50 | Loss: 0.8628 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 6/50 | Loss: 0.8616 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 7/50 | Loss: 0.8809 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 8/50 | Loss: 0.8509 | Avg Q-Value: 0.32\n",
      "INFO:root:Iter 9/50 | Loss: 0.8525 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 10/50 | Loss: 0.8552 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 11/50 | Loss: 0.8888 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 12/50 | Loss: 0.8650 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 13/50 | Loss: 0.8697 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 14/50 | Loss: 0.8729 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 15/50 | Loss: 1.0369 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 16/50 | Loss: 0.8605 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 17/50 | Loss: 0.8542 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 18/50 | Loss: 0.8654 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 19/50 | Loss: 0.8551 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 20/50 | Loss: 0.8557 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 21/50 | Loss: 0.8930 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 22/50 | Loss: 0.8848 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 23/50 | Loss: 0.8973 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 24/50 | Loss: 0.8698 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 25/50 | Loss: 0.8709 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 26/50 | Loss: 0.8819 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 27/50 | Loss: 0.8707 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 28/50 | Loss: 0.8724 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 29/50 | Loss: 0.8756 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 30/50 | Loss: 0.8828 | Avg Q-Value: 0.60\n",
      "INFO:root:Iter 31/50 | Loss: 0.8929 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 32/50 | Loss: 0.8879 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 33/50 | Loss: 0.9479 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 34/50 | Loss: 0.8812 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 35/50 | Loss: 0.9008 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 36/50 | Loss: 0.9194 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 37/50 | Loss: 0.8794 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 38/50 | Loss: 0.8739 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 39/50 | Loss: 0.8688 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 40/50 | Loss: 0.8808 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 41/50 | Loss: 0.9015 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 42/50 | Loss: 0.8881 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 43/50 | Loss: 0.8799 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 44/50 | Loss: 0.8957 | Avg Q-Value: 0.80\n",
      "INFO:root:Iter 45/50 | Loss: 0.8771 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 46/50 | Loss: 0.8836 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 47/50 | Loss: 0.8843 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 48/50 | Loss: 0.9110 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 49/50 | Loss: 0.8789 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 50/50 | Loss: 0.8768 | Avg Q-Value: 0.81\n",
      "100%|██████████| 50/50 [04:38<00:00,  5.56s/it]\n",
      "INFO:root:Policy updated.\n",
      " 32%|███▏      | 6483/20000 [2:39:46<5:27:44,  1.45s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.95265D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.49282D+02    |proj g|=  6.72574D-01\n",
      "\n",
      "At iterate    2    f=  6.48826D+02    |proj g|=  6.19698D-01\n",
      "\n",
      "At iterate    3    f=  6.48722D+02    |proj g|=  6.04523D-01\n",
      "\n",
      "At iterate    4    f=  6.48557D+02    |proj g|=  4.43731D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.452 0.241 0.386 0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  6.48557D+02    |proj g|=  7.40536D-03\n",
      "\n",
      "At iterate    6    f=  6.48557D+02    |proj g|=  2.09149D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      9     0     0   2.091D-03   6.486D+02\n",
      "  F =   648.55666911506262     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:20<00:00, 2401.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 1.5788 | Avg Q-Value: 0.26\n",
      "INFO:root:Iter 2/50 | Loss: 1.5233 | Avg Q-Value: 0.24\n",
      "INFO:root:Iter 3/50 | Loss: 1.5057 | Avg Q-Value: 0.25\n",
      "INFO:root:Iter 4/50 | Loss: 1.5033 | Avg Q-Value: 0.28\n",
      "INFO:root:Iter 5/50 | Loss: 1.5055 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 6/50 | Loss: 1.4980 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 7/50 | Loss: 1.5067 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 8/50 | Loss: 1.4888 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 9/50 | Loss: 1.4880 | Avg Q-Value: 0.30\n",
      "INFO:root:Iter 10/50 | Loss: 1.5084 | Avg Q-Value: 0.31\n",
      "INFO:root:Iter 11/50 | Loss: 1.5342 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 12/50 | Loss: 1.5173 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 13/50 | Loss: 1.5262 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 14/50 | Loss: 1.5241 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 15/50 | Loss: 1.5109 | Avg Q-Value: 0.39\n",
      "INFO:root:Iter 16/50 | Loss: 1.5085 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 17/50 | Loss: 1.5218 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 18/50 | Loss: 1.5047 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 19/50 | Loss: 1.5075 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 20/50 | Loss: 1.5168 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 21/50 | Loss: 1.5689 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 22/50 | Loss: 1.5364 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 23/50 | Loss: 1.5346 | Avg Q-Value: 0.46\n",
      "INFO:root:Iter 24/50 | Loss: 1.5333 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 25/50 | Loss: 1.5245 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 26/50 | Loss: 1.5251 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 27/50 | Loss: 1.5266 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 28/50 | Loss: 1.5244 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 29/50 | Loss: 1.5382 | Avg Q-Value: 0.49\n",
      "INFO:root:Iter 30/50 | Loss: 1.5269 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 31/50 | Loss: 1.5904 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 32/50 | Loss: 1.5312 | Avg Q-Value: 0.53\n",
      "INFO:root:Iter 33/50 | Loss: 1.5254 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 34/50 | Loss: 1.5901 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 35/50 | Loss: 1.5233 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 36/50 | Loss: 1.5223 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 37/50 | Loss: 1.5230 | Avg Q-Value: 0.51\n",
      "INFO:root:Iter 38/50 | Loss: 1.5239 | Avg Q-Value: 0.50\n",
      "INFO:root:Iter 39/50 | Loss: 1.5246 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 40/50 | Loss: 1.5360 | Avg Q-Value: 0.52\n",
      "INFO:root:Iter 41/50 | Loss: 1.5813 | Avg Q-Value: 0.65\n",
      "INFO:root:Iter 42/50 | Loss: 1.5434 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 43/50 | Loss: 1.5949 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 44/50 | Loss: 1.5397 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 45/50 | Loss: 1.5356 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 46/50 | Loss: 1.5433 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 47/50 | Loss: 1.5485 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 48/50 | Loss: 1.5340 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 49/50 | Loss: 1.7609 | Avg Q-Value: 0.62\n",
      "INFO:root:Iter 50/50 | Loss: 1.5301 | Avg Q-Value: 0.63\n",
      "100%|██████████| 50/50 [04:25<00:00,  5.32s/it]\n",
      "INFO:root:Policy updated.\n",
      " 34%|███▎      | 6726/20000 [2:44:34<4:17:01,  1.16s/it]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.26379D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  6.77658D+02    |proj g|=  6.66571D-01\n",
      "\n",
      "At iterate    2    f=  6.77189D+02    |proj g|=  6.13529D-01\n",
      "\n",
      "At iterate    3    f=  6.77086D+02    |proj g|=  5.99171D-01\n",
      "\n",
      "At iterate    4    f=  6.76915D+02    |proj g|=  4.42635D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.455 0.241 0.362 0.382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  6.76915D+02    |proj g|=  8.54828D-03\n",
      "\n",
      "At iterate    6    f=  6.76915D+02    |proj g|=  6.68118D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      9     0     0   6.681D-05   6.769D+02\n",
      "  F =   676.91534406827975     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:21<00:00, 2328.86it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 0.7661 | Avg Q-Value: 0.27\n",
      "INFO:root:Iter 2/50 | Loss: 0.7768 | Avg Q-Value: 0.29\n",
      "INFO:root:Iter 3/50 | Loss: 0.7730 | Avg Q-Value: 0.33\n",
      "INFO:root:Iter 4/50 | Loss: 0.7212 | Avg Q-Value: 0.34\n",
      "INFO:root:Iter 5/50 | Loss: 0.7281 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 6/50 | Loss: 0.7175 | Avg Q-Value: 0.37\n",
      "INFO:root:Iter 7/50 | Loss: 0.7114 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 8/50 | Loss: 0.7079 | Avg Q-Value: 0.38\n",
      "INFO:root:Iter 9/50 | Loss: 0.7173 | Avg Q-Value: 0.36\n",
      "INFO:root:Iter 10/50 | Loss: 0.7026 | Avg Q-Value: 0.35\n",
      "INFO:root:Iter 11/50 | Loss: 0.7457 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 12/50 | Loss: 0.7367 | Avg Q-Value: 0.44\n",
      "INFO:root:Iter 13/50 | Loss: 0.7497 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 14/50 | Loss: 0.8229 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 15/50 | Loss: 0.7367 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 16/50 | Loss: 0.7313 | Avg Q-Value: 0.45\n",
      "INFO:root:Iter 17/50 | Loss: 0.7361 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 18/50 | Loss: 0.7464 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 19/50 | Loss: 0.7291 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 20/50 | Loss: 0.7282 | Avg Q-Value: 0.48\n",
      "INFO:root:Iter 21/50 | Loss: 0.7476 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 22/50 | Loss: 0.7526 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 23/50 | Loss: 0.7408 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 24/50 | Loss: 0.7430 | Avg Q-Value: 0.56\n",
      "INFO:root:Iter 25/50 | Loss: 0.7406 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 26/50 | Loss: 0.7380 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 27/50 | Loss: 0.7364 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 28/50 | Loss: 0.7425 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 29/50 | Loss: 0.7454 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 30/50 | Loss: 0.7351 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 31/50 | Loss: 0.7764 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 32/50 | Loss: 0.7466 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 33/50 | Loss: 0.7450 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 34/50 | Loss: 0.7479 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 35/50 | Loss: 0.7471 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 36/50 | Loss: 0.7429 | Avg Q-Value: 0.64\n",
      "INFO:root:Iter 37/50 | Loss: 0.7420 | Avg Q-Value: 0.67\n",
      "INFO:root:Iter 38/50 | Loss: 0.7552 | Avg Q-Value: 0.66\n",
      "INFO:root:Iter 39/50 | Loss: 0.7650 | Avg Q-Value: 0.63\n",
      "INFO:root:Iter 40/50 | Loss: 0.7542 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 41/50 | Loss: 0.7575 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 42/50 | Loss: 0.7546 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 43/50 | Loss: 0.7766 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 44/50 | Loss: 0.7510 | Avg Q-Value: 0.75\n",
      "INFO:root:Iter 45/50 | Loss: 0.7507 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 46/50 | Loss: 0.7514 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 47/50 | Loss: 0.7572 | Avg Q-Value: 0.74\n",
      "INFO:root:Iter 48/50 | Loss: 0.7572 | Avg Q-Value: 0.77\n",
      "INFO:root:Iter 49/50 | Loss: 0.7518 | Avg Q-Value: 0.76\n",
      "INFO:root:Iter 50/50 | Loss: 0.7652 | Avg Q-Value: 0.76\n",
      "100%|██████████| 50/50 [04:26<00:00,  5.34s/it]\n",
      "INFO:root:Policy updated.\n",
      " 35%|███▍      | 6993/20000 [2:49:24<3:35:35,  1.01it/s]INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.50881D+02    |proj g|=  1.00000D+00\n",
      "\n",
      "At iterate    1    f=  7.01711D+02    |proj g|=  6.71456D-01\n",
      "\n",
      "At iterate    2    f=  7.01253D+02    |proj g|=  6.17181D-01\n",
      "\n",
      "At iterate    3    f=  7.01168D+02    |proj g|=  6.02909D-01\n",
      "\n",
      "At iterate    4    f=  7.01023D+02    |proj g|=  4.69310D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Theta updated. New theta_hat: [0.457 0.264 0.346 0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  7.01023D+02    |proj g|=  2.73970D-03\n",
      "\n",
      "At iterate    6    f=  7.01023D+02    |proj g|=  3.28069D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      9     0     0   3.281D-04   7.010D+02\n",
      "  F =   701.02336827625652     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:22<00:00, 2195.55it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/50 | Loss: 2.1733 | Avg Q-Value: 0.40\n",
      "INFO:root:Iter 2/50 | Loss: 2.1269 | Avg Q-Value: 0.47\n",
      "INFO:root:Iter 3/50 | Loss: 2.1164 | Avg Q-Value: 0.55\n",
      "INFO:root:Iter 4/50 | Loss: 2.1101 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 5/50 | Loss: 2.1088 | Avg Q-Value: 0.57\n",
      "INFO:root:Iter 6/50 | Loss: 2.1131 | Avg Q-Value: 0.59\n",
      "INFO:root:Iter 7/50 | Loss: 4.0211 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 8/50 | Loss: 2.1340 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 9/50 | Loss: 2.1069 | Avg Q-Value: 0.61\n",
      "INFO:root:Iter 10/50 | Loss: 2.1067 | Avg Q-Value: 0.58\n",
      "INFO:root:Iter 11/50 | Loss: 2.1113 | Avg Q-Value: 0.68\n",
      "INFO:root:Iter 12/50 | Loss: 2.0996 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 13/50 | Loss: 2.0983 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 14/50 | Loss: 2.1182 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 15/50 | Loss: 2.1010 | Avg Q-Value: 0.70\n",
      "INFO:root:Iter 16/50 | Loss: 2.1029 | Avg Q-Value: 0.71\n",
      "INFO:root:Iter 17/50 | Loss: 2.1005 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 18/50 | Loss: 2.1016 | Avg Q-Value: 0.72\n",
      "INFO:root:Iter 19/50 | Loss: 2.1048 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 20/50 | Loss: 2.0950 | Avg Q-Value: 0.73\n",
      "INFO:root:Iter 21/50 | Loss: 2.1181 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 22/50 | Loss: 2.1179 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 23/50 | Loss: 2.1163 | Avg Q-Value: 0.85\n",
      "INFO:root:Iter 24/50 | Loss: 2.1216 | Avg Q-Value: 0.84\n",
      "INFO:root:Iter 25/50 | Loss: 2.1176 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 26/50 | Loss: 2.1205 | Avg Q-Value: 0.87\n",
      "INFO:root:Iter 27/50 | Loss: 2.1142 | Avg Q-Value: 0.82\n",
      "INFO:root:Iter 28/50 | Loss: 2.1271 | Avg Q-Value: 0.83\n",
      "INFO:root:Iter 29/50 | Loss: 2.1281 | Avg Q-Value: 0.86\n",
      "INFO:root:Iter 30/50 | Loss: 2.1173 | Avg Q-Value: 0.87\n",
      "INFO:root:Iter 31/50 | Loss: 2.1485 | Avg Q-Value: 1.02\n",
      "INFO:root:Iter 32/50 | Loss: 2.1205 | Avg Q-Value: 0.94\n",
      "INFO:root:Iter 33/50 | Loss: 2.1191 | Avg Q-Value: 0.99\n",
      "INFO:root:Iter 34/50 | Loss: 2.1348 | Avg Q-Value: 0.99\n",
      "INFO:root:Iter 35/50 | Loss: 2.1153 | Avg Q-Value: 0.99\n",
      "INFO:root:Iter 36/50 | Loss: 2.1127 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 37/50 | Loss: 2.1244 | Avg Q-Value: 0.99\n",
      "INFO:root:Iter 38/50 | Loss: 2.1138 | Avg Q-Value: 0.98\n",
      "INFO:root:Iter 39/50 | Loss: 2.1315 | Avg Q-Value: 0.97\n",
      "INFO:root:Iter 40/50 | Loss: 2.1161 | Avg Q-Value: 0.96\n",
      "INFO:root:Iter 41/50 | Loss: 2.1214 | Avg Q-Value: 1.07\n",
      "INFO:root:Iter 42/50 | Loss: 2.1148 | Avg Q-Value: 1.04\n",
      "INFO:root:Iter 43/50 | Loss: 2.1178 | Avg Q-Value: 1.05\n",
      " 86%|████████▌ | 43/50 [03:42<00:36,  5.17s/it]\n",
      " 35%|███▌      | 7023/20000 [2:53:30<5:20:37,  1.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# simulator.projected_volume_learner.is_terminated = True\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simulation_data \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_customers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CUSTOMERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m degradation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mdegradation_history)\n\u001b[1;32m      4\u001b[0m simulation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[0;32m~/degradation_learning/simulation.py:323\u001b[0m, in \u001b[0;36mSimulator.run\u001b[0;34m(self, num_customers)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# --- Check if policy update is needed ---\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_exploration_done \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreakdowns_since_last_update \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_update_threshold:\n\u001b[0;32m--> 323\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[0;32m~/degradation_learning/simulation.py:157\u001b[0m, in \u001b[0;36mSimulator._update_policy\u001b[0;34m(self, customer_idx)\u001b[0m\n\u001b[1;32m    148\u001b[0m u_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojected_volume_learner\u001b[38;5;241m.\u001b[39mget_estimate()\n\u001b[1;32m    149\u001b[0m dp_agent \u001b[38;5;241m=\u001b[39m DPAgent(\n\u001b[1;32m    150\u001b[0m     d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md,\n\u001b[1;32m    151\u001b[0m     u_hat\u001b[38;5;241m=\u001b[39mu_hat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp_params\n\u001b[1;32m    156\u001b[0m )\n\u001b[0;32m--> 157\u001b[0m \u001b[43mdp_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_hyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdp_agent \u001b[38;5;241m=\u001b[39m dp_agent\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_policy \u001b[38;5;241m=\u001b[39m dp_agent\u001b[38;5;241m.\u001b[39mget_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_params)\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:267\u001b[0m, in \u001b[0;36mDPAgent.train\u001b[0;34m(self, num_iterations, dataset_size, batch_size)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    266\u001b[0m     q_next_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network(ns_batch)\n\u001b[0;32m--> 267\u001b[0m     max_q_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_max_q_for_valid_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_next_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     target_q \u001b[38;5;241m=\u001b[39m r_batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m max_q_next\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# --- Update the Q-Network ---\u001b[39;00m\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:226\u001b[0m, in \u001b[0;36mDPAgent._get_max_q_for_valid_actions\u001b[0;34m(self, states_tensor, q_values_tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m         valid_actions_q \u001b[38;5;241m=\u001b[39m q_values_tensor[i, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Departure\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m         valid_actions_q \u001b[38;5;241m=\u001b[39m \u001b[43mq_values_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    227\u001b[0m     max_q_values[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(valid_actions_q)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_q_values\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# simulator.projected_volume_learner.is_terminated = True\n",
    "simulation_data = simulator.run(num_customers=NUM_CUSTOMERS)\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "simulation_df = pd.DataFrame(simulator.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "628dd0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulator.utility_updates\n",
    "\n",
    "# plot L2, and L-inf norms of utility updates\n",
    "L2_errors = [np.linalg.norm(update['u_hat'] - UTILITY_TRUE) for update in simulator.utility_updates]\n",
    "Linf_errors = [np.linalg.norm(update['u_hat'] - UTILITY_TRUE, ord=np.inf) for update in simulator.utility_updates]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(L2_errors, label='$L_2$ Norm Error', marker='o')\n",
    "plt.plot(Linf_errors, label='$L_\\infty$ Norm Error', marker='x')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Number of Customers Processed', fontsize=14)\n",
    "plt.ylabel('Error Norm', fontsize=14)\n",
    "\n",
    "plt.title('Convergence of $\\|\\hat u - u\\|$', fontsize=18)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.savefig('figures/utility_convergence.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting simulation for 20000 customers...\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]INFO:root:Customer 1: Diameter: 0.9884\n",
      "  0%|          | 1/20000 [00:06<34:50:53,  6.27s/it]INFO:root:Customer 2: Diameter: 0.7828\n",
      "  0%|          | 2/20000 [00:13<38:06:05,  6.86s/it]INFO:root:Customer 3: Diameter: 0.6376\n",
      "  0%|          | 3/20000 [00:21<41:00:59,  7.38s/it]INFO:root:Customer 4: Diameter: 0.5900\n",
      "  0%|          | 4/20000 [00:30<44:02:43,  7.93s/it]INFO:root:Customer 5: Diameter: 0.5694\n",
      "  0%|          | 5/20000 [00:40<48:18:54,  8.70s/it]INFO:root:Customer 6: Diameter: 0.3406\n",
      "  0%|          | 6/20000 [00:51<52:43:03,  9.49s/it]INFO:root:Customer 7: Diameter: 0.2370\n",
      "  0%|          | 7/20000 [01:03<57:18:27, 10.32s/it]INFO:root:Customer 8: Diameter: 0.4829\n",
      "  0%|          | 8/20000 [01:15<60:57:32, 10.98s/it]INFO:root:Customer 9: Diameter: 0.1942\n",
      "  0%|          | 9/20000 [01:28<63:48:52, 11.49s/it]INFO:root:Customer 10: Diameter: 0.1144\n",
      "  0%|          | 10/20000 [01:41<67:17:17, 12.12s/it]INFO:root:Customer 11: Diameter: 0.1846\n",
      "  0%|          | 11/20000 [01:56<70:39:28, 12.73s/it]INFO:root:Customer 12: Diameter: 0.2440\n",
      "  0%|          | 12/20000 [02:10<73:56:12, 13.32s/it]INFO:root:Customer 13: Diameter: 0.1568\n",
      "  0%|          | 13/20000 [02:26<77:39:07, 13.99s/it]INFO:root:Customer 14: Diameter: 0.1567\n",
      "  0%|          | 14/20000 [02:42<81:35:03, 14.70s/it]INFO:root:Customer 15: Diameter: 0.2055\n",
      "  0%|          | 15/20000 [03:00<86:25:42, 15.57s/it]INFO:root:Customer 16: Diameter: 0.1152\n",
      "  0%|          | 16/20000 [03:18<90:51:25, 16.37s/it]INFO:root:Customer 17: Diameter: 0.1793\n",
      "  0%|          | 17/20000 [03:37<94:58:46, 17.11s/it]INFO:root:Customer 18: Diameter: 0.0493\n",
      "  0%|          | 18/20000 [03:57<100:42:23, 18.14s/it]INFO:root:Customer 19: Diameter: 0.0651\n",
      "  0%|          | 19/20000 [04:20<108:02:03, 19.46s/it]INFO:root:Customer 20: Diameter: 0.0509\n",
      "  0%|          | 20/20000 [04:43<113:36:22, 20.47s/it]INFO:root:Customer 21: Diameter: 0.0355\n",
      "  0%|          | 21/20000 [05:05<116:10:14, 20.93s/it]INFO:root:Customer 22: Diameter: 0.0193\n",
      "  0%|          | 22/20000 [05:27<119:09:50, 21.47s/it]INFO:root:Customer 23: Diameter: 0.0184\n",
      "  0%|          | 23/20000 [05:52<123:52:43, 22.32s/it]INFO:root:Customer 24: Diameter: 0.0219\n",
      "  0%|          | 24/20000 [06:17<128:21:25, 23.13s/it]INFO:root:Customer 25: Diameter: 0.0089\n",
      "  0%|          | 25/20000 [06:43<133:12:58, 24.01s/it]INFO:root:Customer 26: Diameter: 0.0338\n",
      "  0%|          | 26/20000 [07:10<137:46:06, 24.83s/it]INFO:root:Customer 27: Diameter: 0.0200\n",
      "  0%|          | 27/20000 [07:36<139:54:03, 25.22s/it]INFO:root:Customer 28: Diameter: 0.0057\n",
      "  0%|          | 28/20000 [08:02<142:32:57, 25.69s/it]INFO:root:Customer 29: Diameter: 0.0089\n",
      "  0%|          | 29/20000 [08:30<145:15:34, 26.18s/it]INFO:root:Customer 30: Diameter: 0.0179\n",
      "  0%|          | 30/20000 [08:58<148:03:27, 26.69s/it]INFO:root:Customer 31: Diameter: 0.0070\n",
      "  0%|          | 31/20000 [09:28<153:52:50, 27.74s/it]INFO:root:Customer 32: Diameter: 0.0079\n",
      "  0%|          | 32/20000 [10:00<160:27:24, 28.93s/it]INFO:root:Customer 33: Diameter: 0.0030\n",
      "  0%|          | 33/20000 [10:31<164:57:44, 29.74s/it]INFO:root:Customer 34: Diameter: 0.0044\n",
      "  0%|          | 34/20000 [11:02<166:52:34, 30.09s/it]INFO:root:Customer 35: Diameter: 0.0025\n",
      "  0%|          | 35/20000 [11:35<171:32:08, 30.93s/it]INFO:root:Customer 36: Diameter: 0.0036\n",
      "  0%|          | 36/20000 [12:09<177:09:43, 31.95s/it]INFO:root:Customer 37: Diameter: 0.0023\n",
      "  0%|          | 37/20000 [12:45<182:44:55, 32.96s/it]INFO:root:Customer 38: Diameter: 0.0024\n",
      "  0%|          | 38/20000 [13:19<184:53:09, 33.34s/it]INFO:root:Customer 39: Diameter: 0.0019\n",
      "  0%|          | 39/20000 [13:53<186:25:46, 33.62s/it]INFO:root:Customer 40: Diameter: 0.0018\n",
      "  0%|          | 40/20000 [14:27<187:31:38, 33.82s/it]INFO:root:Customer 41: Diameter: 0.0007\n",
      "  0%|          | 41/20000 [15:03<190:22:13, 34.34s/it]INFO:root:Customer 42: Diameter: 0.0014\n",
      "  0%|          | 42/20000 [15:41<196:32:49, 35.45s/it]INFO:root:Customer 43: Diameter: 0.0012\n",
      "  0%|          | 43/20000 [16:18<198:24:26, 35.79s/it]INFO:root:Customer 44: Diameter: 0.0006\n",
      "  0%|          | 44/20000 [16:56<202:22:22, 36.51s/it]INFO:root:Customer 45: Diameter: 0.0004\n",
      "  0%|          | 45/20000 [17:34<205:11:13, 37.02s/it]INFO:root:Customer 46: Diameter: 0.0005\n",
      "  0%|          | 46/20000 [18:14<210:55:14, 38.05s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 47: Diameter: 0.0005\n",
      "  0%|          | 47/20000 [18:55<215:41:22, 38.92s/it]INFO:root:Customer 48: Diameter: 0.0002\n",
      "  0%|          | 48/20000 [19:36<218:38:32, 39.45s/it]INFO:root:Customer 49: Diameter: 0.0004\n",
      "  0%|          | 49/20000 [20:16<219:48:10, 39.66s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 50: Diameter: 0.0001\n",
      "  0%|          | 50/20000 [20:57<220:56:42, 39.87s/it]INFO:root:Customer 51: Diameter: 0.0003\n",
      "  0%|          | 51/20000 [21:38<223:02:15, 40.25s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 52: Diameter: 0.0002\n",
      "  0%|          | 52/20000 [22:20<225:50:51, 40.76s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 53: Diameter: 0.0002\n",
      "  0%|          | 53/20000 [23:03<230:37:33, 41.62s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 54: Diameter: 0.0002\n",
      "  0%|          | 54/20000 [23:47<234:41:12, 42.36s/it]WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "WARNING:root:Degenerate step in hit-and-run; skipping sample.\n",
      "INFO:root:Customer 55: Diameter: 0.0001\n",
      "  0%|          | 55/20000 [24:32<238:23:41, 43.03s/it]INFO:root:Exploration phase completed at customer 56.\n",
      "INFO:root:Updating optimal policy...\n",
      "INFO:root:Theta updated. New theta_hat: [0.    1.    0.667 1.   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         4 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09861D+00    |proj g|=  7.51808D-01\n",
      "\n",
      "At iterate    1    f=  5.26910D-01    |proj g|=  2.67514D-01\n",
      "\n",
      "At iterate    2    f=  3.05592D-01    |proj g|=  4.82350D-02\n",
      "\n",
      "At iterate    3    f=  3.00394D-01    |proj g|=  3.39379D-02\n",
      "\n",
      "At iterate    4    f=  2.94887D-01    |proj g|=  3.42631D-03\n",
      "\n",
      "At iterate    5    f=  2.94825D-01    |proj g|=  2.75754D-04\n",
      "\n",
      "At iterate    6    f=  2.94824D-01    |proj g|=  2.46829D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      7      9     0     3   2.468D-06   2.948D-01\n",
      "  F =  0.29482434307336192     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Using device: cuda\n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23052/50000 [00:07<00:09, 2922.60it/s]\n",
      "  0%|          | 55/20000 [24:41<149:14:27, 26.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# simulator.projected_volume_learner.is_terminated = True\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simulation_data \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_customers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CUSTOMERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m degradation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mdegradation_history)\n\u001b[1;32m      4\u001b[0m simulation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulator\u001b[38;5;241m.\u001b[39mhistory)\n",
      "File \u001b[0;32m~/degradation_learning/simulation.py:216\u001b[0m, in \u001b[0;36mSimulator.run\u001b[0;34m(self, num_customers)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExploration phase completed at customer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# First time policy setup\u001b[39;00m\n\u001b[1;32m    218\u001b[0m arrival_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m    219\u001b[0m     X_before, \n\u001b[1;32m    220\u001b[0m     customer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;241m0.0\u001b[39m]\n\u001b[1;32m    224\u001b[0m ])\n\u001b[1;32m    225\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_policy(arrival_state)\n",
      "File \u001b[0;32m~/degradation_learning/simulation.py:157\u001b[0m, in \u001b[0;36mSimulator._update_policy\u001b[0;34m(self, customer_idx)\u001b[0m\n\u001b[1;32m    148\u001b[0m u_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojected_volume_learner\u001b[38;5;241m.\u001b[39mget_estimate()\n\u001b[1;32m    149\u001b[0m dp_agent \u001b[38;5;241m=\u001b[39m DPAgent(\n\u001b[1;32m    150\u001b[0m     d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md,\n\u001b[1;32m    151\u001b[0m     u_hat\u001b[38;5;241m=\u001b[39mu_hat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp_params\n\u001b[1;32m    156\u001b[0m )\n\u001b[0;32m--> 157\u001b[0m \u001b[43mdp_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_hyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdp_agent \u001b[38;5;241m=\u001b[39m dp_agent\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_policy \u001b[38;5;241m=\u001b[39m dp_agent\u001b[38;5;241m.\u001b[39mget_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_params)\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:240\u001b[0m, in \u001b[0;36mDPAgent.train\u001b[0;34m(self, num_iterations, dataset_size, batch_size)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_iterations, dataset_size, batch_size):\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Main FQI training loop.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     experience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Unpack and convert to tensors\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m experience]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:178\u001b[0m, in \u001b[0;36mExperienceGenerator.generate\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    175\u001b[0m valid_actions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m phase_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    176\u001b[0m action \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(valid_actions) \u001b[38;5;66;03m# Explore randomly\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m reward, next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m dataset\u001b[38;5;241m.\u001b[39mappend((state, action, reward, next_state))\n\u001b[1;32m    181\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:117\u001b[0m, in \u001b[0;36mExperienceGenerator._step_environment\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    115\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegradation_learner\u001b[38;5;241m.\u001b[39mcum_baseline(machine_active_time_prev) \u001b[38;5;241m+\u001b[39m delta\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     mat_plus_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegradation_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_cum_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     f_i \u001b[38;5;241m=\u001b[39m mat_plus_f \u001b[38;5;241m-\u001b[39m machine_active_time_prev\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f_i \u001b[38;5;241m>\u001b[39m T_curr:\n",
      "File \u001b[0;32m~/degradation_learning/degradation_learner.py:210\u001b[0m, in \u001b[0;36mDegradationLearner.inverse_cum_baseline\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# brentq finds root of cum_baseline(t) - y = 0\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbrentq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcum_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/res/lib/python3.9/site-packages/scipy/optimize/_zeros_py.py:799\u001b[0m, in \u001b[0;36mbrentq\u001b[0;34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrtol too small (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_rtol\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mg\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    798\u001b[0m f \u001b[38;5;241m=\u001b[39m _wrap_nan_raise(f)\n\u001b[0;32m--> 799\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_zeros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_brentq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_c(full_output, r)\n",
      "File \u001b[0;32m~/anaconda3/envs/res/lib/python3.9/site-packages/scipy/optimize/_zeros_py.py:90\u001b[0m, in \u001b[0;36m_wrap_nan_raise.<locals>.f_raise\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_raise\u001b[39m(x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 90\u001b[0m     fx \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     f_raise\u001b[38;5;241m.\u001b[39m_function_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fx):\n",
      "File \u001b[0;32m~/degradation_learning/degradation_learner.py:210\u001b[0m, in \u001b[0;36mDegradationLearner.inverse_cum_baseline.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# brentq finds root of cum_baseline(t) - y = 0\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m brentq(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcum_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m y, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_time)\n",
      "File \u001b[0;32m~/degradation_learning/degradation_learner.py:193\u001b[0m, in \u001b[0;36mDegradationLearner.cum_baseline\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 193\u001b[0m integral, _ \u001b[38;5;241m=\u001b[39m \u001b[43mquad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsabs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m integral\n",
      "File \u001b[0;32m~/anaconda3/envs/res/lib/python3.9/site-packages/scipy/integrate/_quadpack_py.py:465\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst, complex_func)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43m_quad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/res/lib/python3.9/site-packages/scipy/integrate/_quadpack_py.py:577\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m infbounds \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quadpack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qagse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsabs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepsrel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _quadpack\u001b[38;5;241m.\u001b[39m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n",
      "File \u001b[0;32m~/degradation_learning/degradation_learner.py:193\u001b[0m, in \u001b[0;36mDegradationLearner.cum_baseline.<locals>.<lambda>\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 193\u001b[0m integral, _ \u001b[38;5;241m=\u001b[39m quad(\u001b[38;5;28;01mlambda\u001b[39;00m u: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m, t, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, epsabs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m integral\n",
      "File \u001b[0;32m~/anaconda3/envs/res/lib/python3.9/site-packages/scipy/stats/_kde.py:268\u001b[0m, in \u001b[0;36mgaussian_kde.evaluate\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    267\u001b[0m output_dtype, spec \u001b[38;5;241m=\u001b[39m _get_output_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance, points)\n\u001b[0;32m--> 268\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_kernel_estimate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcho_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec0fff9",
   "metadata": {},
   "source": [
    "## Training policy under perfect information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8793230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Generating 500000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:08<00:00, 59906.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:59<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 35\u001b[0m\n\u001b[1;32m     22\u001b[0m perfect_dpagent \u001b[38;5;241m=\u001b[39m DPAgent(\n\u001b[1;32m     23\u001b[0m     d\u001b[38;5;241m=\u001b[39mD,\n\u001b[1;32m     24\u001b[0m     u_hat\u001b[38;5;241m=\u001b[39mUTILITY_TRUE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     params\u001b[38;5;241m=\u001b[39mmdp_params,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# weight = torch.load('weights/perfect_dpagent_q_network.pth', map_location=torch.device('cuda'))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# perfect_dpagent.q_network.load_state_dict(weight)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# perfect_dpagent.q_network.to(perfect_dpagent.device)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# perfect_dpagent.q_network.eval()\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mperfect_dpagent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m perfect_policy \u001b[38;5;241m=\u001b[39m perfect_dpagent\u001b[38;5;241m.\u001b[39mget_policy(\n\u001b[1;32m     42\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m}\n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:267\u001b[0m, in \u001b[0;36mDPAgent.train\u001b[0;34m(self, num_iterations, dataset_size, batch_size)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    266\u001b[0m     q_next_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network(ns_batch)\n\u001b[0;32m--> 267\u001b[0m     max_q_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_max_q_for_valid_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_next_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     target_q \u001b[38;5;241m=\u001b[39m r_batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m max_q_next\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# --- Update the Q-Network ---\u001b[39;00m\n",
      "File \u001b[0;32m~/degradation_learning/policy.py:227\u001b[0m, in \u001b[0;36mDPAgent._get_max_q_for_valid_actions\u001b[0;34m(self, states_tensor, q_values_tensor)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Departure\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         valid_actions_q \u001b[38;5;241m=\u001b[39m q_values_tensor[i, \u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m--> 227\u001b[0m     max_q_values[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_actions_q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_q_values\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class PerfectDegradationLearner:\n",
    "    def __init__(self, d, theta_true, hazard_model):\n",
    "        self.d = d\n",
    "        self.theta_true = theta_true\n",
    "        self.hazard_model = hazard_model  # Placeholder, not used\n",
    "        \n",
    "    def get_theta(self):\n",
    "        return self.theta_true\n",
    "    \n",
    "    def cum_baseline(self, t):\n",
    "        return self.hazard_model.Lambda_0(t)\n",
    "    \n",
    "    def inverse_cum_baseline(self, u):\n",
    "        return self.hazard_model.Lambda_0_inverse(u)\n",
    "    \n",
    "perfect_degradation_learner = PerfectDegradationLearner(\n",
    "    d=D, \n",
    "    theta_true=THETA_TRUE,\n",
    "    hazard_model=usage_exp_hazard_model,\n",
    ")\n",
    "\n",
    "perfect_dpagent = DPAgent(\n",
    "    d=D,\n",
    "    u_hat=UTILITY_TRUE,\n",
    "    time_normalize=True,\n",
    "    degradation_learner=perfect_degradation_learner,\n",
    "    customer_generator=customer_gen,\n",
    "    params=mdp_params,\n",
    ")\n",
    "\n",
    "# weight = torch.load('weights/perfect_dpagent_q_network.pth', map_location=torch.device('cuda'))\n",
    "# perfect_dpagent.q_network.load_state_dict(weight)\n",
    "# perfect_dpagent.q_network.to(perfect_dpagent.device)\n",
    "# perfect_dpagent.q_network.eval()\n",
    "perfect_dpagent.train(\n",
    "    num_iterations=50,\n",
    "    dataset_size=500000,\n",
    "    batch_size=1024\n",
    ")\n",
    "\n",
    "perfect_policy = perfect_dpagent.get_policy(\n",
    "    {'type': 'greedy', 'epsilon': 0.1, 'tau': 1.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeat = 10\n",
    "histories = []\n",
    "\n",
    "for _ in range(num_repeat):\n",
    "    history = simulator.run_full_exploit(10000, policy)\n",
    "    history = pd.DataFrame(history)\n",
    "    \n",
    "    history['net_profit'] = history['profit'] + history['loss']\n",
    "    # calculate cumulative profit and loss\n",
    "    history['cumulative_net_profit'] = history['net_profit'].cumsum()\n",
    "    histories.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot cumulative profit and loss over time\n",
    "plt.plot(history['calendar_time'], history['cumulative_net_profit'], label='Cumulative Net Profit')\n",
    "plt.xlabel('Calendar Time')\n",
    "plt.ylabel('Cumulative Net Profit')\n",
    "plt.title('Cumulative Net Profit Over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e64b25",
   "metadata": {},
   "source": [
    "### Debugging: Look at experience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent\n",
    "\n",
    "print(simulator.projected_volume_learner.get_estimate())\n",
    "print(UTILITY_TRUE)\n",
    "\n",
    "dp_agent = DPAgent(\n",
    "    d=simulator.d,\n",
    "    u_hat=simulator.projected_volume_learner.get_estimate(),\n",
    "    time_normalize=simulator.time_normalize,\n",
    "    degradation_learner=simulator.degradation_learner,\n",
    "    customer_generator=simulator.customer_generator,\n",
    "    params=simulator.mdp_params\n",
    ")\n",
    "\n",
    "dataset = dp_agent.experience_generator.generate(500)\n",
    "\n",
    "for data in dataset:\n",
    "    state, action, reward, next_state = data\n",
    "    print(\"State:\", state.round(3))\n",
    "    print(\"Action:\", dp_agent.experience_generator.ACTION_MAP[action])\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Next State:\", next_state.round(3))\n",
    "    print(\"-----\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "degradation_learner.fit(degradation_df)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f90ec4",
   "metadata": {},
   "source": [
    "Testing Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "X_i = df.loc[i, 'sum_of_contexts_after']\n",
    "I_i = 3 # df.loc[i, '']\n",
    "x_i = df.loc[i+1, 'customer_context']\n",
    "T_i = df.loc[i+1, 'rental_duration']\n",
    "\n",
    "arrival_state = np.concatenate([\n",
    "    X_i,\n",
    "    x_i,\n",
    "    [T_i, I_i, 0.0]\n",
    "])\n",
    "action_arrival = optimal_policy(arrival_state)\n",
    "action_map = {0: 'Give Max Acceptable Price', 1: 'Shutdown'}\n",
    "print(f\"Sample Arrival State. Optimal Action: {action_map[action_arrival]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Departure State\n",
    "departure_state = np.concatenate([\n",
    "    X_i+x_i*10, \n",
    "    np.zeros(D), \n",
    "    [0.0, I_i, 1.0]\n",
    "])\n",
    "action_departure = optimal_policy(departure_state)\n",
    "action_map = {2: 'Replace Machine', 3: 'Do Not Replace'}\n",
    "print(f\"Sample Departure State. Optimal Action: {action_map[action_departure]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
