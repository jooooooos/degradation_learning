{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from simulation import Simulator, CustomerGenerator\n",
    "from hazard_models import ExponentialHazard\n",
    "from utility_learner import ProjectedVolumeLearner, diam\n",
    "from degradation_learner import DegradationLearner\n",
    "\n",
    "from utils import unit_ball_rejection_sample, correct_signs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e08dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Sampling Functions ---\n",
    "# def context_sampler() -> np.ndarray:\n",
    "#     \"\"\"Samples a customer's context vector from a uniform distribution.\"\"\"\n",
    "#     return np.random.uniform(low=0.0, high=1.0, size=D)\n",
    "\n",
    "def context_sampler() -> np.ndarray:\n",
    "    \"\"\"Samples a customer's context vector uniformly from the unit ball.\"\"\"\n",
    "    return np.abs(unit_ball_rejection_sample(D))\n",
    "\n",
    "def rental_sampler() -> float:\n",
    "    \"\"\"Samples a customer's desired rental duration from an exponential distribution.\"\"\"\n",
    "    return np.random.exponential(scale=10.0)\n",
    "\n",
    "def interarrival_sampler() -> float:\n",
    "    \"\"\"Samples the time until the next customer arrives.\"\"\"\n",
    "    return np.random.exponential(scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulation Configuration ---\n",
    "D = 4                                  # Dimension of context vectors\n",
    "LAMBDA_VAL = 0.001                     # Baseline hazard constant\n",
    "NUM_CUSTOMERS = 100000                   # Total number of customers to simulate, i.e. T\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(41)\n",
    "\n",
    "# Ground truth vectors\n",
    "THETA_TRUE = np.array([0.5, 0.2, 0.1, 0.3])#$, 0.4])    # For degradation\n",
    "UTILITY_TRUE = context_sampler()  # For customer's willingness to pay\n",
    "\n",
    "# --- Machine's Pricing Vector 'r' ---\n",
    "# This is a fallback pricing vector, when we don't feed u_hat to calculate_price\n",
    "PRICING_R = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e600551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_exp_hazard_model = ExponentialHazard(lambda_val=LAMBDA_VAL)\n",
    "# spontaneous_exp_hazard_model = None # ExponentialHazard(lambda_val=0.01)\n",
    "\n",
    "customer_gen = CustomerGenerator(\n",
    "    d=D,\n",
    "    context_sampler=context_sampler,\n",
    "    rental_sampler=rental_sampler,\n",
    "    interarrival_sampler=interarrival_sampler\n",
    ")\n",
    "\n",
    "centroid_params = {\n",
    "    # 'num_samples': 2000,\n",
    "    # 'thin': None,\n",
    "    # 'burn_in': 500 * D ** 2,\n",
    "    # 'tol': 1e-4,\n",
    "    # 'rho_target': 0.01\n",
    "}\n",
    "\n",
    "termination_rule = lambda diameter: diameter < 0.0005  # Example custom termination rule\n",
    "\n",
    "projected_volume_learner = ProjectedVolumeLearner(\n",
    "    T=NUM_CUSTOMERS, \n",
    "    d=D, \n",
    "    centroid_params=centroid_params,\n",
    "    incentive_constant=1.1,\n",
    "    termination_rule=termination_rule,\n",
    ")\n",
    "\n",
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.99,             # Discount factor\n",
    "    'learning_rate': 1e-3,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "training_hyperparams = {\n",
    "    'num_iterations': 50, # Number of training iterations per policy update\n",
    "    'dataset_size': 500000,      # Number of transitions to generate for the offline dataset\n",
    "    'batch_size': 2048           # Batch size for training\n",
    "}\n",
    "\n",
    "policy_params = {\n",
    "    'type': 'softmax',\n",
    "    'tau': 1.0,\n",
    "    'epsilon': 0.1,\n",
    "}\n",
    "\n",
    "# Instantiate the Simulator with the new parameters\n",
    "simulator = Simulator(\n",
    "    d=D,\n",
    "    T=NUM_CUSTOMERS,\n",
    "    \n",
    "    theta_true=THETA_TRUE,\n",
    "    utility_true=UTILITY_TRUE,\n",
    "    pricing_r=PRICING_R,\n",
    "    \n",
    "    usage_hazard_model=usage_exp_hazard_model,\n",
    "    customer_generator=customer_gen,\n",
    "    projected_volume_learner=projected_volume_learner,  # Use default ProjectedVolumeLearner\n",
    "    \n",
    "    mdp_params=mdp_params,\n",
    "    training_hyperparams=training_hyperparams,\n",
    "    policy_params=policy_params,\n",
    "    policy_update_threshold=5,\n",
    "    time_normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.projected_volume_learner.is_terminated = True\n",
    "simulation_data = simulator.run(num_customers=NUM_CUSTOMERS)\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "simulation_df = pd.DataFrame(simulator.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0fff9",
   "metadata": {},
   "source": [
    "## Training policy under perfect information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8793230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent\n",
    "\n",
    "class PerfectDegradationLearner:\n",
    "    def __init__(self, d, theta_true, hazard_model):\n",
    "        self.d = d\n",
    "        self.theta_true = theta_true\n",
    "        self.hazard_model = hazard_model  # Placeholder, not used\n",
    "        \n",
    "    def get_theta(self):\n",
    "        return self.theta_true\n",
    "    \n",
    "    def cum_baseline(self, t):\n",
    "        return self.hazard_model.Lambda_0(t)\n",
    "    \n",
    "    def inverse_cum_baseline(self, u):\n",
    "        return self.hazard_model.Lambda_0_inverse(u)\n",
    "    \n",
    "perfect_degradation_learner = PerfectDegradationLearner(\n",
    "    d=D, \n",
    "    theta_true=THETA_TRUE,\n",
    "    hazard_model=usage_exp_hazard_model,\n",
    ")\n",
    "perfect_dpagent = DPAgent(\n",
    "    d=D,\n",
    "    u_hat=UTILITY_TRUE,\n",
    "    time_normalize=True,\n",
    "    degradation_learner=perfect_degradation_learner,\n",
    "    customer_generator=customer_gen,\n",
    "    params=mdp_params,\n",
    ")\n",
    "\n",
    "perfect_dpagent.train(\n",
    "    num_iterations=50,\n",
    "    dataset_size=5000000,\n",
    "    batch_size=1024\n",
    ")\n",
    "\n",
    "perfect_policy = perfect_dpagent.get_policy(\n",
    "    {'type': 'greedy'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e64b25",
   "metadata": {},
   "source": [
    "### Debugging: Look at experience dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent\n",
    "\n",
    "print(simulator.projected_volume_learner.get_estimate())\n",
    "print(UTILITY_TRUE)\n",
    "\n",
    "dp_agent = DPAgent(\n",
    "    d=simulator.d,\n",
    "    u_hat=simulator.projected_volume_learner.get_estimate(),\n",
    "    time_normalize=simulator.time_normalize,\n",
    "    degradation_learner=simulator.degradation_learner,\n",
    "    customer_generator=simulator.customer_generator,\n",
    "    params=simulator.mdp_params\n",
    ")\n",
    "\n",
    "dataset = dp_agent.experience_generator.generate(500)\n",
    "\n",
    "for data in dataset:\n",
    "    state, action, reward, next_state = data\n",
    "    print(\"State:\", state.round(3))\n",
    "    print(\"Action:\", dp_agent.experience_generator.ACTION_MAP[action])\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Next State:\", next_state.round(3))\n",
    "    print(\"-----\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "degradation_df = pd.DataFrame(simulator.degradation_history)\n",
    "degradation_learner.fit(degradation_df)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f90ec4",
   "metadata": {},
   "source": [
    "Testing Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "X_i = df.loc[i, 'sum_of_contexts_after']\n",
    "I_i = 3 # df.loc[i, '']\n",
    "x_i = df.loc[i+1, 'customer_context']\n",
    "T_i = df.loc[i+1, 'rental_duration']\n",
    "\n",
    "arrival_state = np.concatenate([\n",
    "    X_i,\n",
    "    x_i,\n",
    "    [T_i, I_i, 0.0]\n",
    "])\n",
    "action_arrival = optimal_policy(arrival_state)\n",
    "action_map = {0: 'Give Max Acceptable Price', 1: 'Shutdown'}\n",
    "print(f\"Sample Arrival State. Optimal Action: {action_map[action_arrival]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Departure State\n",
    "departure_state = np.concatenate([\n",
    "    X_i+x_i*10, \n",
    "    np.zeros(D), \n",
    "    [0.0, I_i, 1.0]\n",
    "])\n",
    "action_departure = optimal_policy(departure_state)\n",
    "action_map = {2: 'Replace Machine', 3: 'Do Not Replace'}\n",
    "print(f\"Sample Departure State. Optimal Action: {action_map[action_departure]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
