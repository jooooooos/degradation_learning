{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bf8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from simulation import Simulator, CustomerGenerator\n",
    "from hazard_models import ExponentialHazard\n",
    "from utility_learner import ProjectedVolumeLearner, diam\n",
    "from degradation_learner import DegradationLearner\n",
    "\n",
    "from utils import unit_ball_rejection_sample, correct_signs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e08dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Sampling Functions ---\n",
    "# def context_sampler() -> np.ndarray:\n",
    "#     \"\"\"Samples a customer's context vector from a uniform distribution.\"\"\"\n",
    "#     return np.random.uniform(low=0.0, high=1.0, size=D)\n",
    "\n",
    "def context_sampler() -> np.ndarray:\n",
    "    \"\"\"Samples a customer's context vector uniformly from the unit ball.\"\"\"\n",
    "    return np.abs(unit_ball_rejection_sample(D))\n",
    "\n",
    "def rental_sampler() -> float:\n",
    "    \"\"\"Samples a customer's desired rental duration from an exponential distribution.\"\"\"\n",
    "    return np.random.exponential(scale=20.0)\n",
    "\n",
    "def interarrival_sampler() -> float:\n",
    "    \"\"\"Samples the time until the next customer arrives.\"\"\"\n",
    "    return np.random.exponential(scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc2c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulation Configuration ---\n",
    "D = 5                                  # Dimension of context vectors\n",
    "LAMBDA_VAL = 0.001                     # Baseline hazard constant\n",
    "NUM_CUSTOMERS = 2000                   # Total number of customers to simulate, i.e. T\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(41)\n",
    "\n",
    "# Ground truth vectors\n",
    "THETA_TRUE = np.array([0.5, 0.2, 0.1, 0.3, 0.4])    # For degradation\n",
    "UTILITY_TRUE = context_sampler()  # For customer's willingness to pay\n",
    "\n",
    "# --- Machine's Pricing Vector 'r' ---\n",
    "# This is a fallback pricing vector, when we don't feed u_hat to calculate_price\n",
    "PRICING_R = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e600551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_exp_hazard_model = ExponentialHazard(lambda_val=LAMBDA_VAL)\n",
    "# spontaneous_exp_hazard_model = None # ExponentialHazard(lambda_val=0.01)\n",
    "\n",
    "customer_gen = CustomerGenerator(\n",
    "    d=D,\n",
    "    context_sampler=context_sampler,\n",
    "    rental_sampler=rental_sampler,\n",
    "    interarrival_sampler=interarrival_sampler\n",
    ")\n",
    "\n",
    "centroid_params = {\n",
    "    # 'num_samples': 2000,\n",
    "    # 'thin': None,\n",
    "    # 'burn_in': 500 * D ** 2,\n",
    "    # 'tol': 1e-4,\n",
    "    # 'rho_target': 0.01\n",
    "}\n",
    "\n",
    "termination_rule = lambda diameter: diameter < 0.11  # Example custom termination rule\n",
    "\n",
    "projected_volume_learner = ProjectedVolumeLearner(\n",
    "    T=NUM_CUSTOMERS, \n",
    "    d=D, \n",
    "    centroid_params=centroid_params,\n",
    "    incentive_constant=1.1,\n",
    "    termination_rule=termination_rule,\n",
    ")\n",
    "\n",
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.999,             # Discount factor\n",
    "    'learning_rate': 1e-4,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "training_hyperparams = {\n",
    "    'num_iterations': 10, # Number of training iterations per policy update\n",
    "    'dataset_size': 5000,      # Number of transitions to generate for the offline dataset\n",
    "    'batch_size': 256           # Batch size for training\n",
    "}\n",
    "\n",
    "# Instantiate the Simulator with the new parameters\n",
    "simulator = Simulator(\n",
    "    d=D,\n",
    "    T=NUM_CUSTOMERS,\n",
    "    \n",
    "    theta_true=THETA_TRUE,\n",
    "    utility_true=UTILITY_TRUE,\n",
    "    pricing_r=PRICING_R,\n",
    "    \n",
    "    usage_hazard_model=usage_exp_hazard_model,\n",
    "    customer_generator=customer_gen,\n",
    "    projected_volume_learner=projected_volume_learner,  # Use default ProjectedVolumeLearner\n",
    "    \n",
    "    mdp_params=mdp_params,\n",
    "    training_hyperparams=training_hyperparams,\n",
    "    policy_update_threshold=5,\n",
    "    time_normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce816c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from degradation_learner import breslow_baseline_estimator\n",
    "\n",
    "# degradation_history = pd.DataFrame(simulator.degradation_history)\n",
    "# degradation_history['life_id'] = (degradation_history['event'].shift(1).fillna(-99) == 1).cumsum()  # 0 after breakdown\n",
    "\n",
    "# breslow_df = breslow_baseline_estimator(\n",
    "#     degradation_history, \n",
    "#     simulator.degradation_learner.get_theta()\n",
    "# )\n",
    "\n",
    "# breslow_df = breslow_df[breslow_df['delta_t'] > 0]\n",
    "# times = breslow_df['time'].values\n",
    "# lambda_step = breslow_df['lambda_0'].values\n",
    "\n",
    "# times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc7f36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting simulation for 2000 customers...\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Set parameter Username\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter LicenseID to value 2651514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Set parameter LicenseID to value 2651514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2026-04-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gurobipy:Academic license - for non-commercial use only - expires 2026-04-14\n",
      "INFO:root:Customer 1: Diameter: 1.0038\n",
      "  0%|          | 1/2000 [00:02<1:34:01,  2.82s/it]INFO:root:Customer 2: Diameter: 0.7896\n",
      "  0%|          | 2/2000 [00:05<1:38:08,  2.95s/it]INFO:root:Customer 3: Diameter: 0.6292\n",
      "  0%|          | 3/2000 [00:09<1:43:27,  3.11s/it]INFO:root:Customer 4: Diameter: 0.5915\n",
      "  0%|          | 4/2000 [00:12<1:48:21,  3.26s/it]INFO:root:Customer 5: Diameter: 0.6412\n",
      "  0%|          | 5/2000 [00:16<1:54:21,  3.44s/it]INFO:root:Customer 6: Diameter: 0.2740\n",
      "  0%|          | 6/2000 [00:20<2:01:32,  3.66s/it]INFO:root:Customer 7: Diameter: 0.4080\n",
      "  0%|          | 7/2000 [00:24<2:08:23,  3.87s/it]INFO:root:Customer 8: Diameter: 0.2810\n",
      "  0%|          | 8/2000 [00:29<2:14:43,  4.06s/it]INFO:root:Customer 9: Diameter: 0.3840\n",
      "  0%|          | 9/2000 [00:34<2:23:09,  4.31s/it]INFO:root:Customer 10: Diameter: 0.4161\n",
      "  0%|          | 10/2000 [00:39<2:29:55,  4.52s/it]INFO:root:Customer 11: Diameter: 0.2253\n",
      "  1%|          | 11/2000 [00:44<2:36:38,  4.73s/it]INFO:root:Customer 12: Diameter: 0.2270\n",
      "  1%|          | 12/2000 [00:49<2:43:41,  4.94s/it]INFO:root:Customer 13: Diameter: 0.1966\n",
      "  1%|          | 13/2000 [00:55<2:51:00,  5.16s/it]INFO:root:Customer 14: Diameter: 0.1062\n",
      "  1%|          | 14/2000 [01:01<2:57:49,  5.37s/it]INFO:root:Exploration phase completed at customer 15.\n",
      "INFO:root:Updating optimal policy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Using device: mps\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         5 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09861D+00    |proj g|=  4.06656D-01\n",
      "\n",
      "At iterate    1    f=  9.43172D-01    |proj g|=  3.58128D-01\n",
      "\n",
      "At iterate    2    f=  7.50631D-01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5      2      3      3     0     5   0.000D+00   7.506D-01\n",
      "  F =  0.75063115752825205     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Generating 50000 experience samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:12<00:00, 4125.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FQI training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iter 1/100 | Loss: 0.9747 | Avg Q-Value: 1.00\n",
      "INFO:root:Iter 2/100 | Loss: 0.8193 | Avg Q-Value: 1.04\n",
      "INFO:root:Iter 3/100 | Loss: 0.7593 | Avg Q-Value: 1.09\n",
      "INFO:root:Iter 4/100 | Loss: 0.7283 | Avg Q-Value: 1.15\n",
      "INFO:root:Iter 5/100 | Loss: 0.7146 | Avg Q-Value: 1.15\n",
      "INFO:root:Iter 6/100 | Loss: 0.7047 | Avg Q-Value: 1.13\n",
      "INFO:root:Iter 7/100 | Loss: 0.6979 | Avg Q-Value: 1.17\n",
      "INFO:root:Iter 8/100 | Loss: 0.6951 | Avg Q-Value: 1.17\n",
      "INFO:root:Iter 9/100 | Loss: 0.6908 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 10/100 | Loss: 0.6865 | Avg Q-Value: 1.19\n",
      "INFO:root:Iter 11/100 | Loss: 0.4133 | Avg Q-Value: 1.42\n",
      "INFO:root:Iter 12/100 | Loss: 0.3567 | Avg Q-Value: 1.45\n",
      "INFO:root:Iter 13/100 | Loss: 0.3535 | Avg Q-Value: 1.45\n",
      "INFO:root:Iter 14/100 | Loss: 0.3525 | Avg Q-Value: 1.48\n",
      "INFO:root:Iter 15/100 | Loss: 0.3513 | Avg Q-Value: 1.47\n",
      "INFO:root:Iter 16/100 | Loss: 0.3504 | Avg Q-Value: 1.48\n",
      "INFO:root:Iter 17/100 | Loss: 0.3503 | Avg Q-Value: 1.48\n",
      "INFO:root:Iter 18/100 | Loss: 0.3508 | Avg Q-Value: 1.48\n",
      "INFO:root:Iter 19/100 | Loss: 0.3507 | Avg Q-Value: 1.46\n",
      "INFO:root:Iter 20/100 | Loss: 0.3494 | Avg Q-Value: 1.46\n",
      "INFO:root:Iter 21/100 | Loss: 0.4765 | Avg Q-Value: 1.65\n",
      "INFO:root:Iter 22/100 | Loss: 0.4252 | Avg Q-Value: 1.71\n",
      "INFO:root:Iter 23/100 | Loss: 0.4170 | Avg Q-Value: 1.71\n",
      "INFO:root:Iter 24/100 | Loss: 0.4156 | Avg Q-Value: 1.73\n",
      "INFO:root:Iter 25/100 | Loss: 0.4144 | Avg Q-Value: 1.72\n",
      "INFO:root:Iter 26/100 | Loss: 0.4169 | Avg Q-Value: 1.73\n",
      "INFO:root:Iter 27/100 | Loss: 0.4146 | Avg Q-Value: 1.67\n",
      "INFO:root:Iter 28/100 | Loss: 0.4132 | Avg Q-Value: 1.75\n",
      "INFO:root:Iter 29/100 | Loss: 0.4123 | Avg Q-Value: 1.67\n",
      "INFO:root:Iter 30/100 | Loss: 0.4133 | Avg Q-Value: 1.72\n",
      "INFO:root:Iter 31/100 | Loss: 0.3409 | Avg Q-Value: 1.94\n",
      "INFO:root:Iter 32/100 | Loss: 0.2987 | Avg Q-Value: 1.89\n",
      "INFO:root:Iter 33/100 | Loss: 0.2977 | Avg Q-Value: 1.91\n",
      "INFO:root:Iter 34/100 | Loss: 0.2966 | Avg Q-Value: 1.90\n",
      "INFO:root:Iter 35/100 | Loss: 0.2977 | Avg Q-Value: 1.95\n",
      "INFO:root:Iter 36/100 | Loss: 0.2969 | Avg Q-Value: 1.93\n",
      "INFO:root:Iter 37/100 | Loss: 0.2968 | Avg Q-Value: 1.97\n",
      "INFO:root:Iter 38/100 | Loss: 0.2965 | Avg Q-Value: 1.90\n",
      "INFO:root:Iter 39/100 | Loss: 0.2964 | Avg Q-Value: 1.92\n",
      "INFO:root:Iter 40/100 | Loss: 0.2951 | Avg Q-Value: 1.90\n",
      "INFO:root:Iter 41/100 | Loss: 0.4117 | Avg Q-Value: 2.10\n",
      "INFO:root:Iter 42/100 | Loss: 0.3672 | Avg Q-Value: 2.06\n",
      "INFO:root:Iter 43/100 | Loss: 0.3667 | Avg Q-Value: 2.12\n",
      "INFO:root:Iter 44/100 | Loss: 0.3653 | Avg Q-Value: 2.09\n",
      "INFO:root:Iter 45/100 | Loss: 0.3649 | Avg Q-Value: 2.09\n",
      "INFO:root:Iter 46/100 | Loss: 0.3630 | Avg Q-Value: 2.15\n",
      "INFO:root:Iter 47/100 | Loss: 0.3616 | Avg Q-Value: 2.10\n",
      "INFO:root:Iter 48/100 | Loss: 0.3623 | Avg Q-Value: 2.14\n",
      "INFO:root:Iter 49/100 | Loss: 0.3614 | Avg Q-Value: 2.10\n",
      "INFO:root:Iter 50/100 | Loss: 0.3627 | Avg Q-Value: 2.09\n",
      "INFO:root:Iter 51/100 | Loss: 0.3071 | Avg Q-Value: 2.23\n",
      "INFO:root:Iter 52/100 | Loss: 0.2615 | Avg Q-Value: 2.24\n",
      "INFO:root:Iter 53/100 | Loss: 0.2600 | Avg Q-Value: 2.24\n",
      "INFO:root:Iter 54/100 | Loss: 0.2596 | Avg Q-Value: 2.29\n",
      "INFO:root:Iter 55/100 | Loss: 0.2600 | Avg Q-Value: 2.21\n",
      "INFO:root:Iter 56/100 | Loss: 0.2596 | Avg Q-Value: 2.24\n",
      "INFO:root:Iter 57/100 | Loss: 0.2598 | Avg Q-Value: 2.24\n",
      "INFO:root:Iter 58/100 | Loss: 0.2595 | Avg Q-Value: 2.28\n",
      "INFO:root:Iter 59/100 | Loss: 0.2593 | Avg Q-Value: 2.28\n",
      "INFO:root:Iter 60/100 | Loss: 0.2593 | Avg Q-Value: 2.27\n",
      "INFO:root:Iter 61/100 | Loss: 0.3855 | Avg Q-Value: 2.44\n",
      "INFO:root:Iter 62/100 | Loss: 0.3365 | Avg Q-Value: 2.43\n",
      "INFO:root:Iter 63/100 | Loss: 0.3365 | Avg Q-Value: 2.48\n",
      "INFO:root:Iter 64/100 | Loss: 0.3324 | Avg Q-Value: 2.47\n",
      "INFO:root:Iter 65/100 | Loss: 0.3316 | Avg Q-Value: 2.45\n",
      "INFO:root:Iter 66/100 | Loss: 0.3327 | Avg Q-Value: 2.49\n",
      "INFO:root:Iter 67/100 | Loss: 0.3324 | Avg Q-Value: 2.45\n",
      "INFO:root:Iter 68/100 | Loss: 0.3329 | Avg Q-Value: 2.51\n",
      "INFO:root:Iter 69/100 | Loss: 0.3312 | Avg Q-Value: 2.39\n",
      "INFO:root:Iter 70/100 | Loss: 0.3309 | Avg Q-Value: 2.42\n",
      "INFO:root:Iter 71/100 | Loss: 0.2968 | Avg Q-Value: 2.58\n",
      "INFO:root:Iter 72/100 | Loss: 0.2508 | Avg Q-Value: 2.58\n",
      "INFO:root:Iter 73/100 | Loss: 0.2506 | Avg Q-Value: 2.56\n",
      "INFO:root:Iter 74/100 | Loss: 0.2513 | Avg Q-Value: 2.53\n",
      "INFO:root:Iter 75/100 | Loss: 0.2507 | Avg Q-Value: 2.56\n",
      "INFO:root:Iter 76/100 | Loss: 0.2503 | Avg Q-Value: 2.55\n",
      "INFO:root:Iter 77/100 | Loss: 0.2507 | Avg Q-Value: 2.56\n",
      "INFO:root:Iter 78/100 | Loss: 0.2508 | Avg Q-Value: 2.58\n",
      "INFO:root:Iter 79/100 | Loss: 0.2503 | Avg Q-Value: 2.55\n",
      "INFO:root:Iter 80/100 | Loss: 0.2502 | Avg Q-Value: 2.54\n",
      "INFO:root:Iter 81/100 | Loss: 0.3465 | Avg Q-Value: 2.68\n",
      "INFO:root:Iter 82/100 | Loss: 0.3041 | Avg Q-Value: 2.64\n",
      "INFO:root:Iter 83/100 | Loss: 0.3038 | Avg Q-Value: 2.71\n",
      "INFO:root:Iter 84/100 | Loss: 0.3028 | Avg Q-Value: 2.65\n",
      "INFO:root:Iter 85/100 | Loss: 0.3017 | Avg Q-Value: 2.65\n",
      "INFO:root:Iter 86/100 | Loss: 0.3019 | Avg Q-Value: 2.71\n",
      "INFO:root:Iter 87/100 | Loss: 0.3006 | Avg Q-Value: 2.70\n",
      "INFO:root:Iter 88/100 | Loss: 0.3011 | Avg Q-Value: 2.67\n",
      "INFO:root:Iter 89/100 | Loss: 0.3004 | Avg Q-Value: 2.73\n",
      "INFO:root:Iter 90/100 | Loss: 0.3016 | Avg Q-Value: 2.70\n",
      "INFO:root:Iter 91/100 | Loss: 0.2959 | Avg Q-Value: 2.81\n",
      "INFO:root:Iter 92/100 | Loss: 0.2496 | Avg Q-Value: 2.87\n",
      "INFO:root:Iter 93/100 | Loss: 0.2494 | Avg Q-Value: 2.82\n",
      "INFO:root:Iter 94/100 | Loss: 0.2482 | Avg Q-Value: 2.83\n",
      "INFO:root:Iter 95/100 | Loss: 0.2483 | Avg Q-Value: 2.83\n",
      "INFO:root:Iter 96/100 | Loss: 0.2477 | Avg Q-Value: 2.86\n",
      "INFO:root:Iter 97/100 | Loss: 0.2483 | Avg Q-Value: 2.83\n",
      "INFO:root:Iter 98/100 | Loss: 0.2482 | Avg Q-Value: 2.85\n",
      "INFO:root:Iter 99/100 | Loss: 0.2473 | Avg Q-Value: 2.85\n",
      "INFO:root:Iter 100/100 | Loss: 0.2483 | Avg Q-Value: 2.81\n",
      "100%|██████████| 100/100 [14:43<00:00,  8.83s/it]\n",
      "INFO:root:Policy updated. New theta_hat: [0. 0. 1. 0. 0.]\n",
      "  1%|          | 14/2000 [15:57<37:42:43, 68.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (1x13 and 14x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# simulator.projected_volume_learner.is_terminated = True\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simulation_data \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_customers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CUSTOMERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simulation_data)\n",
      "File \u001b[0;32m~/Desktop/degradable/simulation.py:190\u001b[0m, in \u001b[0;36mSimulator.run\u001b[0;34m(self, num_customers)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_policy() \u001b[38;5;66;03m# First time policy setup\u001b[39;00m\n\u001b[1;32m    185\u001b[0m arrival_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m    186\u001b[0m     X_before, \n\u001b[1;32m    187\u001b[0m     customer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    188\u001b[0m     [customer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesired_duration\u001b[39m\u001b[38;5;124m'\u001b[39m], I_before, \u001b[38;5;241m0.0\u001b[39m]\n\u001b[1;32m    189\u001b[0m ])\n\u001b[0;32m--> 190\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimal_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrival_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# action = 0 # temporary\u001b[39;00m\n\u001b[1;32m    193\u001b[0m price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmachine\u001b[38;5;241m.\u001b[39mcalculate_price(\n\u001b[1;32m    194\u001b[0m     customer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojected_volume_learner\u001b[38;5;241m.\u001b[39mget_estimate()\n\u001b[1;32m    196\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/degradable/policy.py:311\u001b[0m, in \u001b[0;36mDPAgent.get_policy.<locals>.policy_fn\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    309\u001b[0m state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 311\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m phase \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m: \u001b[38;5;66;03m# Arrival\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/degradable/policy.py:29\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/res/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (1x13 and 14x64)"
     ]
    }
   ],
   "source": [
    "# simulator.projected_volume_learner.is_terminated = True\n",
    "simulation_data = simulator.run(num_customers=NUM_CUSTOMERS)\n",
    "df = pd.DataFrame(simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_history = pd.DataFrame(simulator.degradation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "\n",
    "degradation_learner.fit(degradation_history)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.event_type == 'rental'].profit.mean(), df[df.event_type == 'rental'].profit.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126debf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.feedback.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086d1ae",
   "metadata": {},
   "source": [
    "## Estimating $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "degradation_learner = DegradationLearner(d=D, initial_theta=np.zeros(D))\n",
    "\n",
    "degradation_learner.fit(df)\n",
    "degradation_learner.get_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0da177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy import DPAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp_params = {\n",
    "    'replacement_cost': 1.5,   # Cost to replace the machine\n",
    "    'failure_cost': 0.75,      # Additional penalty for in-service failure\n",
    "    'holding_cost_rate': 0.02,   # Cost per unit of idle time\n",
    "    'gamma': 0.999,             # Discount factor\n",
    "    'learning_rate': 1e-4,      # Learning rate for the Adam optimizer\n",
    "    'target_update_freq': 10    # How often to update the target network (in iterations)\n",
    "}\n",
    "\n",
    "# Training Hyperparameters\n",
    "TRAINING_ITERATIONS = 100\n",
    "DATASET_SIZE = 50000          # Number of transitions to generate for the offline dataset\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "u_hat = simulator.centroids[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22317754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_agent = DPAgent(\n",
    "    d=D,\n",
    "    u_hat=u_hat,\n",
    "    degradation_learner=degradation_learner,\n",
    "    customer_generator=customer_gen,\n",
    "    params=mdp_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "dp_agent.train(\n",
    "    num_iterations=TRAINING_ITERATIONS,\n",
    "    dataset_size=DATASET_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policy = dp_agent.get_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "\n",
    "X_i = df.loc[i, 'sum_of_contexts_after']\n",
    "I_i = 3 # df.loc[i, '']\n",
    "x_i = df.loc[i+1, 'customer_context']\n",
    "T_i = df.loc[i+1, 'rental_duration']\n",
    "\n",
    "arrival_state = np.concatenate([\n",
    "    X_i,\n",
    "    x_i,\n",
    "    [T_i, I_i, 0.0]\n",
    "])\n",
    "action_arrival = optimal_policy(arrival_state)\n",
    "action_map = {0: 'Give Max Acceptable Price', 1: 'Shutdown'}\n",
    "print(f\"Sample Arrival State. Optimal Action: {action_map[action_arrival]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Departure State\n",
    "departure_state = np.concatenate([\n",
    "    X_i+x_i*10, \n",
    "    np.zeros(D), \n",
    "    [0.0, I_i, 1.0]\n",
    "])\n",
    "action_departure = optimal_policy(departure_state)\n",
    "action_map = {2: 'Replace Machine', 3: 'Do Not Replace'}\n",
    "print(f\"Sample Departure State. Optimal Action: {action_map[action_departure]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
